# Зміст документації проєкту HealthRisk.AI

## 1. Вступ

### 1.1. Про проєкт
### 1.2. Мета та завдання
### 1.3. Структура документації

## 2. Архітектурний огляд системи (блок 10-ARCHITECTURE_OVERVIEW)

### 2.1. Високорівнева структура системи
### 2.2. Потік даних: від сирих NHANES до прогнозу ризику
### 2.3. Взаємодія користувача з системою
### 2.4. Логічні модулі та сторінки системи
### 2.5. Роль бази даних в архітектурі
### 2.6. Архітектура інтеграції з локальною AI-моделлю (Ollama)
### 2.7. Архітектура генерації звітів
### 2.8. Тестування як частина архітектури системи
### 2.9. Нефункціональні аспекти архітектури
### 2.10. Підсумок

## 3. Дані та підготовка датасету (блоки 0-DATA, 1-ETL)

### 3.1. Джерело даних: NHANES (National Health and Nutrition Examination Survey)
#### 3.1.1. Опис датасету NHANES
#### 3.1.2. Компоненти NHANES, що використовуються в проєкті
#### 3.1.3. Структура сирих даних

### 3.2. Цільовий датасет проєкту: health_dataset.csv
#### 3.2.1. Основні групи змінних
#### 3.2.2. Демографічні змінні
#### 3.2.3. Антропометрія
#### 3.2.4. Артеріальний тиск
#### 3.2.5. Лабораторні показники
#### 3.2.6. Цільові змінні

### 3.3. ETL-процес: підготовка NHANES до health_dataset.csv
#### 3.3.1. Файли та папки, що беруть участь у ETL
#### 3.3.2. Сирі дані
#### 3.3.3. ETL-логіка та скрипти
#### 3.3.4. Конфігурація ETL
#### 3.3.5. Послідовність ETL-процесу
##### 3.3.5.1. Завантаження сирих таблиць
##### 3.3.5.2. Об'єднання таблиць
##### 3.3.5.3. Вибір необхідних колонок
##### 3.3.5.4. Обробка пропусків
##### 3.3.5.5. Фільтрування
##### 3.3.5.6. Перейменування колонок
##### 3.3.5.7. Формування фінального датасету
#### 3.3.6. Перевірка якості підготовлених даних
##### 3.3.6.1. Перевірки на пропуски
##### 3.3.6.2. Перевірка типів даних
##### 3.3.6.3. Перевірка діапазонів
##### 3.3.6.4. Перевірка унікальності ключа SEQN
#### 3.3.7. Роль ETL в магістерському проєкті

## 4. Дослідницький аналіз даних (EDA) (блок 2-EDA)

### 4.1. Вихідні дані для аналізу
### 4.2. Скрипти та інструменти EDA
### 4.3. Основні візуалізації та висновки
#### 4.3.1. Розподіли та описові статистики
#### 4.3.2. Зв'язки між змінними
#### 4.3.3. Аналіз цільових змінних
#### 4.3.4. Текстовий підсумок (summary.txt)
### 4.4. Як результати EDA вплинули на вибір ознак і моделей
### 4.5. Роль EDA в магістерському проєкті

## 5. ML-моделі проєкту (блок 3-ML_MODELS)

### 5.1. Набір моделей
#### 5.1.1. Моделі для прогнозування діабету (diabetes_present)
#### 5.1.2. Моделі для прогнозування ожиріння (obesity_present)
#### 5.1.3. Основні ознаки

### 5.2. Навчання моделей
#### 5.2.1. Скрипти навчання
#### 5.2.2. Pipeline навчання
##### 5.2.2.1. Завантаження даних
##### 5.2.2.2. Підготовка даних
##### 5.2.2.3. Попередня обробка (preprocessing)
##### 5.2.2.4. Навчання моделей
##### 5.2.2.5. Обчислення метрик
##### 5.2.2.6. Збереження артефактів
##### 5.2.2.7. Створення лідерборду
#### 5.2.3. Вибір "Champion Model"

### 5.3. Калібрування моделей
#### 5.3.1. Процес калібрування
#### 5.3.2. Методи калібрування
#### 5.3.3. Артефакти калібрування

### 5.4. Інференс (прогнозування) у API
#### 5.4.1. API endpoints
#### 5.4.2. Завантаження моделей
#### 5.4.3. Pipeline використання

### 5.5. Інтерпретація та фактори ризику
#### 5.5.1. Обчислення важливості ознак
#### 5.5.2. Інтеграція у веб-інтерфейс та PDF

### 5.6. Роль ML-моделей у проєкті

## 6. Технологічний стек (блок 4-TECH_STACK)

### 6.1. Backend
#### 6.1.1. FastAPI
#### 6.1.2. Uvicorn
#### 6.1.3. Starlette
#### 6.1.4. SQLModel та SQLAlchemy
#### 6.1.5. SQLite
#### 6.1.6. Pydantic
#### 6.1.7. JWT (JSON Web Tokens)
#### 6.1.8. OAuth2PasswordBearer
#### 6.1.9. Bcrypt та Passlib
#### 6.1.10. Pillow (PIL)
#### 6.1.11. Requests
#### 6.1.12. Python-multipart

### 6.2. Frontend
#### 6.2.1. Vanilla JavaScript
#### 6.2.2. Chart.js
#### 6.2.3. jsPDF
#### 6.2.4. xlsx-js-style
#### 6.2.5. Navigo
#### 6.2.6. Lucide
#### 6.2.7. Власний i18n модуль
#### 6.2.8. CSS

### 6.3. ML та аналіз даних
#### 6.3.1. Pandas
#### 6.3.2. NumPy
#### 6.3.3. Scikit-learn
#### 6.3.4. XGBoost
#### 6.3.5. Joblib
#### 6.3.6. Matplotlib та Seaborn
#### 6.3.7. PyYAML

### 6.4. База даних та сховище
#### 6.4.1. SQLite
#### 6.4.2. SQLModel ORM
#### 6.4.3. Міграції

### 6.5. Інфраструктура та інструменти розробки
#### 6.5.1. Makefile
#### 6.5.2. Pytest
#### 6.5.3. Pytest-asyncio
#### 6.5.4. Pytest-cov
#### 6.5.5. Httpx
#### 6.5.6. Pyright
#### 6.5.7. Typer

### 6.6. AI-асистент та Ollama
#### 6.6.1. Ollama
#### 6.6.2. Інтеграція з Ollama

### 6.7. Підсумок

## 7. API проєкту (блок 5-API)

### 7.1. Архітектура API
### 7.2. Основні групи ендпоінтів
#### 7.2.1. Прогнозування ризиків (/predict, /explain, /metadata)
#### 7.2.2. Аутентифікація (/auth/*)
#### 7.2.3. Управління користувачами (/users/*)
#### 7.2.4. AI-асистент (/assistant/*)
#### 7.2.5. Чати (/api/chats/*)
#### 7.2.6. Системні ендпоінти (/health, /system/*)

### 7.3. Як API працює з ML-моделями
#### 7.3.1. Зберігання моделей
#### 7.3.2. Завантаження моделей
#### 7.3.3. Pipeline використання
#### 7.3.4. Передача даних до моделі
#### 7.3.5. Повернення оцінки ризику
#### 7.3.6. Визначення factor impact

### 7.4. Як API працює з базою даних
#### 7.4.1. Структура даних
#### 7.4.2. CRUD операції
#### 7.4.3. Інтеграція з ORM

### 7.5. Аутентифікація
#### 7.5.1. JWT токени
#### 7.5.2. Хешування паролів
#### 7.5.3. Захищені та незахищені роути

### 7.6. Генерація PDF/Excel/CSV/JSON на бекенді та фронтенді
#### 7.6.1. Роль бекенду
#### 7.6.2. Роль фронтенду
#### 7.6.3. Формати експорту

### 7.7. Інтеграція API з AI-моделлю Ollama
#### 7.7.1. Архітектура інтеграції
#### 7.7.2. Формування контексту
#### 7.7.3. Виклики Ollama API

### 7.8. API-Status система
#### 7.8.1. Перевірка стану компонентів
#### 7.8.2. Відображення статусів

### 7.9. Формат відповідей API
#### 7.9.1. Структури JSON
#### 7.9.2. Валідація даних

### 7.10. Взаємодія API та фронтенду
#### 7.10.1. SPA архітектура
#### 7.10.2. Обробка помилок

### 7.11. Безпека API
#### 7.11.1. Захист ендпоінтів
#### 7.11.2. Валідація даних
#### 7.11.3. Обмеження доступу

### 7.12. Обмеження та майбутня робота

## 8. Архітектура фронтенду (блок 6-FRONTEND_ARCHITECTURE)

### 8.1. Загальний огляд фронтенду
### 8.2. Структура файлів фронтенду
#### 8.2.1. index.html
#### 8.2.2. app.js
#### 8.2.3. app.css
#### 8.2.4. i18n.js
#### 8.2.5. Локалізація (locales/)
#### 8.2.6. Шрифти та зображення

### 8.3. Архітектура SPA
#### 8.3.1. Принцип роботи SPA
#### 8.3.2. Секції відображаються/ховаються
#### 8.3.3. Маршрути синхронізуються
#### 8.3.4. Ключові концепції

### 8.4. Система маршрутизації (Frontend Routing)
#### 8.4.1. Сторінки системи
#### 8.4.2. Публічні та захищені сторінки
#### 8.4.3. Guard-и для автентифікації

### 8.5. Управління станом (State Management)
#### 8.5.1. authState
#### 8.5.2. chatState
#### 8.5.3. modelResultsState
#### 8.5.4. diagramState
#### 8.5.5. reportState
#### 8.5.6. apiStatusState

### 8.6. Робота з API
#### 8.6.1. Fetch-запити
#### 8.6.2. Обробка помилок
#### 8.6.3. Управління токенами

### 8.7. Генерація PDF-звітів
#### 8.7.1. Використання jsPDF
#### 8.7.2. Вбудовування діаграм
#### 8.7.3. Підтримка кирилиці

### 8.8. Діаграми (Charts)
#### 8.8.1. Використання Chart.js
#### 8.8.2. Типи діаграм
#### 8.8.3. Експорт у PDF

### 8.9. AI-асистент (Ollama Frontend UI)
#### 8.9.1. Чат-інтерфейс
#### 8.9.2. Інтеграція з API
#### 8.9.3. Відображення статусів

### 8.10. UI/UX архітектура
#### 8.10.1. Система секцій та сторінок
#### 8.10.2. Модальні вікна
#### 8.10.3. Анімації та переходи
#### 8.10.4. Адаптивність

### 8.11. Стилі
#### 8.11.1. Архітектура CSS
#### 8.11.2. Темна та світла теми
#### 8.11.3. BEM-подібна методологія

### 8.12. Система локалізації
#### 8.12.1. JSON-файли перекладів
#### 8.12.2. Динамічна підміна текстів
#### 8.12.3. Підтримка мов

### 8.13. Тести для фронтенду (архітектурний огляд)
### 8.14. Майбутні покращення

## 9. Архітектура бекенду (блок 7-BACKEND_ARCHITECTURE)

### 9.1. Загальний огляд бекенду
### 9.2. Структура файлів бекенду
#### 9.2.1. api.py
#### 9.2.2. routers/
#### 9.2.3. routes_auth.py
#### 9.2.4. schemas.py
#### 9.2.5. models.py
#### 9.2.6. db.py
#### 9.2.7. repositories.py
#### 9.2.8. auth_utils.py
#### 9.2.9. model_registry.py
#### 9.2.10. services/assistant_llm.py
#### 9.2.11. avatar_utils.py
#### 9.2.12. i18n.py

### 9.3. ASGI / FastAPI архітектура
#### 9.3.1. Запуск сервісу
#### 9.3.2. ASGI lifecycle
#### 9.3.3. Робота event loop
#### 9.3.4. Інтеграція FastAPI з фронтендом
#### 9.3.5. Middleware

### 9.4. Архітектура маршрутів (Routers)
#### 9.4.1. auth_router
#### 9.4.2. users_router
#### 9.4.3. assistant_router
#### 9.4.4. chats_router
#### 9.4.5. Системні ендпоінти

### 9.5. Система аутентифікації
#### 9.5.1. JWT токени
#### 9.5.2. Хешування паролів
#### 9.5.3. Dependency injection
#### 9.5.4. Механізм refresh токенів

### 9.6. Взаємодія бекенду з ML-моделями
#### 9.6.1. Зберігання моделей
#### 9.6.2. Завантаження моделей
#### 9.6.3. Обробка вхідних даних
#### 9.6.4. Виконання прогнозування
#### 9.6.5. Обчислення факторів впливу

### 9.7. Робота з базою даних
#### 9.7.1. ORM та структура БД
#### 9.7.2. CRUD операції
#### 9.7.3. Управління сесіями
#### 9.7.4. Обробка помилок

### 9.8. Обробка історії прогнозів
#### 9.8.1. Збереження прогнозів
#### 9.8.2. Отримання історії
#### 9.8.3. Статистика

### 9.9. API статуси (API-Status System)
#### 9.9.1. Перевірка стану компонентів
#### 9.9.2. Агрегація статусів

### 9.10. Chat API
#### 9.10.1. Створення чатів
#### 9.10.2. Управління повідомленнями
#### 9.10.3. Блокування користувачів

### 9.11. AI-Assistant API (Ollama)
#### 9.11.1. Інтеграція з Ollama
#### 9.11.2. Формування контексту
#### 9.11.3. Обробка відповідей

### 9.12. Error handling
#### 9.12.1. Глобальна обробка помилок
#### 9.12.2. Форматування відповідей
#### 9.12.3. Статус-коди

### 9.13. Безпека
#### 9.13.1. CORS контроль
#### 9.13.2. JWT безпека
#### 9.13.3. Хешування паролів
#### 9.13.4. Валідація даних

### 9.14. Майбутні покращення

## 10. База даних (блок 8-DATABASE)

### 10.1. Загальний огляд
#### 10.1.1. Тип БД
#### 10.1.2. Основні задачі БД
#### 10.1.3. Роль БД як центрального сховища стану

### 10.2. Технології та інструменти для роботи з БД
#### 10.2.1. Бібліотеки для роботи з БД
#### 10.2.2. Основний код роботи з БД
#### 10.2.3. Організація підключення до БД
#### 10.2.4. Life-cycle сесій у запитах

### 10.3. Фізичне розташування БД
#### 10.3.1. Де зберігається файл БД
#### 10.3.2. Створення БД автоматично
#### 10.3.3. Скрипти для ініціалізації / міграцій

### 10.4. Основні таблиці та їх призначення
#### 10.4.1. Таблиця користувачів (user)
#### 10.4.2. Таблиця історії прогнозів (predictionhistory)
#### 10.4.3. Таблиця чатів (chat)
#### 10.4.4. Таблиця повідомлень (chatmessage)
#### 10.4.5. Таблиця повідомлень AI-асистента (assistantmessage)
#### 10.4.6. Таблиця заблокованих користувачів (userblock)
#### 10.4.7. Таблиця токенів відновлення пароля (passwordresettoken)

### 10.5. Зв'язки між таблицями
#### 10.5.1. User ↔ PredictionHistory
#### 10.5.2. User ↔ AssistantMessage
#### 10.5.3. User ↔ Chat
#### 10.5.4. Chat ↔ ChatMessage
#### 10.5.5. User ↔ UserBlock
#### 10.5.6. Інші зв'язки

### 10.6. Управління транзакціями
#### 10.6.1. Як відкривається сесія для запиту
#### 10.6.2. Як commit/rollback організовано
#### 10.6.3. Контекстні менеджери / dependency injection
#### 10.6.4. Цілісність даних при помилках

### 10.7. Продуктивність та масштабованість
#### 10.7.1. Індекси на ключових полях
#### 10.7.2. Які таблиці ростуть найшвидше
#### 10.7.3. Що буде важливим для масштабування

### 10.8. Як різні модулі системи використовують базу даних
#### 10.8.1. Модуль аутентифікації
#### 10.8.2. Модуль прогнозів
#### 10.8.3. Модуль чатів
#### 10.8.4. Модуль API-status
#### 10.8.5. Модуль блокувань
#### 10.8.6. Модуль AI-асистента

### 10.9. Безпека даних
#### 10.9.1. Як зберігаються паролі
#### 10.9.2. Відсутність зберігання "чистих" паролів
#### 10.9.3. Можлива анонімізація чутливих медичних даних
#### 10.9.4. Обмеження доступу через auth-рівень

### 10.10. Можливі напрямки покращення схеми БД
#### 10.10.1. Перехід на більш потужну СУБД
#### 10.10.2. Виділення логів у окрему таблицю/схему
#### 10.10.3. Додавання audit log
#### 10.10.4. Оптимізація індексів
#### 10.10.5. Розділення data warehouse та онлайн-схеми

## 11. Тестування (блок 9-TESTING)

### 11.1. Загальний огляд
#### 11.1.1. Рівні тестування
#### 11.1.2. Призначення тестів
#### 11.1.3. Фізичне розташування тестів

### 11.2. Структура тестового каталогу
#### 11.2.1. Коренева папка tests/
#### 11.2.2. Підпапка tests/backend/
#### 11.2.3. Підпапка tests/frontend/
#### 11.2.4. Підпапка tests/ml/
#### 11.2.5. Підпапка tests/utils/
#### 11.2.6. Файл conftest.py

### 11.3. Інструменти та фреймворки тестування
#### 11.3.1. Pytest
#### 11.3.2. Pytest-asyncio
#### 11.3.3. Pytest-cov
#### 11.3.4. Httpx
#### 11.3.5. Frontend тестові інструменти

### 11.4. Unit тести
#### 11.4.1. Модулі, що покриваються unit тестами
#### 11.4.2. Розташування unit тестів
#### 11.4.3. Типові сценарії, що перевіряються

### 11.5. Інтеграційні тести
#### 11.5.1. Компоненти, що перевіряють інтеграційні тести
#### 11.5.2. Розташування інтеграційних тестів
#### 11.5.3. Організація підготовки середовища

### 11.6. Тестування ML моделей
#### 11.6.1. Розташування ML тестів
#### 11.6.2. Аспекти, що перевіряються

### 11.7. Тестування API
#### 11.7.1. Ендпоінти, що покриваються тестами
#### 11.7.2. Як тести формують HTTP запити
#### 11.7.3. Як тести перевіряють статус код
#### 11.7.4. Як тести перевіряють структуру JSON-відповіді
#### 11.7.5. Як тести перевіряють сценарії з помилками

### 11.8. Тестування фронтенду
#### 11.8.1. Статус фронтенд тестів
#### 11.8.2. Майбутні інструменти

### 11.9. Експериментальні тести та нестандартні сценарії
#### 11.9.1. Розташування експериментальних тестів
#### 11.9.2. Що перевіряють експериментальні тести
#### 11.9.3. Як допомагають підтвердити надійність системи

### 11.10. Запуск тестів та конфігурація
#### 11.10.1. Як запустити всі тести одним рядком
#### 11.10.2. Окремі задачі для різних типів тестів
#### 11.10.3. Використання coverage

### 11.11. Покриття та якість
#### 11.11.1. Вимірювання coverage
#### 11.11.2. Частини системи, покриті тестами найкраще
#### 11.11.3. Частини системи, покриті гірше або ще не покриті
#### 11.11.4. Як тести інтегруються з процесом розробки

### 11.12. Можливі напрямки розвитку системи тестування

## 12. Структура проєкту (блок STRUCTURE)

### 12.1. Загальна структура директорій
### 12.2. Ключові папки та файли
#### 12.2.1. artifacts/
#### 12.2.2. configs/
#### 12.2.3. data/
#### 12.2.4. datasets/
#### 12.2.5. scripts/
#### 12.2.6. src/
#### 12.2.7. tests/
#### 12.2.8. docs/

## 13. Обмеження та поточний стан системи

### 13.1. Технічні обмеження
#### 13.1.1. Обмеження SQLite
#### 13.1.2. Обмеження локального Ollama
#### 13.1.3. Обмеження фронтенду
#### 13.1.4. Обмеження ML-моделей

### 13.2. Функціональні обмеження
#### 13.2.1. Підтримувані цільові змінні
#### 13.2.2. Обмеження датасету
#### 13.2.3. Обмеження інтерфейсу

### 13.3. Поточний стан розробки
#### 13.3.1. Реалізовані функції
#### 13.3.2. Функції в розробці
#### 13.3.3. Відомі проблеми

## 14. Майбутній розвиток

### 14.1. Розширення ML-моделей
#### 14.1.1. Додавання нових цільових змінних
#### 14.1.2. Покращення існуючих моделей
#### 14.1.3. Інтеграція нових алгоритмів

### 14.2. Покращення архітектури
#### 14.2.1. Масштабування для продакшену
#### 14.2.2. Мікросервісна архітектура
#### 14.2.3. Оптимізація продуктивності

### 14.3. Розширення функціональності
#### 14.3.1. Додаткові типи звітів
#### 14.3.2. Покращення AI-асистента
#### 14.3.3. Розширення системи чатів

### 14.4. Покращення тестування
#### 14.4.1. Покриття фронтенду тестами
#### 14.4.2. E2E тести
#### 14.4.3. Стес-тести

### 14.5. Інфраструктура
#### 14.5.1. CI/CD
#### 14.5.2. Моніторинг та логування
#### 14.5.3. Резервне копіювання

## 15. Висновки

### 15.1. Підсумок проєкту
### 15.2. Досягнення
### 15.3. Вклад у магістерську роботу
### 15.4. Перспективи розвитку

# Частина 1: Вступ, огляд проєкту, дані, ETL та EDA

## 1. Вступ

HealthRisk.AI — це комплексна система для оцінки та прогнозування ризиків здоров'я на основі медичних даних NHANES (National Health and Nutrition Examination Survey). Система трансформує сирі медичні дані через етапи обробки, аналізу та машинного навчання в інтерактивний веб-застосунок, який дозволяє користувачам отримувати персоналізовані оцінки ризиків здоров'я та рекомендації.

Система створена для забезпечення доступності передових методів машинного навчання в сфері оцінки ризиків здоров'я для широкого кола користувачів. Основна мета проєкту полягає в тому, щоб надати інструмент, який дозволяє людям отримувати об'єктивні оцінки ризиків розвитку таких захворювань, як діабет та ожиріння, на основі їхніх медичних показників. Система спрощує складний процес аналізу медичних даних та перетворює його в зрозумілі та дієві рекомендації.

Високорівнева логіка роботи системи організована як послідовна трансформація даних від сирих медичних таблиць до персоналізованих оцінок ризиків. Процес починається з завантаження та обробки офіційних даних NHANES, які містять комплексну інформацію про стан здоров'я населення США. Ці дані проходять через етап ETL (Extract, Transform, Load), де вони об'єднуються, очищаються та підготовлюються для подальшого аналізу. Наступний етап — дослідницький аналіз даних (EDA), який дозволяє зрозуміти розподіли змінних, кореляції між ознаками та виявити ключові фактори ризику. Результати EDA використовуються для навчання моделей машинного навчання, які трансформують медичні параметри в оцінки ризиків. Навчені моделі інтегруються в веб-інтерфейс через REST API, що дозволяє користувачам вводити свої показники та отримувати миттєві прогнози ризиків.

Користувачами системи є люди, які цікавляться оцінкою ризиків свого здоров'я та отриманням об'єктивних рекомендацій на основі медичних показників. Система розроблена для широкого кола користувачів, включаючи тих, хто хоче проактивно підходити до збереження здоров'я, людей з факторами ризику, які потребують регулярного моніторингу, та фахівців, які можуть використовувати систему як допоміжний інструмент для оцінки ризиків пацієнтів.

Система важлива, оскільки вона демократизує доступ до передових методів машинного навчання в медицині, роблячи складні аналітичні інструменти доступними для широкої аудиторії. Вона забезпечує об'єктивну оцінку ризиків на основі науково обґрунтованих даних, що дозволяє користувачам приймати інформовані рішення щодо свого здоров'я. Система також слугує прикладом практичного застосування машинного навчання в медичній сфері, демонструючи, як великі медичні датасети можуть бути трансформовані в корисні інструменти для повсякденного використання.

Основна ідея системи полягає в поєднанні аналізу даних NHANES, машинного навчання, REST API та веб-інтерфейсу для створення комплексного рішення для оцінки ризиків здоров'я. NHANES надає надійну та репрезентативну базу даних для навчання моделей, машинне навчання забезпечує точні прогнози на основі складних взаємозв'язків між показниками здоров'я, REST API дозволяє інтегрувати моделі в веб-застосунок, а веб-інтерфейс забезпечує зручний та зрозумілий спосіб взаємодії користувачів з системою. Це поєднання створює потужну платформу, яка трансформує складні медичні дані в практичні та дієві інструменти для оцінки ризиків здоров'я.

## 2. Огляд проєкту

Система HealthRisk.AI складається з кількох взаємопов'язаних компонентів, які працюють разом для забезпечення повної функціональності платформи. Кожен компонент має свою специфічну роль та відповідальність, але разом вони створюють єдину інтегровану систему для оцінки та прогнозування ризиків здоров'я.

**Frontend** — це інтерфейсний шар системи, реалізований як Single Page Application (SPA) на чистому JavaScript. Фронтенд забезпечує взаємодію користувачів з системою через веб-браузер, надаючи форми для введення медичних параметрів, відображаючи результати прогнозування з візуалізацією ризиків, інтегруючи чати між користувачами та AI-асистента, генеруючи PDF-звіти з результатами та забезпечуючи навігацію між сторінками без перезавантаження. Фронтенд працює як тонкий клієнт, який отримує дані через API та відображає їх користувачам у зручному та зрозумілому форматі.

**Backend** — це центральний шар взаємодії, побудований на FastAPI, який об'єднує всі компоненти системи. Бекенд забезпечує REST API для фронтенду, виконує ML inference через завантаження та використання навчених моделей, управляє аутентифікацією користувачів через JWT-токени, зберігає та читає дані з бази даних, інтегрується з Ollama для AI-асистента та надає системні ендпоінти для моніторингу стану системи. API працює як оркестратор, який координує роботу всіх компонентів для обробки запитів користувачів.

**ML (Machine Learning)** — це інтелектуальний шар системи, який трансформує медичні параметри в оцінки ризиків. На цьому етапі навчаються множина моделей машинного навчання для прогнозування ризиків діабету та ожиріння. Моделі оцінюються за метриками, після чого обирається найкраща (champion) модель для кожної задачі. Champion-моделі проходять калібрування для покращення якості ймовірностей та зберігаються як артефакти для використання в API.

**Database** — це шар персистентності, який зберігає всі динамічні дані системи. SQLite база даних містить таблиці для користувачів, історії прогнозів, чатів та повідомлень, AI-асистента та блокувань користувачів. БД є єдиним джерелом правди для всіх динамічних даних, які змінюються під час роботи системи.

**API** — це інтерфейс взаємодії між фронтендом та бекендом, який забезпечує структуровану передачу даних та обробку запитів. API надає ендпоінти для прогнозування ризиків, управління користувачами, роботи з історією прогнозів, чатами та AI-асистентом.

**PDF-звіти** — це система генерації звітів, яка трансформує результати прогнозування в структуровані документи. PDF-звіти генеруються на фронтенді через jsPDF та Chart.js, включаючи текст з поясненнями, діаграми ризиків, топ фактори впливу та технічні деталі.

**Assistant (AI-асистент)** — це допоміжний інтелектуальний шар, який надає AI-асистента для пояснення результатів та надання рекомендацій. Локальна мовна модель Ollama працює як окремий сервіс, до якого бекенд звертається через HTTP API для генерації відповідей на запити користувачів.

**Оцінка ризиків** — це основна функціональність системи, яка дозволяє користувачам отримувати персоналізовані оцінки ризиків здоров'я на основі їхніх медичних показників. Система оцінює ризики розвитку діабету та ожиріння, надаючи ймовірності, категорії ризику та топ фактори впливу.

Загальні принципи архітектури системи базуються на модульності, простоті, масштабованості та прозорості. **Модульність** забезпечується чітким розділенням відповідальності між компонентами, де кожен модуль виконує конкретні завдання та взаємодіє з іншими через чітко визначені інтерфейси. **Простота** досягається через використання стандартних технологій та мінімалістичних рішень, які забезпечують легкість розуміння, підтримки та розширення системи. **Масштабованість** враховується через архітектурні рішення, які дозволяють легко додавати нові функції та компоненти без впливу на існуючі. **Прозорість** забезпечується через детальну документацію, логування операцій та інтеграцію результатів EDA у веб-інтерфейс, що дозволяє користувачам розуміти, на основі яких даних та аналізів формуються прогнози.

Технічний стек системи включає сучасні інструменти та бібліотеки для забезпечення високої продуктивності, надійності та зручності розробки. Бекенд побудований на FastAPI — сучасному асинхронному веб-фреймворку для Python, який забезпечує автоматичну генерацію OpenAPI-документації, валідацію даних через Pydantic та високу продуктивність. Фронтенд реалізований на чистому JavaScript без використання фреймворків, що забезпечує мінімальну залежність від зовнішніх бібліотек та повний контроль над поведінкою додатку. ML-моделі навчаються за допомогою scikit-learn, XGBoost та інших бібліотек машинного навчання. База даних використовує SQLite для простоти розгортання та SQLModel як ORM для роботи з даними. Детальний опис технологічного стеку наведено в окремому розділі документації.

## 3. Дані

### 3.1. Джерело даних: NHANES

У цьому проєкті використовується офіційний медичний датасет NHANES (National Health and Nutrition Examination Survey), який доступний на платформі Kaggle за посиланням: https://www.kaggle.com/datasets/cdc/national-health-and-nutrition-examination-survey. NHANES — це репрезентативне дослідження стану здоров'я та харчування населення США, яке проводиться Центром контролю та профілактики захворювань (CDC). Це дослідження включає комплексні медичні вимірювання, лабораторні аналізи, антропометричні дані та опитувальники, що охоплюють широкий спектр показників здоров'я.

Вибір датасету NHANES обумовлений кількома ключовими факторами. По-перше, це офіційне джерело даних від CDC, що забезпечує високу якість та надійність інформації. По-друге, NHANES є репрезентативним дослідженням, яке охоплює широку вибірку населення США, що робить результати застосовними до великої кількості людей. По-третє, датасет містить комплексну інформацію про різні аспекти здоров'я, включаючи демографічні дані, антропометричні вимірювання, лабораторні показники, дані про харчування та прийом ліків, що дозволяє проводити багатофакторний аналіз ризиків здоров'я. По-четверте, дані NHANES широко використовуються в наукових дослідженнях, що забезпечує можливість порівняння результатів з іншими роботами та валідацію методів.

Структура сирих даних NHANES організована як набір окремих таблиць, кожна з яких містить специфічну категорію медичних та демографічних даних. Усі таблиці мають спільний унікальний ідентифікатор респондента — `SEQN` (Sequence Number), який дозволяє об'єднувати дані з різних джерел для кожного учасника дослідження. Ця структура дозволяє гнучко працювати з даними, об'єднуючи лише необхідні таблиці для конкретного аналізу.

У цьому проєкті використовуються наступні компоненти NHANES, які зберігаються у вигляді окремих CSV-файлів у директорії `datasets/raw/`:

- **demographic.csv** — демографічні дані, які містять інформацію про вік, стать, расу/етнічність та інші соціально-демографічні характеристики респондентів. Ці дані є фундаментальними для будь-якого аналізу ризиків здоров'я, оскільки демографічні фактори тісно пов'язані з різними захворюваннями.

- **examination.csv** — дані фізичного обстеження, які включають антропометричні вимірювання (зріст, вага, індекс маси тіла), артеріальний тиск та інші фізичні показники. Ці дані є ключовими для оцінки фізичного стану здоров'я та виявлення факторів ризику.

- **labs.csv** — лабораторні показники, які містять результати біохімічних аналізів крові, включаючи рівень глюкози, холестерину та інших маркерів здоров'я. Ці дані надають об'єктивну інформацію про метаболічний стан організму та дозволяють виявляти ранні ознаки захворювань.

- **questionnaire.csv** — дані з опитувальників, які включають інформацію про діагностовані захворювання (зокрема, статус діабету), медичну історію та інші суб'єктивні показники здоров'я. Ці дані доповнюють об'єктивні вимірювання та надають контекст для інтерпретації результатів.

- **diet.csv** — дані про харчування, які містять інформацію про споживання різних продуктів та харчових речовин. Хоча ці дані не використовуються безпосередньо в моделях проєкту, вони можуть бути корисними для майбутніх розширень системи.

- **medications.csv** — дані про прийом ліків, які містять інформацію про лікарські препарати, що приймають респонденти. Ці дані також можуть бути корисними для майбутніх аналізів та розширень функціональності системи.

Типи даних у NHANES охоплюють широкий спектр показників здоров'я. **Показники здоров'я** включають індекс маси тіла, артеріальний тиск, пульс та інші фізичні характеристики. **Лабораторні тести** містять результати біохімічних аналізів, включаючи рівень глюкози, холестерину, гемоглобіну та інших маркерів. **Демографія** включає вік, стать, расу/етнічність, рівень освіти та інші соціально-демографічні характеристики. **Антропометрія** охоплює зріст, вагу, обхват талії та інші фізичні вимірювання. Кожен тип даних надає унікальну інформацію про стан здоров'я респондента та дозволяє проводити комплексний аналіз ризиків.

### 3.2. Цільовий датасет проєкту: health_dataset.csv

Після обробки сирих даних NHANES через ETL-процес формується цільовий датасет проєкту `health_dataset.csv`, який зберігається у директорії `datasets/processed/`. Це об'єднаний, очищений і підготовлений датасет, який є результатом трансформації сирих NHANES-таблиць. Він використовується для дослідницького аналізу даних (EDA), тренування моделей машинного навчання для прогнозування ризиків та інференсу (реального прогнозування ризиків здоров'я через веб-інтерфейс та API).

Датасет містить 9770 рядків та 10 колонок, що представляє значну вибірку для аналізу та навчання моделей. Основні групи змінних включають демографічні дані, антропометрію, артеріальний тиск, лабораторні показники, статус захворювань та цільові змінні.

**Демографічні змінні** представлені унікальним ідентифікатором респондента `SEQN`, віком у роках `RIDAGEYR` та статтю `RIAGENDR` (1 = чоловік, 2 = жінка). Ці змінні є фундаментальними для будь-якого аналізу ризиків здоров'я, оскільки демографічні фактори тісно пов'язані з різними захворюваннями та впливають на інтерпретацію інших показників.

**Антропометрія** представлена індексом маси тіла `BMXBMI` (Body Mass Index), який є ключовим показником для оцінки фізичного стану здоров'я та виявлення факторів ризику, пов'язаних з ожирінням.

**Артеріальний тиск** включає систолічний артеріальний тиск `BPXSY1` та діастолічний артеріальний тиск `BPXDI1`. Ці показники є важливими маркерами серцево-судинного здоров'я та пов'язані з ризиками різних захворювань.

**Лабораторні показники** представлені рівнем глюкози в крові `LBXGLU` та загальним холестерином `LBXTC`. Ці показники надають об'єктивну інформацію про метаболічний стан організму та дозволяють виявляти ранні ознаки захворювань, зокрема діабету та серцево-судинних захворювань.

**Статус захворювань** представлений діагностованим діабетом `DIQ010` з опитувальника, який надає інформацію про наявність захворювання на момент обстеження.

**Цільові змінні** створені в процесі ETL та включають наявність ожиріння `obesity_present` (1 = так, якщо BMI ≥ 30; 0 = ні) та наявність діабету `diabetes_present` (1 = так, якщо DIQ010 == 1; 0 = ні). Ці змінні використовуються для навчання моделей бінарної класифікації, які прогнозують ризик ожиріння та діабету на основі інших показників здоров'я.

Характеристика даних показує, що датасет має достатній обсяг для проведення надійного аналізу та навчання моделей. Формат даних — CSV з кодуванням UTF-8, що забезпечує сумісність з різними інструментами та платформами. Кількість стовпців обмежена до 10 ключових змінних, що спрощує аналіз та навчання моделей, зберігаючи при цьому всю необхідну інформацію для прогнозування ризиків.

## 4. ETL-процес

ETL (Extract, Transform, Load) — це перший етап магістерської роботи, на якому сирі NHANES-таблиці об'єднуються в узгоджений придатний датасет. Саме на цьому етапі формується `health_dataset.csv`, який потім використовується в дослідницькому аналізі даних (EDA) та машинному навчанні (ML) для прогнозування ризиків здоров'я.

Процес ETL починається з **скачування датасету** з платформи Kaggle, де NHANES доступний як набір CSV-файлів. Після завантаження файли розміщуються у директорії `datasets/raw/`, де вони зберігаються у вихідному форматі для подальшої обробки. ETL-скрипти зчитують ці файли з обробкою різних кодувань: спочатку намагається UTF-8, а у разі помилки використовується latin-1 як резервне кодування, що забезпечує коректне зчитування даних незалежно від їхнього походження.

Наступний крок — **об'єднання кількох таблиць** в одну структуровану таблицю. Процес об'єднання виконується послідовно: спочатку об'єднується перша таблиця з другою, потім результат з третьою, і так далі до об'єднання всіх шести таблиць. Злиття виконується за спільним ключем `SEQN` (Sequence Number), який є унікальним ідентифікатором кожного респондента в дослідженні NHANES. Використовується зовнішнє злиття (outer join), що означає збереження всіх респондентів, навіть якщо у них відсутні дані в деяких таблицях. Це забезпечує повне зіставлення різних модулів NHANES для кожного респондента та зберігає максимальну кількість даних для подальшого аналізу.

Після об'єднання таблиць виконується **вибір необхідних колонок** з об'єднаної таблиці. Логіка полягає в тому, що для EDA та ML потрібні тільки ключові ознаки, а не всі сотні колонок з оригінальних NHANES-таблиць. Основні колонки, які зберігаються, включають демографію (SEQN, RIDAGEYR, RIAGENDR), антропометрію (BMXBMI), артеріальний тиск (BPXSY1, BPXDI1), лабораторні показники (LBXGLU, LBXTC) та статус захворювань (DIQ010). Якщо якась колонка відсутня в об'єднаній таблиці, вона просто пропускається, але процес продовжується з доступними колонками.

**Видалення пропусків** виконується на кількох рівнях для забезпечення якості даних. Спочатку видаляються дублікати за ключем `SEQN`, залишається лише перший запис для кожного унікального респондента. Далі виконується фільтрація рядків з надмірними пропусками: видаляються рядки, у яких більше 50% числових колонок містять пропущені значення. Це означає, що якщо у респондента відсутні дані більш ніж у половині ключових показників, такий запис виключається з датасету. Всі числові колонки конвертуються у тип float з обробкою помилок, де некоректні значення перетворюються на NaN. Окремі пропуски в колонках залишаються для подальшої обробки моделями машинного навчання або імпутації на наступних етапах.

**Обробка некоректних значень** виконується автоматично під час конвертації типів даних. Некоректні числові значення перетворюються на NaN, що дозволяє моделям машинного навчання обробляти їх через pipeline імпутації. Конкретні перевірки на нереалістичні вимірювання (наприклад, дуже високий або від'ємний ІМТ) не виконуються на етапі ETL, але можуть бути додані під час EDA або перед навчанням моделей.

**Нормалізація** даних у традиційному розумінні (масштабування до діапазону 0-1 або стандартизація) не виконується на етапі ETL, оскільки це завдання покладається на pipeline моделей машинного навчання. Однак виконується нормалізація структури даних: змінні зберігають свої оригінальні NHANES-назви (наприклад, RIDAGEYR, BMXBMI, BPXSY1), що дозволяє легко звірятися з оригінальною документацією NHANES та забезпечує прозорість джерела даних.

**Формування фінального файлу health_dataset.csv** виконується на останньому етапі ETL, коли створюються цільові змінні (target variables) на основі бізнес-правил. Змінна `obesity_present` створюється як бінарна змінна, яка дорівнює 1, якщо `BMXBMI >= 30` (критерій ожиріння за WHO), інакше 0. Змінна `diabetes_present` створюється як бінарна змінна, яка дорівнює 1, якщо `DIQ010 == 1` (діагностований діабет згідно з опитувальником), інакше 0. Пропущені значення в цих змінних заповнюються як 0 (False). Після формування цільових змінних фінальний датасет зберігається у файл `datasets/processed/health_dataset.csv` у форматі CSV з кодуванням UTF-8, без індексів рядків.

ETL був необхідний, оскільки сирі дані NHANES представлені у вигляді окремих таблиць з різними структурами та форматами, що ускладнює їх безпосереднє використання для аналізу та навчання моделей. ETL-процес об'єднує ці таблиці в єдину структуровану таблицю, очищає дані від дублікатів та некоректних значень, відбирає релевантні змінні та формує цільові змінні для навчання моделей. Без цього етапу неможливо було б провести надійний аналіз даних або навчити моделі машинного навчання.

Чому саме такий пайплайн був обраний? По-перше, послідовне об'єднання таблиць за ключем `SEQN` забезпечує повне зіставлення даних для кожного респондента, зберігаючи максимальну кількість інформації. По-друге, видалення рядків з надмірними пропусками (понад 50%) забезпечує баланс між збереженням даних та якістю: рядки з невеликою кількістю пропусків залишаються для подальшої обробки моделями, а рядки з критичною кількістю пропусків видаляються як ненадійні. По-третє, збереження оригінальних назв змінних NHANES забезпечує прозорість та можливість звіряння з оригінальною документацією. По-четверте, формування цільових змінних на основі бізнес-правил (BMI ≥ 30 для ожиріння, DIQ010 == 1 для діабету) забезпечує чіткі та інтерпретовані цільові змінні для навчання моделей.

## 5. EDA: дослідницький аналіз даних

EDA (Exploratory Data Analysis) був другим етапом магістерської роботи після ETL, на якому перевірялась якість даних, аналізувались розподіли змінних та зв'язки між ознаками. Результати EDA дозволили сформувати гіпотези про фактори ризику, обґрунтувати вибір ключових ознак для моделювання та визначити підходи до обробки пропущених значень. Ці висновки безпосередньо вплинули на архітектуру моделей машинного навчання та їх продуктивність.

Для EDA використовується готовий оброблений датасет `datasets/processed/health_dataset.csv`, який був створений на етапі ETL. Датасет містить 9770 рядків та 10 колонок, включаючи демографічні змінні (вік, стать), антропометрію (ІМТ), артеріальний тиск (систолічний та діастолічний), лабораторні показники (глюкоза, холестерин), статус захворювань (діагностований діабет) та цільові змінні (наявність ожиріння, наявність діабету).

Основна логіка EDA реалізована у модулі `src/analysis/explore_data.py`, який використовує стандартні бібліотеки Python для аналізу даних та візуалізації: pandas для роботи з датафреймами та обчислення статистики, matplotlib для створення базових графіків, seaborn для побудови складніших візуалізацій (боксплоти, теплокарти) та numpy для математичних обчислень та регресійних ліній. Скрипт виконує наступні основні кроки: завантаження даних, базові описові статистики, аналіз пропущених значень, розрахунок метрик здоров'я, побудова розподілів, кореляційний аналіз та збереження артефактів.

**Що аналізували** — EDA охоплював комплексний аналіз всіх ключових змінних датасету. Аналізувались розподіли числових змінних (вік, ІМТ, артеріальний тиск, глюкоза, холестерин) для розуміння їхньої природи та виявлення аномалій. Досліджувались зв'язки між змінними через кореляційний аналіз та діаграми розсіювання для виявлення залежностей та потенційної мультиколінеарності. Аналізувались цільові змінні (ожиріння, діабет) у зв'язку з іншими показниками для виявлення ключових факторів ризику. Перевірялась якість даних через аналіз пропущених значень та виявлення викидів.

**Які метрики переглядали** — EDA включав широкий спектр метрик для всебічного розуміння даних. **Розподіли** аналізувались через гістограми, які показували форму розподілу, наявність спотворень та концентрацію значень. Для ІМТ спостерігалось правостороннє спотворення, що вказує на наявність значної кількості людей з підвищеною масою тіла. Більшість значень зосереджені в діапазоні 20–30, що відповідає нормальній та надмірній вазі. **Кореляції** аналізувались через кореляційну матрицю та теплокарту, яка показувала взаємозв'язки між усіма числовими ознаками. Виявлено помірні кореляції між артеріальним тиском, ІМТ та холестерином, що вказує на взаємопов'язаність цих показників. Вік корелює з багатьма показниками здоров'я, що підтверджує важливість вікового фактора в оцінці ризиків. Деякі змінні мають слабкий зв'язок, що підтверджує їх незалежність та корисність для моделювання. **Heatmap** кореляційної матриці є ключовою візуалізацією для розуміння взаємозв'язків між змінними та уникнення проблеми мультиколінеарності при моделюванні.

**Як це вплинуло на вибір ознак** — результати EDA безпосередньо вплинули на вибір ключових ознак для моделювання. На основі аналізу кореляцій, розподілів та зв'язків між змінними були відібрані наступні ознаки, які використовуються в моделях для прогнозування ожиріння та діабету: вік (RIDAGEYR) — важлива ознака, оскільки старший вік асоціюється з вищими ризиками обох захворювань; стать (RIAGENDR) — використовується для врахування статевих відмінностей у розподілі ризиків; індекс маси тіла (BMXBMI) — ключова ознака для прогнозування ожиріння та пов'язаних з ним ризиків; артеріальний тиск (BPXSY1, BPXDI1) — важливі показники, які корелюють з обома цільовими змінними; холестерин (LBXTC) — показник, який демонструє кореляцію з ІМТ та загальним станом здоров'я; глюкоза (LBXGLU) — критична ознака для прогнозування діабету, додається до моделей, якщо доступна в датасеті.

Деякі ознаки були відкинуті або обмежені через надто багато пропусків (наприклад, артеріальний тиск має 26.6% пропусків, що потребує спеціальної обробки під час навчання моделей), дублювання інформації (деякі змінні можуть бути високо корельовані між собою, тому для уникнення мультиколінеарності обираються найбільш інформативні) та слабкий зв'язок із цільовими змінними (змінні, які не демонструють значущого зв'язку з ожирінням або діабетом, виключаються з моделей).

**Які особливості даних були виявлені** — EDA виявив кілька важливих особливостей даних, які вплинули на подальшу обробку та моделювання. Найбільше пропусків спостерігається в артеріальному тиску (близько 26.6%) та холестерині (близько 22%), що впливає на подальшу обробку даних та потребує спеціальних методів імпутації. Розподіл ІМТ має правостороннє спотворення, що вказує на наявність значної кількості людей з підвищеною масою тіла. Відсоток людей з ожирінням становить 24.02% (2347 осіб), а відсоток людей з діабетом — 7.54% (737 осіб), що вказує на класифікаційну задачу з дисбалансом класів. Люди з ожирінням мають вищий середній вік (45.67 vs 28.72), вищий ІМТ (36.13 vs 22.02) та вищий холестерин (188.34 vs 175.89), що підтверджує зв'язок між цими факторами. Старший вік пов'язаний із значно вищим ризиком діабету, що є очікуваним результатом з медичної точки зору.

**Які інсайти отримані** — EDA надав кілька ключових інсайтів, які сформували підхід до моделювання та інтерпретації результатів. По-перше, виявлено, що вік є критичним фактором ризику для обох захворювань, що обґрунтовує його включення в усі моделі. По-друге, ІМТ тісно пов'язаний з ожирінням та іншими факторами ризику, що робить його ключовою ознакою для моделювання. По-третє, артеріальний тиск та холестерин демонструють помірні кореляції з цільовими змінними, що підтверджує їх важливість для прогнозування ризиків. По-четверте, наявність дисбалансу класів (24% ожиріння, 7.5% діабету) потребує спеціальних методів обробки при навчанні моделей, таких як зважування класів або використання метрик, які враховують дисбаланс. По-п'яте, висока кількість пропусків у деяких змінних потребує надійних методів імпутації, які не спотворюють розподіли даних.

**Чому EDA важливий етап перед ML** — EDA є критично важливим етапом перед машинним навчанням, оскільки він дозволяє зрозуміти природу даних, виявити проблеми та сформувати обґрунтовані рішення щодо обробки даних та вибору моделей. Без EDA неможливо правильно обробити пропущені значення, оскільки невідомо, які методи імпутації будуть найбільш доречними. Без EDA неможливо вибрати оптимальні ознаки для моделювання, оскільки невідомо, які змінні мають найбільший вплив на цільові змінні. Без EDA неможливо виявити проблеми з даними (викиди, аномалії, дисбаланс класів), які можуть призвести до некоректних результатів моделювання. Без EDA неможливо обґрунтувати вибір архітектури моделей та методів обробки даних, що робить процес моделювання менш прозорим та менш надійним.

Результати EDA (графіки та текстовий звіт) зберігаються у директорії `artifacts/eda/` та використовуються у пояснювальній записці магістерської роботи, частково в PDF-звітах, а також інтегровані у веб-інтерфейс проєкту. На сторінці діаграм веб-застосунку відображаються ключові візуалізації з EDA, що дозволяє користувачам краще розуміти розподіли показників здоров'я та їх взаємозв'язки. Це робить систему більш прозорою та зрозумілою для кінцевих користувачів, які можуть бачити, на основі яких даних та аналізів формуються прогнози ризиків.

# Частина 2: ML-моделі та API

## 6. ML-Моделі (Machine Learning)

### 6.1. Мета ML у проєкті

Машинне навчання в проєкті HealthRisk.AI виконує роль інтелектуального ядра системи, яке трансформує медичні параметри користувачів в об'єктивні оцінки ризиків здоров'я. Основна мета ML-компонента полягає в тому, щоб надати точні та надійні прогнози ризиків розвитку захворювань на основі обмеженого набору медичних показників, які користувач може легко надати через веб-інтерфейс.

**Які ризики прогнозуються** — система навчає та використовує моделі для прогнозування двох ключових ризиків здоров'я: ожиріння та діабету. Ожиріння визначається як наявність індексу маси тіла (ІМТ) рівного або вище 30, що відповідає критеріям Всесвітньої організації охорони здоров'я. Діабет визначається як діагностований діабет згідно з опитувальником NHANES. Обидва ризики є бінарними змінними (наявність або відсутність), що робить задачу класифікацією з двома класами.

**Чому ці показники** — вибір саме цих двох ризиків обумовлений кількома факторами. По-перше, обидва захворювання є широко поширеними та мають значний вплив на здоров'я населення, що робить їх актуальними для оцінки. По-друге, обидва ризики мають чіткі медичні критерії визначення, що дозволяє точно формувати цільові змінні для навчання моделей. По-третє, обидва ризики пов'язані з факторами, які можна легко виміряти або отримати від користувача (вік, стать, ІМТ, артеріальний тиск, лабораторні показники), що робить систему практичною для використання. По-четверте, обидва ризики мають достатню кількість позитивних випадків у датасеті NHANES для навчання надійних моделей (24% ожиріння, 7.5% діабету).

**Які змінні впливають** — моделі використовують наступний набір ознак для прогнозування ризиків: вік особи (RIDAGEYR) — важлива ознака, оскільки старший вік асоціюється з вищими ризиками обох захворювань; стать (RIAGENDR) — використовується для врахування статевих відмінностей у розподілі ризиків; індекс маси тіла (BMXBMI) — ключова ознака для прогнозування ожиріння та пов'язаних з ним ризиків; систолічний артеріальний тиск (BPXSY1) та діастолічний артеріальний тиск (BPXDI1) — важливі показники, які корелюють з обома цільовими змінними; загальний холестерин (LBXTC) — показник, який демонструє кореляцію з ІМТ та загальним станом здоров'я; рівень глюкози в крові (LBXGLU) — критична ознака для прогнозування діабету, додається до моделей, якщо доступна в датасеті. Ці ознаки були відібрані на основі результатів EDA, які показали їх значущість та кореляцію з цільовими змінними.

### 6.2. Підготовка даних для моделей

Підготовка даних для навчання моделей є критично важливим етапом, який забезпечує якість та надійність прогнозів. Процес підготовки включає кілька ключових кроків, кожен з яких виконує специфічну роль у забезпеченні готовності даних для машинного навчання.

**Normalization** — нормалізація даних виконується через StandardScaler, який перетворює числові ознаки до стандартного розподілу з середнім значенням 0 та стандартним відхиленням 1. Це критично важливо для моделей, які чутливі до масштабу даних, таких як логістична регресія, SVM та нейромережі. Нормалізація забезпечує, що всі ознаки мають однаковий вплив на модель незалежно від їхніх оригінальних діапазонів значень. Наприклад, вік (діапазон 0-100) та холестерин (діапазон 100-300) після нормалізації мають однаковий масштаб, що дозволяє моделі правильно оцінити їхню важливість. Нормалізація виконується на тренувальній вибірці, після чого параметри нормалізації (середнє та стандартне відхилення) зберігаються та застосовуються до тестової вибірки та нових даних під час інференсу.

**Train-test split** — датасет розділяється на тренувальну та тестову вибірки у співвідношенні 80/20, що забезпечує достатню кількість даних для навчання та надійну оцінку продуктивності моделей. Розділення виконується зі стратифікацією за цільовою змінною, що означає, що пропорції позитивних та негативних класів зберігаються в обох вибірках. Це критично важливо для незбалансованих датасетів, де позитивні випадки становлять меншість (7.5% для діабету, 24% для ожиріння). Стратифікація забезпечує, що модель навчається та тестується на репрезентативних вибірках, що покращує надійність оцінки метрик. Використовується `random_state=42` для забезпечення відтворюваності результатів, що дозволяє порівнювати різні моделі на однакових вибірках.

**Вибір ознак** — відбір ознак виконується на основі результатів EDA, які показали значущість та кореляцію з цільовими змінними. Всі моделі використовують однаковий набір ознак для забезпечення порівнянності результатів. Ознаки відібрані на основі кількох критеріїв: наявність значущого зв'язку з цільовими змінними (виявлено через кореляційний аналіз та візуалізації), доступність для користувачів (всі ознаки можуть бути легко виміряні або отримані), відсутність надмірної кореляції між ознаками (для уникнення мультиколінеарності), достатня кількість доступних даних (ознаки з надто багатьма пропусками виключаються або обробляються спеціально).

**Чому саме такі фактори** — вибір саме цих факторів обґрунтований медичною наукою та результатами EDA. Вік є універсальним фактором ризику для більшості захворювань, включаючи діабет та ожиріння, що підтверджено численними дослідженнями. Стать враховує статеві відмінності у розподілі ризиків, які спостерігаються в реальних даних. ІМТ є прямим показником ожиріння та тісно пов'язаний з метаболічними ризиками, включаючи діабет. Артеріальний тиск є маркером серцево-судинного здоров'я та корелює з обома цільовими змінними. Холестерин є показником метаболічного стану та пов'язаний з ризиками діабету та серцево-судинних захворювань. Глюкоза є прямим маркером діабету та критично важлива для прогнозування цього ризику. Результати EDA підтвердили значущість цих факторів через кореляційний аналіз та візуалізації, що обґрунтувало їх включення в моделі.

**Проблеми дисбалансу** — датасет має дисбаланс класів, де позитивні випадки становлять меншість (7.5% для діабету, 24% для ожиріння). Це створює проблему для моделей, які можуть навчитися завжди передбачати більшість клас, що призводить до високої точності, але низької чутливості до позитивних випадків. Для вирішення цієї проблеми використовуються кілька підходів: стратифікація при розділенні на тренувальну та тестову вибірки для забезпечення репрезентативності, використання метрик, які враховують дисбаланс (ROC-AUC, Average Precision), зважування класів у деяких моделях для збільшення важливості позитивних випадків, калібрування моделей для покращення якості ймовірностей. Дисбаланс класів враховується при інтерпретації результатів та виборі порогів для категорій ризику.

### 6.3. Моделі, які використовувались

У проєкті навчаються та оцінюються шість різних моделей машинного навчання для кожної цільової змінної, що дозволяє порівняти їх продуктивність та обрати найкращу. Кожна модель має свої переваги та недоліки, які роблять її підходящою для різних сценаріїв використання.

**Логістична регресія** — це лінійна модель класифікації, яка моделює ймовірність позитивного класу через логістичну функцію. Модель використовує лінійну комбінацію ознак з вагами, які навчаються для мінімізації функції втрат. Логістична регресія є однією з найпростіших та найінтерпретованіших моделей, що робить її ідеальною для медичних застосунків, де важливо розуміти, як модель приймає рішення.

**Для чого використовується** — логістична регресія використовується як базова модель для порівняння з більш складними алгоритмами та як основний інструмент для інтерпретації результатів. Модель дозволяє легко зрозуміти вплив кожної ознаки на прогноз через коефіцієнти, які показують, як зміна ознаки впливає на логарифм шансів позитивного класу.

**Переваги** — логістична регресія має кілька ключових переваг: висока інтерпретованість — коефіцієнти моделі можна легко інтерпретувати як вплив ознак на ризик, швидкість навчання та інференсу — модель навчається та передбачає дуже швидко, що важливо для реального використання, стабільність — модель не схильна до перенавчання на невеликих датасетах, простота — модель не має гіперпараметрів, які потребують налаштування, лінійність — модель припускає лінійні зв'язки між ознаками та цільовою змінною, що часто є достатнім для багатьох медичних задач.

**Чому вона стала основною** — логістична регресія часто стає основною моделлю для медичних застосунків через свою інтерпретованість та надійність. У проєкті вона може бути обрана як champion-модель, якщо показує найкращі результати за метриками ROC-AUC та Average Precision. Навіть якщо інші моделі показують трохи кращі результати, логістична регресія може бути обрана через свою простоту та зрозумілість для користувачів та медичних фахівців.

**Як інтерпретується результат** — результат логістичної регресії інтерпретується через ймовірність позитивного класу (0-1), яка показує ризик розвитку захворювання. Коефіцієнти моделі показують вплив кожної ознаки: позитивний коефіцієнт означає, що збільшення ознаки збільшує ризик, негативний — зменшує. Величина коефіцієнта показує силу впливу. Наприклад, якщо коефіцієнт для віку дорівнює 0.05, це означає, що збільшення віку на 1 рік збільшує логарифм шансів на 0.05, що відповідає приблизно 5% збільшенню ризику.

**Random Forest** — це ансамблева модель, яка об'єднує прогнози множини дерев рішень для отримання фінального результату. Кожне дерево навчається на випадковій підвибірці даних та випадковому підмножині ознак, що забезпечує різноманітність дерев та зменшує перенавчання. Фінальний прогноз обчислюється як середнє або мажоритарне голосування всіх дерев.

**Переваги** — Random Forest має кілька переваг: висока точність — модель часто показує кращі результати, ніж прості алгоритми, завдяки комбінації множини дерев, стійкість до викидів — модель менш чутлива до аномальних значень, ніж лінійні моделі, автоматичний відбір ознак — модель може використовувати велику кількість ознак та автоматично визначати найважливіші, обробка нелінійних зв'язків — модель може виявляти складні взаємодії між ознаками, вбудована оцінка важливості ознак — модель автоматично обчислює важливість кожної ознаки.

**Складність** — Random Forest є більш складною моделлю, ніж логістична регресія, що створює кілька викликів: менша інтерпретованість — важко зрозуміти, як модель приймає рішення через комбінацію множини дерев, більша складність налаштування — модель має гіперпараметри (кількість дерев, глибина дерев, мінімальна кількість зразків у листі), які потребують оптимізації, більша вимогливість до ресурсів — модель потребує більше пам'яті та часу для навчання та інференсу, ризик перенавчання — при неправильному налаштуванні модель може перенавчитися на тренувальних даних.

**Чому використовувався як порівняльна модель** — Random Forest використовується як порівняльна модель для оцінки, чи можуть складніші алгоритми покращити результати порівняно з простою логістичною регресією. Якщо Random Forest показує значно кращі результати, це може обґрунтувати використання більш складних моделей. Якщо різниця невелика, логістична регресія може бути обрана через свою простоту та інтерпретованість.

**Gradient Boosting (XGBoost)** — це потужна ансамблева модель, яка послідовно навчає слабкі моделі (зазвичай дерева рішень) для виправлення помилок попередніх моделей. Кожна нова модель фокусується на випадках, які попередні моделі передбачили неправильно, що дозволяє поступово покращувати загальну продуктивність.

**Чому тестувався** — XGBoost тестувався як один з найпотужніших алгоритмів машинного навчання, який часто показує найкращі результати на різних задачах класифікації. Модель має репутацію високої точності та здатності виявляти складні патерни в даних, що робить її привабливою для медичних застосунків, де точність критично важлива.

**Які результати показав** — XGBoost може показати найкращі результати за метриками ROC-AUC та Average Precision серед усіх тестованих моделей, що може зробити його champion-моделлю. Однак модель має високу складність та меншу інтерпретованість, що може бути компромісом між точністю та зрозумілістю. Результати залежать від конкретного датасету та налаштувань моделі.

**Інші моделі** — крім логістичної регресії, Random Forest та XGBoost, у проєкті також тестуються SVC (Support Vector Classifier), KNN (K-Nearest Neighbors) та MLP (Multi-Layer Perceptron, нейромережа). Кожна з цих моделей має свої особливості: SVC використовує ядра для обробки нелінійних зв'язків, KNN базується на подібності з найближчими сусідами, MLP використовує глибоке навчання для виявлення складних патернів. Всі моделі оцінюються за однаковими метриками, що дозволяє об'єктивно порівняти їх продуктивність та обрати найкращу.

### 6.4. Компонування моделей у проєкті

Моделі машинного навчання організовані у проєкті за чіткою структурою, яка забезпечує їх збереження, завантаження та використання в API для реального прогнозування.

**Файли ML-моделей у репозиторії** — всі навчені моделі зберігаються у директорії `artifacts/models/`, яка організована за цільовими змінними та назвами моделей. Структура директорії має вигляд `artifacts/models/{target}/{ModelName}/`, де `target` — це цільова змінна (`diabetes_present` або `obesity_present`), а `ModelName` — назва моделі (наприклад, `LogisticRegression`, `RandomForest`, `XGBoost`). Кожна модель має свою піддиректорію, яка містить файл моделі, метрики, графіки та інші артефакти.

**Де зберігаються pickle файли** — моделі зберігаються у форматі `.joblib` (бібліотека joblib для серіалізації Python-об'єктів), який є оптимізованою версією pickle для великих масивів NumPy. Файли моделей мають назву `model.joblib` та зберігаються у піддиректорії кожної моделі. Калібровані версії чемпіонських моделей зберігаються окремо як `champion_calibrated.joblib` у директорії цільової змінної. Моделі зберігають повний pipeline, який включає препроцесор (імпутацію, стандартизацію, кодування) та навчену модель, що дозволяє використовувати їх безпосередньо для прогнозування без додаткової підготовки даних.

**Як моделі завантажуються у API** — моделі завантажуються через систему реєстрації моделей, яка реалізована у модулі `model_registry.py`. При першому запиті на прогноз модель завантажується з диску у пам'ять за допомогою `joblib.load()`, після чого кешується у словнику `_MODEL_CACHE` для швидкого доступу при наступних запитах. Система віддає перевагу каліброваним моделям, якщо вони доступні, інакше використовує звичайну чемпіонську модель. Кешування забезпечує, що модель завантажується тільки один раз при першому використанні, що значно покращує продуктивність API.

**Структура функцій прогнозування** — функції прогнозування організовані як pipeline, який включає кілька кроків: валідація вхідних даних через Pydantic-схему для перевірки типів, діапазонів та обов'язковості полів; конвертація вхідних даних у pandas DataFrame з колонками, що відповідають ознакам моделі; передача DataFrame через pipeline моделі, який автоматично виконує імпутацію пропущених значень, стандартизацію числових ознак та кодування категоріальних; обчислення ймовірності позитивного класу через `pipeline.predict_proba()`; визначення категорії ризику на основі ймовірності (низький, середній, високий); обчислення топ факторів впливу через функцію `calculate_top_factors_simple()`; формування відповіді у форматі JSON для повернення клієнту.

### 6.5. Метрики

Оцінка продуктивності моделей виконується за множиною метрик, кожна з яких оцінює різні аспекти якості прогнозів. Використання кількох метрик забезпечує всебічну оцінку моделей та дозволяє обрати найкращу для конкретного застосування.

**Accuracy** — це найпростіша метрика, яка показує частку правильних прогнозів серед усіх прогнозів. Accuracy обчислюється як відношення кількості правильних прогнозів до загальної кількості прогнозів. Метрика легко інтерпретується та зрозуміла для широкої аудиторії, але має обмеження для незбалансованих датасетів, де модель може досягти високої точності, просто завжди передбачаючи більшість клас. Для датасету з 7.5% позитивних випадків діабету модель може досягти 92.5% точності, просто завжди передбачаючи відсутність діабету, що робить метрику неінформативною.

**ROC-AUC** — це основна метрика для бінарної класифікації, яка показує здатність моделі розрізняти позитивні та негативні класи незалежно від порогу класифікації. ROC-AUC обчислюється як площа під кривою ROC (Receiver Operating Characteristic), яка показує залежність між чутливістю (True Positive Rate) та специфічністю (False Positive Rate) при різних порогах. Значення ROC-AUC коливається від 0 до 1, де 1 означає ідеальну модель, а 0.5 — модель, яка працює не краще за випадкову. ROC-AUC є основною метрикою для вибору champion-моделі, оскільки вона враховує дисбаланс класів та оцінює здатність моделі розрізняти класи на всіх можливих порогах.

**Precision/Recall** — це метрики, які оцінюють якість позитивних прогнозів та здатність моделі виявляти позитивні випадки. Precision (точність) показує частку правильних позитивних прогнозів серед усіх позитивних прогнозів, тобто скільки з передбачених позитивних випадків дійсно є позитивними. Recall (повнота, чутливість) показує частку виявлених позитивних випадків серед усіх реальних позитивних випадків, тобто скільки позитивних випадків модель змогла виявити. Для медичних застосунків часто важливіше мати високий recall, щоб не пропустити реальні випадки захворювань, навіть якщо це призводить до деяких хибно-позитивних результатів.

**Чому саме ці метрики** — вибір саме цих метрик обумовлений специфікою задачі та характеристиками датасету. ROC-AUC обрана як основна метрика через свою здатність оцінювати модель незалежно від порогу класифікації та врахування дисбалансу класів. Average Precision обрана як додаткова метрика для незбалансованих класів, оскільки вона фокусується на якості позитивних прогнозів. Precision та Recall використовуються для детального аналізу якості прогнозів та виявлення слабких місць моделей. F1-score використовується як гармонійне середнє precision та recall для збалансованої оцінки. Brier Score використовується для оцінки калібрування ймовірностей, що критично важливо для медичних застосунків, де точність ймовірностей впливає на прийняття рішень.

**Інтерпретація** — інтерпретація метрик залежить від контексту застосування. Для медичних застосунків високий ROC-AUC (вище 0.8) вважається хорошим результатом, оскільки він показує, що модель значно краща за випадкову. Високий Precision означає, що коли модель передбачає наявність ризику, це дійсно так у більшості випадків, що важливо для уникнення зайвих тривог. Високий Recall означає, що модель виявляє більшість реальних випадків, що важливо для недопущення пропуску захворювань. Баланс між Precision та Recall залежить від конкретного застосування: для скринінгу важливіший Recall, для діагностики — Precision.

**Порівняння моделей** — порівняння моделей виконується за кількома метриками одночасно, що дозволяє обрати найкращу модель для конкретного застосування. Champion-модель обирається на основі найвищого ROC-AUC, а у разі рівності — найвищого Average Precision. Результати всіх моделей зберігаються у `leaderboard.csv`, який містить всі метрики для кожної моделі, що дозволяє порівняти їх продуктивність та зробити обґрунтований вибір. Порівняння також враховує інші фактори, такі як інтерпретованість, швидкість інференсу та складність моделі.

### 6.6. Інтерпретація моделей

Інтерпретація моделей є критично важливою для медичних застосунків, де користувачі та фахівці потребують розуміння того, як модель приймає рішення та які фактори найбільше впливають на прогноз.

**Feature importance** — важливість ознак обчислюється через permutation importance, який показує, наскільки знижується продуктивність моделі при випадковому перемішуванні значень ознаки. Метод працює наступним чином: модель передбачає на вибірці даних та обчислює базову метрику (наприклад, ROC-AUC); значення однієї ознаки випадково перемішуються, а інші залишаються незмінними; модель знову передбачає на модифікованих даних та обчислює метрику; різниця між базовою та модифікованою метрикою показує важливість ознаки. Чим більше знижується метрика при перемішуванні ознаки, тим важливіша ця ознака для моделі. Permutation importance обчислюється для champion-моделі під час навчання та зберігається у `champion_importance.json` для використання в API та веб-інтерфейсі.

**Як робиться факторний аналіз** — факторний аналіз виконується на двох рівнях: глобальний рівень (для всієї моделі) та індивідуальний рівень (для конкретного прогнозу). На глобальному рівні використовується permutation importance для визначення загальної важливості кожної ознаки для моделі. Ця інформація використовується в ендпоінті `/explain` для пояснення моделі в цілому. На індивідуальному рівні використовується спрощений підхід, який аналізує нормалізовані значення ознак для конкретного користувача та обчислює їх вплив на прогноз. Ця інформація використовується в ендпоінті `/predict` для показу топ факторів, які найбільше впливають на конкретний прогноз користувача.

**Чому деякі фічі важливіші** — важливість ознак залежить від кількох факторів: сила зв'язку з цільовою змінною — ознаки, які мають сильний зв'язок з цільовою змінною, мають більшу важливість; унікальність інформації — ознаки, які надають унікальну інформацію, яку не можна отримати з інших ознак, мають більшу важливість; варіативність — ознаки з великою варіативністю можуть мати більшу важливість, оскільки вони дозволяють краще розрізняти класи; взаємодії — деякі ознаки можуть мати велику важливість через взаємодії з іншими ознаками, навіть якщо індивідуально вони мають слабкий зв'язок. Наприклад, ІМТ може мати велику важливість для прогнозування ожиріння, оскільки він є прямим показником цього стану, а вік може мати велику важливість для діабету через його зв'язок з метаболічними змінами.

**Як це впливає на PDF-звіти та UI** — важливість ознак інтегрована у веб-інтерфейс та PDF-звіти для надання користувачам зрозумілої інформації про фактори ризику. У веб-інтерфейсі топ фактори відображаються після кожного прогнозування у вигляді списку з відсотками впливу, що дозволяє користувачам зрозуміти, які показники найбільше впливають на їхній ризик. У PDF-звітах топ фактори включаються як окремий розділ з детальним описом впливу кожного фактора, що дозволяє користувачам зберегти та проаналізувати цю інформацію. Назви ознак перекладаються на зрозумілі користувачу терміни (наприклад, `RIDAGEYR` → "Вік", `BMXBMI` → "ІМТ"), що робить інформацію доступною для широкої аудиторії. Вплив показується у відсотках або нормалізованих значеннях, що дозволяє легко порівняти важливість різних факторів. Фактори сортуються за спаданням впливу, що дозволяє користувачам швидко ідентифікувати найважливіші фактори ризику.

## 7. API

### 7.1. Концепція API

API (Application Programming Interface) проєкту HealthRisk.AI є центральним шаром взаємодії між фронтендом, ML-моделями, базою даних та системою прогнозування ризиків здоров'я. API забезпечує структуровану передачу даних, обробку запитів та повернення результатів у стандартизованому форматі.

**FastAPI як основа** — API побудований на FastAPI, сучасному асинхронному веб-фреймворку для Python, який забезпечує високу продуктивність, автоматичну генерацію OpenAPI-документації та вбудовану валідацію даних через Pydantic. FastAPI базується на Starlette для асинхронної обробки запитів та Pydantic для валідації та серіалізації даних, що робить його ідеальним вибором для ML-застосунків, де потрібна швидка обробка запитів та надійна валідація вхідних даних.

**Чому цей фреймворк** — FastAPI обрано для проєкту через кілька ключових переваг: висока продуктивність — асинхронна обробка запитів забезпечує швидкий відгук навіть при високому навантаженні; автоматична документація — OpenAPI-схема генерується автоматично, що спрощує розробку та тестування; типобезпека — Pydantic забезпечує автоматичну валідацію типів та значень, що зменшує кількість помилок; простота розробки — мінімальний boilerplate код та інтуїтивний синтаксис спрощують створення ендпоінтів; інтеграція з ML — легка інтеграція з бібліотеками машинного навчання та можливість використання синхронних функцій для ML-операцій.

**Модель request/response** — API використовує стандартну REST модель, де клієнт надсилає HTTP-запит з даними у форматі JSON, а сервер обробляє запит та повертає відповідь також у форматі JSON. Всі запити валідуються через Pydantic-схеми, які перевіряють наявність обов'язкових полів, типи даних та діапазони значень перед обробкою. Всі відповіді також структуровані через Pydantic-схеми, що забезпечує консистентність та передбачуваність формату даних.

**Формат JSON** — всі дані передаються у форматі JSON, що забезпечує сумісність з різними клієнтами та платформами. JSON є стандартним форматом для REST API та підтримується всіма сучасними мовами програмування та фреймворками. Структура JSON визначається через Pydantic-схеми, які автоматично серіалізують Python-об'єкти у JSON та десеріалізують JSON у Python-об'єкти, що спрощує роботу з даними.

**Продуктивність** — API оптимізований для високої продуктивності через кілька механізмів: кешування моделей — моделі завантажуються один раз та зберігаються в пам'яті для швидкого доступу; асинхронна обробка — FastAPI використовує асинхронну обробку запитів, що дозволяє обробляти кілька запитів одночасно; оптимізація запитів до БД — використання індексів та ефективних SQL-запитів забезпечує швидкий доступ до даних; мінімальна обробка — дані обробляються тільки необхідним чином без зайвих перетворень; локальне виконання — всі компоненти (API, БД, ML-моделі) працюють локально, що зменшує мережеві затримки.

### 7.2. Головні групи ендпоінтів

API організовано за функціональними групами ендпоінтів, кожна з яких виконує конкретні завдання та забезпечує специфічну функціональність системи.

**`/predict` — отримання прогнозу** — це основний ендпоінт системи, який приймає параметри пацієнта (вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин) та цільову змінну (діабет або ожиріння), завантажує відповідну ML-модель, виконує інференс та повертає ймовірність ризику, категорію ризику (низький, помірний, високий), топ фактори впливу та метадані моделі. Ендпоінт підтримує опційну автентифікацію — якщо користувач автентифікований, прогноз автоматично зберігається в історії для подальшого аналізу. Ендпоінт валідує вхідні дані через Pydantic-схему, обробляє пропущені значення через pipeline моделі та обчислює топ фактори впливу для інтерпретації результату.

**`/auth/*` — реєстрація, логін, токени** — група ендпоінтів для аутентифікації та управління користувачами включає `/auth/register` для реєстрації нового користувача з валідацією email, пароля та обов'язкових полів профілю; `/auth/login` для входу користувача з поверненням JWT-токена та профілю; `/auth/me` для отримання профілю поточного автентифікованого користувача; `/auth/update-profile` для оновлення профілю користувача (ім'я, прізвище, дата народження, стать, аватар); `/auth/change-password` для зміни пароля з перевіркою поточного пароля; `/auth/forgot-password` для ініціалізації процесу відновлення пароля через email-токен; `/auth/reset-password` для встановлення нового пароля через токен відновлення. Всі ендпоінти використовують хешування паролів через bcrypt для безпеки та валідацію даних через Pydantic-схеми.

**`/users/*` — робота з користувачами** — ендпоінти для управління користувачами включають `/users/history` для отримання історії прогнозів користувача з можливістю фільтрації та пагінації; `/users/history/stats` для статистики історії прогнозів для побудови діаграм (розподіл по цілям, категоріям ризику, моделям, часова серія); `/users/history/{id}` для видалення конкретного прогнозу з історії; `/users/history/clear` для очищення всієї історії прогнозів користувача; `/users/avatar` для завантаження аватару користувача з валідацією формату та розміру. Всі ендпоінти вимагають автентифікації та перевіряють належність ресурсів користувачу.

**`/chats/*` — чат і AI-асистент** — ендпоінти для системи чатів між користувачами включають `/api/chats` для отримання списку всіх чатів користувача з інформацією про останнє повідомлення та кількість непрочитаних; `/api/chats/{chat_uuid}` для отримання детальної інформації про конкретний чат з усіма повідомленнями; `/api/chats` (POST) для створення нового чату або отримання існуючого між двома користувачами; `/api/chats/{chat_uuid}/messages` (POST) для відправки повідомлення в чат; `/api/chats/{chat_uuid}/read` (POST) для позначення всіх повідомлень у чаті як прочитаних; `/api/chats/{chat_uuid}` (DELETE) для видалення чату та всіх його повідомлень; `/api/chats/{chat_uuid}/pin` (PATCH) для закріплення або відкріплення чату; `/api/chats/reorder` (PATCH) для зміни порядку чатів у списку; `/api/chats/users` для отримання списку всіх активних користувачів для створення чатів; `/api/chats/unread-count` для отримання загальної кількості непрочитаних повідомлень. Всі ендпоінти перевіряють блокування користувачів та доступ до ресурсів.

**`/reports/*` — генерація PDF** — API не має спеціальних ендпоінтів для генерації PDF, оскільки PDF генерується на фронтенді. Однак API надає дані для генерації звітів через ендпоінти `/users/history` для отримання історії прогнозів, `/users/history/stats` для статистики для діаграм та `/predict` для результатів прогнозування. Фронтенд використовує ці дані для генерації PDF-звітів через jsPDF та Chart.js.

**`/api-status/*` — статуси системи** — ендпоінти для моніторингу стану системи включають `/health` для перевірки стану API, повертає список доступних маршрутів та версію сервісу; `/system/database/stats` для отримання статистики бази даних, включаючи кількість записів у кожній таблиці, розмір БД та активність за останні 7 днів; `/assistant/health` для перевірки статусу Ollama сервера з вимірюванням латентності. Всі ендпоінти не вимагають автентифікації та використовуються для моніторингу доступності компонентів системи.

**`/history/*` — історія прогнозів** — ендпоінти для роботи з історією прогнозів включають `/users/history` для отримання списку всіх збережених прогнозів користувача з можливістю фільтрації та пагінації; `/users/history/stats` для статистики історії прогнозів для побудови діаграм; `/users/history/{id}` для видалення конкретного прогнозу з історії; `/users/history/clear` для очищення всієї історії прогнозів користувача. Всі ендпоінти вимагають автентифікації та перевіряють належність ресурсів користувачу.

### 7.3. Перевірка токенів і аутентифікація

Система аутентифікації API побудована на JWT (JSON Web Tokens) та забезпечує безпечний доступ до захищених ресурсів через механізм токенів.

**JWT** — JSON Web Tokens є стандартом для безпечної передачі інформації між сторонами у форматі JSON. Токени містять закодовану інформацію про користувача (email, час закінчення дії) та підписані секретним ключем для забезпечення цілісності. JWT використовується для автентифікації користувачів без необхідності зберігати стан сесії на сервері, що робить API stateless та масштабованим.

**Access token** — це основний токен для автентифікації, який видається після успішного входу або реєстрації. Токен містить email користувача та час закінчення дії (за замовчуванням 60 хвилин) та підписується секретним ключем через алгоритм HS256. Токен передається у заголовку `Authorization` у форматі `Bearer <token>` при кожному запиті до захищених ендпоінтів. API перевіряє валідність токена, розшифровує його та завантажує користувача з БД для подальшої обробки запиту.

**Refresh token** — наразі не реалізований у проєкті, але може бути доданий для продовження сесії без повторного входу. Refresh токени мають більший термін дії (наприклад, 7 днів) та зберігаються в БД для можливості відкликання. Коли access token закінчується, клієнт може використати refresh token для отримання нового access token без необхідності повторного входу.

**Чому така схема** — вибір JWT-схеми обумовлений кількома факторами: stateless — API не зберігає стан сесії, що робить його масштабованим та легким для розгортання; безпека — токени підписані секретним ключем, що забезпечує їх цілісність та автентичність; простота — токени легко передаються через HTTP-заголовки та не потребують складних механізмів зберігання; масштабованість — токени можуть бути перевірені на будь-якому сервері без доступу до БД, що дозволяє горизонтально масштабувати API.

**Як frontend використовує токени** — фронтенд зберігає JWT-токен у LocalStorage під ключем `hr_auth_token` після успішного входу або реєстрації. Токен автоматично додається до всіх API-запитів у заголовку `Authorization` у форматі `Bearer <token>`. Фронтенд перевіряє наявність токена при завантаженні сторінки та автоматично перенаправляє на сторінку входу, якщо токен відсутній або невалідний. При отриманні помилки 401 (неавторизований) фронтенд автоматично очищає токен та перенаправляє користувача на сторінку входу.

**Як захищені маршрути обробляються на API** — захищені маршрути використовують dependency injection через `Depends(require_current_user)`, який автоматично витягує токен з заголовка `Authorization`, перевіряє його валідність, розшифровує та завантажує користувача з БД. Якщо токен невалідний або користувач не знайдений, функція викидає HTTPException зі статусом 401, що призводить до повернення помилки клієнту. Якщо токен валідний, користувач передається у функцію ендпоінта як параметр, що дозволяє використовувати його для обробки запиту та перевірки доступу до ресурсів.

### 7.4. Як API взаємодіє з ML-моделями

API інтегрується з ML-моделями через систему реєстрації моделей, яка забезпечує їх завантаження, кешування та використання для інференсу.

**Як модель завантажується у пам'ять** — моделі завантажуються через функції `load_champion()` та `load_model()` у модулі `model_registry.py`. При першому запиті на прогноз модель завантажується з диску у пам'ять за допомогою `joblib.load()`, який десеріалізує збережений pipeline (препроцесор + модель) з файлу `.joblib`. Після завантаження модель зберігається у словнику `_MODEL_CACHE` для швидкого доступу при наступних запитах. Система віддає перевагу каліброваним моделям (`champion_calibrated.joblib`), якщо вони доступні, інакше використовує звичайну чемпіонську модель.

**Як вона використовується при кожному запиті** — при кожному запиті на прогноз API виконує наступні кроки: отримує вхідні дані користувача через Pydantic-схему `PredictRequest`; валідує дані (типи, діапазони, обов'язковість полів); завантажує модель через `load_champion()` або `load_model()` (з кешу, якщо вже завантажена); конвертує вхідні дані у pandas DataFrame з колонками, що відповідають ознакам моделі; передає DataFrame через pipeline моделі, який автоматично виконує імпутацію пропущених значень, стандартизацію числових ознак та кодування категоріальних; обчислює ймовірність позитивного класу через `pipeline.predict_proba()`; визначає категорію ризику на основі ймовірності; обчислює топ фактори впливу; формує відповідь у форматі JSON та повертає клієнту.

**Чому не можна завантажувати при кожному запиті** — завантаження моделі при кожному запиті було б неефективним через кілька причин: час завантаження — завантаження моделі з диску займає кілька секунд, що робить API повільним та непридатним для реального використання; використання пам'яті — повторне завантаження моделі призводить до дублювання даних у пам'яті, що збільшує використання ресурсів; навантаження на диск — часті операції читання з диску створюють додаткове навантаження на систему та зменшують продуктивність; нестабільність — завантаження моделі при кожному запиті може призвести до нестабільності через можливі помилки читання з диску. Кешування моделей у пам'яті забезпечує швидкий доступ (мілісекунди замість секунд) та стабільність роботи API.

**Робота з FeatureImpact** — обчислення топ факторів впливу виконується через функцію `calculate_top_factors_simple()`, яка аналізує нормалізовані значення ознак для конкретного користувача та обчислює їх вплив на прогноз. Функція використовує нормалізовані абсолютні значення ознак як проксі для впливу, оскільки точне обчислення впливу для складних моделей (наприклад, Random Forest, XGBoost) потребує значно більше обчислень. Фактори ранжуються за абсолютним значенням впливу та повертаються як топ-5 найважливіших. Для детального пояснення моделі використовується ендпоінт `/explain`, який обчислює permutation importance на вибірці з датасету для глобального пояснення моделі.

**Алгоритм повернення JSON-відповіді** — формування JSON-відповіді виконується автоматично через Pydantic-схему `PredictResponse`, яка серіалізує дані у JSON-формат. Відповідь включає поля `target` (цільова змінна), `probability` (ймовірність від 0 до 1), `risk_bucket` (категорія ризику: low, medium, high), `model_name` (назва моделі), `version` (версія моделі), `is_calibrated` (чи використовується калібрована модель), `top_factors` (список факторів з полями `feature` та `impact`), `note` (примітка про методику розрахунку). Ймовірність обмежується діапазоном (0.0001, 0.9999) для захисту від екстремальних значень та стабільності категорій ризику. Якщо користувач автентифікований, результат також зберігається в історії прогнозів через `save_history_entry()`.

### 7.5. Обробка помилок

Обробка помилок у API забезпечує надійність системи та надає користувачам зрозумілі повідомлення про проблеми.

**Перевірка введених даних** — всі вхідні дані валідуються через Pydantic-схеми, які перевіряють наявність обов'язкових полів, типи даних, діапазони значень та формати. При помилках валідації Pydantic автоматично генерує детальні повідомлення про помилки, які включають інформацію про поле, тип помилки та очікуване значення. Валідація виконується автоматично при отриманні запиту, що забезпечує, що тільки валідні дані передаються до обробки.

**Обробка 400, 401, 422** — API використовує стандартні HTTP статус-коди для індикації різних типів помилок: 400 (Bad Request) — невалідний запит, наприклад, відсутні обов'язкові поля або некоректні типи даних; 401 (Unauthorized) — неавторизований доступ, наприклад, відсутній або невалідний JWT-токен; 422 (Unprocessable Entity) — помилка валідації даних, наприклад, значення поза дозволеним діапазоном або некоректний формат. Всі помилки повертаються у форматі JSON з полем `detail`, яке містить детальне опис помилки для зручності обробки на фронтенді.

**Валідація полів** — валідація полів виконується на кількох рівнях: рівень Pydantic — автоматична валідація типів, діапазонів та обов'язковості полів через Pydantic-схеми; рівень бізнес-логіки — додаткова валідація специфічних правил, наприклад, перевірка унікальності email при реєстрації або перевірка належності ресурсів користувачу; рівень БД — перевірка обмежень БД, наприклад, унікальність ключів або foreign key constraints. Багаторівнева валідація забезпечує надійність системи та запобігає обробці некоректних даних.

**Стандартизовані помилки** — всі помилки повертаються у стандартизованому форматі JSON з полями `detail` (детальний опис помилки) та опційними полями для додаткової інформації. Формат помилок узгоджений по всьому API, що спрощує обробку на фронтенді та забезпечує передбачуваність поведінки. Помилки також логуються на сервері для діагностики та моніторингу проблем.

**Валідація через Pydantic** — Pydantic забезпечує автоматичну валідацію даних через визначення схем, які описують очікувану структуру та типи даних. Схеми автоматично перевіряють типи (int, float, str, bool), діапазони значень (наприклад, вік 0-120, ІМТ 10-60), обов'язковість полів (required vs optional), формати (наприклад, email, UUID), та валідність значень (наприклад, enum values). При помилках валідації Pydantic автоматично генерує детальні повідомлення про помилки, які включають інформацію про поле, тип помилки та очікуване значення, що спрощує діагностику проблем на стороні клієнта.

### 7.6. PDF-звіти

Генерація PDF-звітів у проєкті реалізована переважно на фронтенді, а API забезпечує передачу необхідних даних у форматі JSON.

**Як API взаємодіє/не взаємодіє з PDF** — API не генерує PDF безпосередньо, а надає дані через стандартні ендпоінти у форматі JSON. API не має спеціальних ендпоінтів для генерації PDF, оскільки вся логіка форматування та візуалізації знаходиться на клієнті. API забезпечує консистентність даних через Pydantic-схеми, але не визначає формат звіту, що дає фронтенду гнучкість у виборі способу відображення даних.

**Чому PDF на фронтенді** — генерація PDF на фронтенді має кілька переваг: зменшення навантаження на сервер — генерація PDF виконується на клієнті, що зменшує навантаження на сервер та дозволяє обробляти більше запитів; швидкість — генерація PDF на клієнті забезпечує швидкий відгук без необхідності очікування обробки на сервері; гнучкість — фронтенд може легко змінювати формат звітів без змін на сервері; масштабованість — генерація PDF на клієнті не обмежує кількість одночасних запитів на генерацію звітів. Недоліком є залежність від можливостей браузера та необхідність завантаження додаткових бібліотек на клієнті.

**Як дані передаються** — дані для генерації PDF передаються через стандартні API ендпоінти у форматі JSON. Фронтенд робить запити до `/users/history` для отримання історії прогнозів, `/users/history/stats` для статистики для діаграм та `/predict` для результатів прогнозування. Всі відповіді повертаються у форматі JSON з структурованими даними, що дозволяє фронтенду легко обробляти їх для генерації звітів. API не виконує серверного рендерингу — вся логіка форматування та візуалізації знаходиться на клієнті.

### 7.7. API для AI-асистента

API інтегрується з локальним Ollama сервером для реалізації AI-асистента здоров'я, який надає персоналізовані рекомендації користувачам.

**Виклики Ollama** — API виконує HTTP POST-запити до локального Ollama сервера (`http://localhost:11434/api/generate`) з використанням бібліотеки `requests`. Запити включають модель (за замовчуванням `llama3`), промпт з інструкціями та контекстом, параметри генерації (temperature, max_tokens) та опційні параметри для контролю поведінки моделі. API не підтримує streaming — всі запити виконуються синхронно з отриманням повної відповіді, що спрощує обробку, але може призводити до затримок при довгих відповідях.

**Обробка контексту** — контекст про стан здоров'я користувача формується на основі останнього прогнозу через функцію `build_health_context()`, яка включає інформацію про цільову змінну (діабет або ожиріння), ймовірність ризику, категорію ризику (низький, середній, високий), топ фактори впливу та вхідні параметри користувача. Контекст формується українською або англійською мовою залежно від параметра `language` у запиті. Контекст додається до системного промпту, який містить інструкції для асистента (не ставити діагнози, не призначати лікування, надавати загальні рекомендації) та забезпечує, що асистент надає корисні та безпечні відповіді.

**Логіка message history** — історія повідомлень зберігається в БД у таблиці `assistantmessage` з полями `user_id`, `role` (user або assistant), `content` (текст повідомлення), `prediction_id` (опційний зв'язок з прогнозом), `created_at` (timestamp). При відправці повідомлення користувача воно зберігається в БД, після чого формується контекст, викликається Ollama, відповідь асистента зберігається в БД та повертається користувачу. Історія повідомлень може бути отримана через ендпоінт `/assistant/history` для відображення на фронтенді та використання в подальших діалогах для забезпечення контексту розмови.

# Частина 3: Frontend та UI/UX

## 8. Frontend (Web Interface)

### 8.1. Загальний огляд

Фронтенд проєкту HealthRisk.AI є центральним інтерфейсом взаємодії користувачів з системою прогнозування ризиків здоров'я. Він реалізований як Single Page Application (SPA) на чистому JavaScript без використання фреймворків, що забезпечує мінімалістичний, автономний та легкий клієнт з повною функціональністю системи.

**Що таке frontend у проєкті** — фронтенд є клієнтською частиною веб-додатку, яка відповідає за відображення інтерфейсу користувача, обробку взаємодії, комунікацію з API та генерацію звітів. Він працює повністю в браузері користувача та не потребує серверного рендерингу, що робить його швидким та масштабованим. Фронтенд інтегрується з усіма компонентами системи: API для отримання даних та виконання операцій, ML-моделями через API для прогнозування ризиків, базою даних через API для збереження історії та профілів, Ollama через API для AI-асистента.

**Які технології використовуються** — фронтенд побудований на нативних веб-технологіях: HTML5 для структури сторінки, CSS3 для стилізації та анімацій, Vanilla JavaScript (ES6+) для логіки та інтерактивності. Додатково використовуються зовнішні бібліотеки: Chart.js для побудови діаграм, jsPDF для генерації PDF-звітів, xlsx-js-style для експорту в Excel, Navigo для маршрутизації, Lucide для іконок. Всі бібліотеки завантажуються з CDN, що спрощує розгортання та оновлення. Власні модулі (i18n.js для локалізації, app.js для основної логіки) завантажуються з сервера та інтегруються з HTML.

**Чому саме vanilla JS + HTML/CSS без фреймворків** — вибір нативних технологій без фреймворків обумовлений кількома факторами: простота розробки — відсутність необхідності налаштування системи збірки (Webpack, Vite) спрощує розробку та тестування; легкість підтримки — код без абстракцій фреймворків легше зрозуміти та модифікувати; швидкість завантаження — відсутність великих бібліотек фреймворків зменшує розмір завантажуваних файлів та прискорює перше завантаження сторінки; повний контроль — розробник має повний контроль над поведінкою додатку без обмежень фреймворків; мінімальні залежності — менша кількість залежностей зменшує ризик конфліктів версій та проблем сумісності; навчальна мета — для магістерського проєкту важливо продемонструвати розуміння основ веб-розробки без покладання на готові рішення.

**Архітектура SPA** — Single Page Application працює через один HTML-файл, який містить всі секції сторінок у прихованому стані. При завантаженні сторінки бекенд завжди повертає один і той самий HTML-файл незалежно від URL, а JavaScript визначає, яку секцію потрібно показати на основі поточного URL. Всі секції присутні в DOM з самого початку, але приховані через CSS-класи та атрибут `hidden`, що дозволяє швидко перемикатися між сторінками без додаткових HTTP-запитів. Перемикання секцій виконується через додавання класу `page--active` та видалення атрибута `hidden` для активної секції та приховування всіх інших.

**Перехоплення роутів без перезавантаження** — навігація між сторінками виконується без перезавантаження сторінки через History API браузера. При кліку на посилання або програмній зміні маршруту JavaScript перехоплює подію, оновлює URL через `history.pushState()` або `history.replaceState()`, активує відповідну секцію та оновлює інтерфейс. При використанні кнопок "Назад" та "Вперед" браузера спрацьовує обробник події `popstate`, який синхронізує стан SPA з URL. Це забезпечує плавну навігацію без затримок перезавантаження та зберігає історію перегляду для користувача.

### 8.2. Структура фронтенду

Фронтенд організований у директорії `src/service/web/` з чітким розділенням відповідальності між файлами та модулями.

**index.html** — це кореневий HTML-файл, який містить структуру всієї сторінки. Він включає всі секції сторінок (форма прогнозування, історія, діаграми, профіль, чати, асистент, API-status тощо) у прихованому стані, sidebar з навігацією, модальні вікна, overlay-и для завантаження та інші UI-компоненти. HTML містить всі необхідні елементи для роботи SPA, включаючи атрибути для локалізації (`data-i18n`), іконки Lucide (`data-lucide`) та структуровані дані для доступу через JavaScript. Всі бібліотеки завантажуються через теги `<script>` у `<head>`, а власні модулі завантажуються з атрибутом `defer` для забезпечення правильного порядку ініціалізації.

**app.js (величезний orchestrator)** — це основний файл логіки SPA, який містить всю бізнес-логіку фронтенду. Файл має приблизно 14667 рядків коду та включає: управління станом (authState для автентифікації, predictionStore для результатів прогнозів, diagramState для діаграм, chatState для чатів, apiStatusState для моніторингу); систему маршрутизації (ROUTE_SECTIONS для мапінгу URL на секції, normalizePath для нормалізації шляхів, showSectionForPath для активації секцій, syncRouteFromLocation для синхронізації з URL); роботу з API (apiFetch для HTTP-запитів, обробка відповідей, валідація даних, обробка помилок); генерацію PDF-звітів (generatePDFReport, експорт діаграм, форматування тексту, підтримка кирилиці); роботу з діаграмами Chart.js (створення, оновлення, експорт); інтеграцію з AI-асистентом (відправка повідомлень, відображення відповідей, збереження історії); обробку форм (валідація, відправка, відображення результатів); всю інтерактивність користувача (кліки, натискання клавіш, зміна тем, перемикання sidebar).

**app.css** — це глобальні стилі для всього додатку, які визначають вигляд всіх компонентів, тем (світла/темна), анімації, адаптивність та типографіку. CSS організований за принципом BEM-подібної методології з використанням модифікаторів та вкладених селекторів. Стилі включають CSS-змінні для тем (кольори, градієнти, тіні, прозорість), нормалізацію браузерних стилів, стилі компонентів (sidebar, forms, charts, modals, tooltips), стилі секцій сторінок, анімації та transitions, адаптивні стилі через media queries та утилітарні класи для спінерів, badges та інших елементів.

**Папки компонентів** — хоча фронтенд не використовує компонентну архітектуру фреймворків, логіка організована функціонально через функції у `app.js`, які відповідають за конкретні компоненти. Компоненти включають форми (форма прогнозування, форма входу, форма реєстрації, форма профілю), діаграми (Chart.js інстанси для різних типів графіків), модальні вікна (підтвердження дій, налаштування, інформація), нотифікації (toast-сповіщення для успіхів, помилок, інформації), sidebar (навігація, перемикання теми, статуси), чати (список чатів, детальний вигляд чату, повідомлення), AI-асистент (інтерфейс чату, історія повідомлень).

**Папки сторінок (page-*)** — всі сторінки реалізовані як секції в HTML з унікальними ID, які відповідають префіксу `page-`. Секції включають `page-form` для форми прогнозування, `page-history` для історії прогнозів, `page-insights` для діаграм та аналітики, `page-profile` для профілю користувача, `page-assistant` для AI-асистента, `page-chats` для системи чатів, `page-report` для звітів, `page-api-status` для моніторингу системи, `page-login` для входу, `page-register` для реєстрації, `page-about` для інформації про систему. Кожна секція містить свою структуру HTML, яка активується через JavaScript при навігації.

**Папка графіків** — діаграми реалізовані через Chart.js та зберігаються у об'єкті `dashboardCharts` для швидкого доступу та управління. Кожна діаграма має унікальний ID (наприклад, `chart-risk-diabetes`, `chart-risk-obesity`, `chart-factors`, `chart-distributions`, `chart-correlations`, `chart-age`, `chart-history`) та створюється через функцію `upsertDashboardChart()`, яка створює новий інстанс Chart.js або оновлює існуючий. Діаграми автоматично оновлюються при зміні даних та експортуються у PDF через конвертацію canvas у зображення.

**Папка PDF** — генерація PDF реалізована через функції у `app.js`, які використовують jsPDF для створення документів. Функції включають `generatePDFReport()` для генерації основного звіту, `renderCoverPage()` для обкладинки, `renderContentPage()` для основного контенту, `exportChartsToPDF()` для експорту діаграм, `ensurePdfFontInitialized()` для завантаження шрифтів кирилиці. PDF генерується повністю на клієнті без завантаження на сервер, що забезпечує швидкість та конфіденційність даних.

**Основна логіка: state management** — управління станом реалізовано через JavaScript-об'єкти без використання спеціалізованих бібліотек. Головні об'єкти стану включають `authState` для автентифікації (token, user, history, initialized), `predictionStore` для результатів прогнозів (зберігається за ключами), `dashboardCharts` для діаграм (зберігаються інстанси Chart.js), `chatState` для чатів (вибраний чат, список користувачів, непрочитані повідомлення), `apiStatusState` для моніторингу (статуси API, БД, Ollama, історія статусів). Стан оновлюється синхронно через прямі зміни об'єктів та зберігається в LocalStorage для персистентних даних (токен, налаштування теми, стан sidebar).

**Основна логіка: event bus** — хоча фронтенд не використовує формальний event bus, комунікація між компонентами виконується через глобальні функції та події браузера. Події включають `popstate` для навігації через історію браузера, `resize` для адаптації діаграм до розміру вікна, `click` для взаємодії користувача, `submit` для відправки форм, `keydown` для обробки клавіатури (наприклад, Escape для закриття модальних вікон). Функції викликаються безпосередньо з обробників подій або через делегування подій на батьківських елементах.

**Основна логіка: router (внутрішній)** — маршрутизація реалізована через власну систему без використання зовнішніх бібліотек (Navigo використовується тільки як допоміжна утиліта). Система включає об'єкт `ROUTE_SECTIONS` для мапінгу URL на ID секцій, функцію `normalizePath()` для нормалізації шляхів (видалення подвійних слешів, обробка аліасів, конвертація в нижній регістр), функцію `getSectionByPath()` для визначення секції за URL, функцію `showSectionForPath()` для активації секції з перевіркою автентифікації, функцію `syncRouteFromLocation()` для синхронізації стану з URL, функцію `activateSection()` для активації конкретної секції з оновленням навігації та локалізації.

**Основна логіка: система ініціалізації сторінок** — ініціалізація сторінок виконується через функцію `activateSection()`, яка викликається при навігації. Функція виконує кілька кроків: видаляє клас `page--active` з усіх секцій та додає атрибут `hidden`, додає клас `page--active` до цільової секції та видаляє атрибут `hidden`, оновлює активний стан навігації у sidebar (додає клас `nav-item--active` до відповідного пункту меню), застосовує локалізацію до елементів секції через `applyTranslations()`, викликає специфічні функції ініціалізації для деяких сторінок (наприклад, `initializeInsights()` для діаграм, `loadChatsList()` для чатів, `loadApiStatus()` для API-status). Це забезпечує, що кожна сторінка правильно ініціалізується при активації.

### 8.3. UI/UX логіка

UI/UX архітектура фронтенду організована через систему компонентів, анімацій та адаптивності для забезпечення зручного та інтуїтивного інтерфейсу.

**Notification system** — система сповіщень реалізована через функцію `showNotification()`, яка створює toast-сповіщення у правому верхньому куті екрана. Сповіщення підтримують три типи: `success` для успішних операцій (зелена ліва межа, іконка check-circle), `error` для помилок (червона ліва межа, іконка alert-circle), `info` для інформаційних повідомлень (синя ліва межа, іконка info). Сповіщення автоматично зникають через заданий час (за замовчуванням 5 секунд) або можуть бути закриті вручну через кнопку закриття. Система обмежує кількість одночасних сповіщень (максимум 4), автоматично видаляючи найстаріші при перевищенні ліміту. Сповіщення мають анімацію появи (slide in зправа) та зникнення (slide out вправо) для плавності. Кожне сповіщення має заголовок та опційне повідомлення, підтримує ARIA-атрибути для доступності та автоматично оновлює іконки Lucide після створення.

**Custom tooltips** — tooltip-и реалізовані через CSS псевдоелемент `::after` для елементів з атрибутом `data-tooltip`. Tooltip-и особливо важливі для згорнутого стану sidebar, де текст навігації прихований, а tooltip-и показують назву пункту меню при наведенні. Tooltip-и мають напівпрозорий фон з blur-ефектом, тінь для глибини, плавну анімацію появи (fade in + slide) та автоматичне позиціювання відносно елемента. Tooltip-и також використовуються для кнопок, іконок та інших інтерактивних елементів для надання додаткової інформації користувачам.

**Dynamic modals** — модальні вікна реалізовані через HTML-структури з класом `modal` та overlay з класом `modal__backdrop`. Модальні вікна використовуються для підтвердження дій (видалення прогнозів, очищення історії, вихід з акаунту), налаштувань (тема, мова), інформації (про систему, про ризики) та помилок. Модальні вікна мають анімацію появи (fade in для overlay, slide up + scale для контейнера) та зникнення (fade out + slide down), закриваються при кліку поза ними, натисканні клавіші Escape або кнопки закриття. Модальні вікна мають напівпрозорий backdrop з blur-ефектом, центрований контейнер з контентом, кнопки дій (primary для підтвердження, secondary для скасування) та підтримують фокус-трап для доступності.

**Sidebar animation + expand/collapse** — sidebar має функціональність згортання/розгортання через кнопку toggle у верхній частині. При згортанні sidebar зменшує ширину, приховує текст навігації, зберігає тільки іконки та змінює іконку toggle з `panel-left-close` на `panel-left-open`. Стан sidebar зберігається в LocalStorage під ключем `hr_sidebar_collapsed` та відновлюється при завантаженні сторінки. Анімація виконується через CSS transitions для плавності зміни ширини, padding, gap та opacity. При згортанні sidebar використовує tooltip-и для показу назв пунктів меню при наведенні. Layout автоматично адаптується до стану sidebar через клас `layout--sidebar-collapsed`, який змінює grid-template-columns для правильного розміщення контенту.

**Header adaptive logic** — header (якщо присутній) адаптується до розміру екрана через CSS media queries. На мобільних пристроях header може згортатися, приховувати деякі елементи або змінювати розмір шрифтів та відступів. Header також може містити індикатори стану (наприклад, кількість непрочитаних повідомлень, статус API) та адаптувати їх відображення залежно від доступного простору.

**Логіка блокування користувачів** — блокування користувачів реалізовано через ендпоінти API `/users/block` та `/users/unblock`, які створюють або видаляють записи у таблиці `userblock`. На фронтенді блокування доступне через профіль користувача, де можна заблокувати або розблокувати іншого користувача. Заблоковані користувачі не можуть створювати чати, відправляти повідомлення та бачитися в активних чатах. UI відображає статус блокування через індикатори та обмежує взаємодію з заблокованими користувачами. Блокування перевіряється на бекенді при створенні чатів, відправці повідомлень та отриманні списку користувачів.

**Анімації крапочок «Перевірка...»** — анімація "Перевірка..." використовується для індикації очікування відповіді від Ollama під час генерації AI-відповіді. Анімація реалізована через JavaScript, який додає крапки поступово (".", "..", "...") з інтервалом приблизно 500 мілісекунд. Анімація запускається перед відправкою запиту до API та зупиняється при отриманні відповіді або помилки. Це забезпечує візуальний індикатор того, що система обробляє запит та генерує відповідь.

**Динамічна зміна стилів теми** — перемикання теми (світла/темна) реалізується через зміну класу `theme-light` або `theme-dark` на елементі `<body>`. CSS-змінні автоматично оновлюються залежно від класу, що змінює кольори, градієнти, тіні та прозорість всіх компонентів. Тема зберігається в LocalStorage під ключем `hr_theme` та відновлюється при завантаженні сторінки. Перемикання теми виконується через кнопку у sidebar, яка змінює клас на body, оновлює іконку (sun для світлої теми, moon для темної) та зберігає вибір у LocalStorage. Перехід між темами має плавну анімацію через CSS transitions для всіх кольорів та фонів.

### 8.4. Навігація та SPA-механіка

Система навігації фронтенду забезпечує плавну навігацію між сторінками без перезавантаження через History API та синхронізацію стану з URL.

**Що таке syncRouteFromLocation()** — це функція, яка синхронізує стан SPA з поточним URL у браузері. Вона викликається при завантаженні сторінки, зміні URL через History API (кнопки "Назад"/"Вперед") або програмній зміні маршруту. Функція отримує поточний `pathname` з `window.location`, викликає `showSectionForPath()` для активації відповідної секції та оновлює URL через `history.replaceState()`, якщо шлях змінився. Це забезпечує, що URL завжди відповідає активній секції та дозволяє використовувати кнопки браузера для навігації по історії SPA.

**Як працює showSectionForPath()** — це основна функція навігації, яка визначає та активує секцію на основі URL. Функція виконує кілька кроків: нормалізує шлях через `normalizePath()` (видаляє подвійні слеші, обробляє аліаси, конвертує в нижній регістр), визначає секцію через `getSectionByPath()` (знаходить відповідну секцію в `ROUTE_SECTIONS`), перевіряє автентифікацію для захищених маршрутів (якщо користувач не залогінений та маршрут не публічний, викликає `handleUnauthorized()` та перенаправляє на `/login`), перевіряє ініціалізацію автентифікації (якщо автентифікація ще не ініціалізована, чекає та повертає шлях для подальшої обробки), активує секцію через `activateSection()` (додає клас `page--active`, видаляє атрибут `hidden`, оновлює навігацію), повертає фінальний шлях для оновлення URL. Функція також обробляє спеціальні випадки, такі як редірект залогінених користувачів з `/login` на `/app` та обробка маршрутів з параметрами (наприклад, `/c/{chat_uuid}`, `/reset-password?token=...`).

**Як працюють публічні та захищені маршрути** — маршрути розділені на публічні (доступні без автентифікації) та захищені (вимагають автентифікації). Публічні маршрути включають `/login`, `/register`, `/forgot-password`, `/reset-password`, `/about` та визначаються через функцію `isPublicRoute()`. Захищені маршрути включають всі інші сторінки (`/app`, `/diagrams`, `/history`, `/profile`, `/assistant`, `/chats`, `/reports`, `/api-status`) та визначаються через список `protectedSections`. При спробі доступу до захищеного маршруту без автентифікації користувач автоматично перенаправляється на `/login` через `handleUnauthorized()`. При спробі доступу залогіненого користувача до публічних маршрутів (наприклад, `/login` або `/register`) він автоматично перенаправляється на `/app` для зручності.

**Як логіка визначає, куди пускати / куди редіректити** — логіка визначення маршруту виконується через кілька перевірок у `showSectionForPath()`: перевірка автентифікації (якщо користувач не залогінений та маршрут не публічний → редірект на `/login`), перевірка ініціалізації (якщо автентифікація ще не ініціалізована → чекаємо, поки ініціалізується), перевірка валідності маршруту (якщо маршрут не існує в `ROUTE_SECTIONS` → редірект на `/app` для залогінених або `/login` для незалогінених), перевірка стану користувача (якщо залогінений користувач на `/login` або `/register` → редірект на `/app`), активація секції (якщо всі перевірки пройдені → активуємо секцію та залишаємося на маршруті). Логіка також зберігає цільовий маршрут у `pendingRouteAfterAuth` для повернення після входу, якщо користувач намагався отримати доступ до захищеного маршруту без автентифікації.

**Взаємодія з localStorage** — LocalStorage використовується для зберігання персистентних даних, які повинні зберігатися між сесіями. Ключові дані, що зберігаються: `hr_auth_token` для JWT-токена автентифікації, `hr_sidebar_collapsed` для стану sidebar (згорнутий/розгорнутий), `hr_theme` для вибраної теми (light/dark), `hr_history_view` для режиму перегляду історії (list/grid), `hr_assistant_selected_prediction_{userId}` для вибраного прогнозу в асистенті, `hr_assistant_latest_ts_{userId}` для останнього timestamp в асистенті. Дані зчитуються при завантаженні сторінки та використовуються для відновлення стану (автентифікація, налаштування, вибір користувача). Дані оновлюються при зміні стану (вхід/вихід, зміна теми, зміна стану sidebar) та видаляються при необхідності (вихід з акаунту очищає токен).

### 8.5. Взаємодія з API

Взаємодія фронтенду з API організована через централізовану функцію `apiFetch()`, яка інкапсулює всі HTTP-запити та забезпечує обробку помилок, додавання токенів та парсинг відповідей.

**Принцип асинхронних викликів** — всі API-запити виконуються асинхронно через `async/await` для неблокуючої обробки. Функція `apiFetch()` приймає шлях ендпоінта, опції HTTP (method, body, headers) та опції обробки (skipAuth, skipAuthCheck) та повертає Promise з даними відповіді. Використання `async/await` дозволяє писати код у синхронному стилі з обробкою помилок через `try/catch`, що спрощує читабельність та підтримку. Всі запити виконуються через нативний API `fetch()`, який підтримується всіма сучасними браузерами та забезпечує швидкість та надійність.

**Валідація відповідей** — валідація відповідей виконується на кількох рівнях: перевірка статусу відповіді (якщо `!response.ok`, обробляється як помилка), перевірка Content-Type (якщо відповідь містить `application/json`, парситься як JSON, інакше обробляється як текст), перевірка структури даних (очікується структурована відповідь згідно з Pydantic-схемами API), обробка помилок парсингу (якщо JSON невалідний, повертається помилка з зрозумілим повідомленням). Валідація забезпечує, що фронтенд отримує коректні дані та може правильно їх обробити.

**Помилки API** — обробка помилок виконується централізовано через `apiFetch()` з різною логікою для різних статус-кодів: 401 (Unauthorized) → автоматичне очищення токена, видалення користувача зі стану, перенаправлення на `/login` через `handleUnauthorized()`, 400 (Bad Request) → відображення повідомлення про помилку через нотифікацію, 403 (Forbidden) → відображення повідомлення про відсутність доступу, 404 (Not Found) → відображення повідомлення про відсутність ресурсу, 422 (Unprocessable Entity) → відображення деталей помилки валідації, 500 (Internal Server Error) → відображення загального повідомлення про помилку сервера. Всі помилки логуються в консоль для діагностики та відображаються користувачу через систему нотифікацій з детальними повідомленнями.

**Автоматичне оновлення UI після відповідей** — після успішних API-запитів UI автоматично оновлюється через виклик відповідних функцій рендерингу. Наприклад, після успішного прогнозування викликається `renderResult()` для відображення результатів, після завантаження історії викликається `renderHistoryTable()` для оновлення таблиці, після оновлення профілю викликається `updateProfileSection()` для відображення нових даних, після завантаження чатів викликається `renderChatsList()` для оновлення списку. Це забезпечує, що UI завжди відображає актуальні дані після операцій та користувач бачить результати своїх дій.

**Використання токенів** — JWT-токени використовуються для автентифікації всіх захищених API-запитів. Токен зберігається в LocalStorage під ключем `hr_auth_token` після успішного входу або реєстрації та автоматично додається до всіх API-запитів через заголовок `Authorization: Bearer <token>` у функції `apiFetch()`. Токен перевіряється при завантаженні сторінки через ендпоінт `/auth/me` для відновлення сесії користувача. При отриманні помилки 401 токен автоматично видаляється з LocalStorage та стану, користувач перенаправляється на `/login`. Токен також використовується для опційної автентифікації на деяких ендпоінтах (наприклад, `/predict`), де запит може виконуватися без токена, але зберігається в історії тільки для автентифікованих користувачів.

### 8.6. Формування PDF на фронтенді

Генерація PDF-звітів виконується повністю на фронтенді через бібліотеку jsPDF, що забезпечує швидкість, конфіденційність даних та гнучкість форматування.

**Чому jsPDF** — jsPDF обрано для генерації PDF через кілька переваг: повна клієнтська обробка — PDF генерується в браузері без завантаження даних на сервер, що забезпечує конфіденційність та швидкість; простота використання — бібліотека має інтуїтивний API для створення документів, додавання тексту, зображень та форматування; підтримка кирилиці — через завантаження спеціальних шрифтів (DejaVuSans) можна генерувати PDF з українським текстом; інтеграція з Chart.js — діаграми можуть бути легко експортовані у зображення та вставлені в PDF; легкість розгортання — бібліотека завантажується з CDN, не потребує налаштування сервера; гнучкість — можна повністю контролювати структуру, стилі та вміст PDF.

**Чому PDF на фронтенді, а не на бекенді** — генерація PDF на фронтенді має кілька переваг: зменшення навантаження на сервер — генерація виконується на клієнті, що зменшує навантаження на сервер та дозволяє обробляти більше одночасних запитів; швидкість — генерація на клієнті забезпечує швидкий відгук без очікування обробки на сервері; конфіденційність — дані не передаються на сервер для генерації, що забезпечує додатковий рівень конфіденційності; гнучкість — фронтенд може легко змінювати формат звітів без змін на сервері; масштабованість — генерація на клієнті не обмежує кількість одночасних запитів на генерацію звітів; відсутність залежності від сервера — PDF може генеруватися навіть при обмеженій доступності сервера. Недоліками є залежність від можливостей браузера та необхідність завантаження додаткових бібліотек на клієнті.

**Як формується структура PDF** — структура PDF формується через функцію `generatePDFReport()`, яка створює документ у форматі A4 (210x297 мм) та додає контент поетапно. Структура включає: обкладинку (`renderCoverPage()`) з назвою системи, іконкою, датою генерації та темою (світла/темна), основну сторінку (`renderContentPage()`) з інформацією про прогноз (цільова змінна, ймовірність, категорія ризику), топ факторами впливу, рекомендаціями та технічними деталями, діаграми (`exportChartsToPDF()`) з експортованими графіками Chart.js у форматі PNG, додаткові сторінки (якщо потрібно) з детальною статистикою, історією прогнозів або іншою інформацією. Кожна сторінка має відступи (margins), внутрішні відступи (inner margins) та автоматичне перенесення тексту для оптимального розміщення контенту.

**Генерація графіків (canvas → PNG → PDF)** — експорт діаграм у PDF виконується через конвертацію canvas-елементів у зображення. Процес включає кілька кроків: отримання canvas-елементів для всіх діаграм на сторінці через їхні ID, тимчасове показування прихованих canvas (якщо діаграми на неактивній сторінці), збереження початкового стану canvas (display, visibility, hidden) для відновлення після експорту, експорт canvas у PNG через метод `toDataURL('image/png')` з високою роздільною здатністю, масштабування зображень для вміщення на сторінку A4 з збереженням пропорцій, вставка зображень у PDF через `doc.addImage()`, відновлення початкового стану canvas. Експорт виконується для всіх доступних діаграм (ризики, фактори, розподіли, кореляції, історія) та вставляється у PDF у логічному порядку.

**Вирівнювання діаграм** — діаграми вирівнюються на сторінці PDF через обчислення розмірів у міліметрах та автоматичне масштабування. Кожна діаграма має максимальну ширину (зазвичай 180 мм для сторінки A4 з відступами) та висоту (залежно від типу діаграми), обчислюється коефіцієнт масштабування для вміщення на сторінку з збереженням пропорцій, діаграми центруються горизонтально через обчислення позиції X, діаграми розміщуються вертикально з відступами між ними для читабельності. Якщо діаграма не вміщується на поточну сторінку, створюється нова сторінка через `doc.addPage()`.

**Оптимізація якості** — якість PDF оптимізується через кілька механізмів: висока роздільна здатність експорту canvas (зазвичай 2x або 3x від оригінального розміру для чіткості тексту та ліній), оптимізація розміру зображень (стиснення PNG через параметри якості, якщо підтримується), використання векторних шрифтів (DejaVuSans для кирилиці забезпечує чіткий текст на будь-якому масштабі), оптимізація кольорів (використання RGB для точного відтворення кольорів діаграм), мінімізація кількості сторінок (ефективне розміщення контенту для зменшення розміру файлу). Це забезпечує високу якість PDF при розумному розмірі файлу.

**Проблеми з кирилицею та використання DejaVuSans** — стандартні шрифти jsPDF не підтримують кирилицю, тому для генерації PDF з українським текстом використовуються спеціальні шрифти DejaVuSans. Шрифти завантажуються асинхронно з файлів `fonts/DejaVuSans.ttf` (звичайний) та `fonts/DejaVuSans-Bold.ttf` (жирний) при першій генерації PDF через функцію `ensurePdfFontInitialized()`. Шрифти конвертуються у base64 та додаються до документа через `doc.addFileToVFS()` та `doc.addFont()`. Після додавання шрифтів вони використовуються через `doc.setFont('DejaVuSans', 'normal')` або `doc.setFont('DejaVuSans', 'bold')` для коректного відображення українського тексту. Шрифти кешуються в пам'яті для швидкого доступу при подальших генераціях PDF.

### 8.7. Діаграми

Діаграми у фронтенді реалізовані через бібліотеку Chart.js, яка забезпечує інтерактивні, адаптивні та високоякісні графіки для візуалізації даних.

**Chart.js як головна бібліотека** — Chart.js версії 4.4.6 використовується як основна бібліотека для побудови діаграм через кілька переваг: простота використання — інтуїтивний API для створення різних типів діаграм, висока якість — векторний рендеринг через canvas забезпечує чіткість на будь-якому масштабі, інтерактивність — підтримка tooltip-ів, легенд, масштабування та інших інтерактивних елементів, адаптивність — автоматична адаптація до розміру контейнера, анімації — плавні анімації появи та оновлення діаграм, експорт — можливість експорту у зображення через `toDataURL()`, підтримка тем — можливість налаштування кольорів та стилів для світлої/темної теми. Бібліотека завантажується з CDN через тег `<script>` у HTML та доступна глобально через `window.Chart`.

**Архітектура файлів графіків** — діаграми не мають окремих файлів, а реалізовані через функції у `app.js`, які створюють та оновлюють інстанси Chart.js. Функції включають `upsertDashboardChart()` для створення або оновлення діаграми, `exportChartsToPDF()` для експорту діаграм у PDF, `initializeInsights()` для ініціалізації всіх діаграм на сторінці діаграм, специфічні функції для кожного типу діаграми (наприклад, `renderRiskCharts()` для діаграм ризиків, `renderFactorChart()` для діаграми факторів). Всі інстанси Chart.js зберігаються у об'єкті `dashboardCharts` з ключами, що відповідають ID canvas-елементів, для швидкого доступу та управління.

**Як будуються та оновлюються графіки** — побудова графіків виконується через функцію `upsertDashboardChart()`, яка приймає ID canvas-елемента, тип діаграми, дані та опції конфігурації. Функція перевіряє, чи існує вже інстанс Chart.js для даного canvas (через `dashboardCharts[chartId]`), якщо так — оновлює дані через `chart.data = newData` та `chart.update()`, якщо ні — створює новий інстанс через `new Chart(canvas, config)`. Оновлення виконується автоматично при зміні даних (нові прогнози, оновлення історії, зміна фільтрів) через виклик `upsertDashboardChart()` з новими даними. Chart.js автоматично анімує зміни даних для плавності оновлення.

**Як експортуються в PDF** — експорт діаграм у PDF виконується через функцію `exportChartsToPDF()`, яка обходить всі діаграми на сторінці, експортує їх у PNG через `chart.toBase64Image()` або `canvas.toDataURL('image/png')` та вставляє у PDF через `doc.addImage()`. Процес включає тимчасове показування прихованих canvas (якщо діаграми на неактивній сторінці), збереження початкового стану для відновлення, експорт з високою роздільною здатністю (2x або 3x для чіткості), масштабування для вміщення на сторінку A4, вставку у PDF з правильним вирівнюванням, відновлення початкового стану canvas. Діаграми експортуються у логічному порядку (ризики, фактори, розподіли, кореляції, історія) та розміщуються на окремих сторінках або разом залежно від розміру.

**Особливості Canvas** — діаграми рендеряться на canvas-елементах, які мають кілька особливостей: роздільна здатність — canvas має фіксовану роздільну здатність, яка визначається атрибутами `width` та `height` (не CSS-розмірами), масштабування — CSS-розміри можуть масштабувати canvas, але для експорту важлива оригінальна роздільна здатність, прозорість — canvas підтримує прозорість через альфа-канал, що дозволяє створювати накладки та ефекти, продуктивність — canvas забезпечує швидкий рендеринг навіть для складних діаграм з багатьма точками даних, доступність — canvas не підтримує нативну доступність, тому важливо додавати альтернативний текст через атрибут `aria-label` або прихований текст.

**Проблеми з рендерингом і їх вирішення** — при роботі з діаграмами виникають кілька проблем та їх рішення: приховані canvas не експортуються — рішення: тимчасово показуємо canvas перед експортом через зміну display, visibility та hidden, низька якість експорту — рішення: збільшуємо роздільну здатність canvas перед експортом через зміну атрибутів width та height, діаграми не оновлюються при зміні розміру вікна — рішення: додаємо обробник події `resize`, який викликає `chart.resize()` для всіх діаграм, конфлікти кольорів з темою — рішення: оновлюємо кольори діаграм при зміні теми через `chart.options.plugins.legend.labels.color` та інші опції, пам'ять не звільняється при видаленні діаграм — рішення: викликаємо `chart.destroy()` перед видаленням інстансу для коректного звільнення пам'яті.

### 8.8. Системні сторінки

Системні сторінки забезпечують моніторинг стану всіх компонентів системи та відображення детальної інформації про їх роботу.

**`/api-status`** — це головна сторінка моніторингу системи, яка відображає стан API, бази даних та Ollama сервера. Сторінка включає індикатори стану для кожного компонента (онлайн/офлайн через кольорові індикатори), графіки часу відгуку для відстеження продуктивності, детальну статистику (кількість запитів, латентність, помилки), кнопки оновлення статусу для ручного оновлення даних. Сторінка оновлюється автоматично кожні 10 секунд через періодичні запити до ендпоінтів `/health`, `/system/database/stats` та `/assistant/health`. Статуси зберігаються в історії для побудови графіків трендів та аналізу продуктивності.

**`/api-status/history`** — це сторінка історії статусів системи, яка відображає хронологічну історію змін статусів компонентів. Сторінка включає таблицю або список записів з timestamp, статусом кожного компонента (API, БД, Ollama), латентністю запитів, помилками (якщо були) та деталями. Історія дозволяє відстежувати зміни стану системи у часі, виявляти проблеми та аналізувати тренди продуктивності. Історія може фільтруватися за компонентом, діапазоном дат або типом події (онлайн/офлайн/помилка).

**Анімації статусів** — індикатори стану мають анімації для візуального відображення змін: пульсація для онлайн-статусу (зелений індикатор пульсує для показу активності), обертання для очікування (spinner обертається під час перевірки статусу), fade in/out для зміни статусу (плавна зміна кольору при переході між станами), slide in для нових записів історії (нові записи з'являються з анімацією slide in зверху). Анімації забезпечують плавність інтерфейсу та привертають увагу до важливих змін стану.

**Індикатори живучості системи** — індикатори живучості відображають поточний стан компонентів через кольорові точки або badges: зелений для онлайн (компонент працює нормально), червоний для офлайн (компонент недоступний), жовтий для попередження (компонент працює, але з обмеженнями), сірий для невідомого стану (статус не визначено). Індикатори також можуть відображати числові значення (латентність у мілісекундах, кількість помилок) для детальної інформації. Індикатори оновлюються в реальному часі при зміні статусів та зберігають історію для аналізу.

**Концепція вкладок** — сторінка `/api-status` може використовувати вкладки для перемикання між різними компонентами системи (API, БД, Ollama) або різними типами інформації (поточний стан, історія, статистика). Вкладки реалізовані через HTML-структуру з кнопками перемикання та контейнерами контенту, які показуються/ховаються через CSS-класи. Вкладки мають активний стан (виділення поточної вкладки), плавні переходи між вкладками та збереження вибраної вкладки в LocalStorage для відновлення при наступному відвідуванні.

**Статусо-моніторинг Ollama** — моніторинг Ollama включає перевірку доступності локального Ollama сервера через ендпоінт `/assistant/health`, вимірювання латентності запитів (час відгуку у мілісекундах), відображення статусу моделі (яка модель завантажена, чи доступна), відображення помилок (якщо Ollama недоступна, показується детальна інформація про помилку). Моніторинг виконується періодично (кожні 10 секунд) та при ручному оновленні через кнопку. Статус Ollama критично важливий для роботи AI-асистента, тому індикатор має помітне розміщення та детальну інформацію про помилки.

**Статус Бази Даних** — моніторинг бази даних включає перевірку доступності через ендпоінт `/system/database/stats`, відображення статистики (кількість користувачів, прогнозів, чатів, повідомлень), відображення розміру БД (у байтах або мегабайтах), відображення активності за останні 7 днів (кількість нових записів, остання активність). Статус БД важливий для оцінки здоров'я системи та планування масштабування. Помилки підключення до БД відображаються як критичні та вимагають негайної уваги.

**Графік навантаження системи** — графіки навантаження відображають зміну продуктивності системи у часі через лінійні діаграми Chart.js. Графіки включають латентність API (час відгуку на запити), латентність Ollama (час генерації відповідей), кількість активних користувачів, кількість запитів за одиницю часу, розмір бази даних у часі. Графіки будуються на основі історії статусів, яка зберігається в `apiStatusHistory` та `ollamaStatusHistory`, та оновлюються автоматично при додаванні нових записів. Графіки дозволяють виявляти тренди, аномалії та проблеми продуктивності.

### 8.9. Реалізація AI-асистента (інтерфейсна частина)

Інтерфейс AI-асистента реалізований як чат-інтерфейс, який інтегрується з локальним Ollama сервером через API для генерації персоналізованих рекомендацій щодо здоров'я.

**Інтерфейс чату** — інтерфейс чату включає область повідомлень з історією діалогу, поле введення для повідомлень користувача, кнопку відправки та індикатор "Асистент думає..." під час генерації відповіді. Повідомлення відображаються у вигляді карток з різними стилями для повідомлень користувача (вирівняні праворуч, світлий фон) та асистента (вирівняні ліворуч, темніший фон), включають аватари (іконки для користувача та асистента), timestamps для кожного повідомлення та форматування тексту (підтримка переносів рядків, посилань). Інтерфейс має плавну анімацію появи нових повідомлень (fade in + slide) та автоматичну прокрутку до останнього повідомлення при додаванні нового.

**Взаємодія з бекендом** — взаємодія з бекендом виконується через ендпоінт `/assistant/chat`, який приймає повідомлення користувача, опційний `prediction_id` для контексту конкретного прогнозу та мову (`uk` або `en`). Фронтенд відправляє POST-запит з JSON-тілом, отримує відповідь асистента та відображає її в чаті. Всі повідомлення зберігаються в історії через ендпоінт `/assistant/history`, який повертає всі попередні повідомлення для відображення при завантаженні сторінки. Історія завантажується автоматично при активації сторінки асистента та оновлюється після кожного нового повідомлення.

**Логіка повідомлень** — логіка повідомлень включає кілька аспектів: відправка повідомлень — при натисканні кнопки відправки або Enter у полі введення повідомлення валідується (перевірка на порожність, максимальна довжина), відображається в чаті як повідомлення користувача, відправляється на бекенд через API, відображається індикатор "Перевірка..." під час очікування відповіді; отримання відповіді — після отримання відповіді від API індикатор "Перевірка..." замінюється на відповідь асистента, відповідь відображається в чаті як повідомлення асистента, історія оновлюється для відображення нового повідомлення; обробка помилок — при помилці підключення до Ollama або інших помилках відображається повідомлення про помилку в чаті з деталями та рекомендаціями для користувача.

**Збереження історії** — історія повідомлень зберігається в базі даних через бекенд та завантажується на фронтенді при активації сторінки асистента. Історія включає всі попередні повідомлення користувача та асистента, зберігає порядок хронологічно, включає timestamps для кожного повідомлення та може бути пов'язана з конкретним прогнозом через `prediction_id`. Історія відображається в чаті у хронологічному порядку з можливістю прокрутки до початку діалогу. Історія також може бути очищена через ендпоінт `/assistant/history` (DELETE) для початку нового діалогу.

**Автоматичні відповіді** — автоматичні відповіді генеруються Ollama на основі контексту про стан здоров'я користувача, який формується на бекенді. Контекст включає інформацію про останній прогноз (цільова змінна, ймовірність, категорія ризику, топ фактори), вхідні параметри користувача (вік, стать, ІМТ, артеріальний тиск, лабораторні показники) та системний промпт з інструкціями для асистента (не ставити діагнози, не призначати лікування, надавати загальні рекомендації). Відповіді генеруються українською або англійською мовою залежно від параметра `language` у запиті та включають персоналізовані рекомендації на основі контексту.

**Dynamically resizing textarea** — поле введення для повідомлень реалізовано як textarea, яка автоматично змінює висоту залежно від вмісту. При введенні тексту textarea розширюється вертикально для вміщення всього тексту без необхідності прокрутки, має максимальну висоту (зазвичай 4-5 рядків), після чого з'являється вертикальна прокрутка. Зміна розміру виконується через JavaScript, який встановлює `textarea.style.height = 'auto'` для скидання висоти, потім `textarea.style.height = textarea.scrollHeight + 'px'` для встановлення нової висоти на основі вмісту. Це забезпечує зручне введення довгих повідомлень без необхідності ручного змінення розміру поля.

# Частина 4: База даних, тестування, архітектура, безпека та інфраструктура

## 9. База даних (DATABASE)

### 9.1. Загальна концепція

База даних у проєкті HealthRisk.AI виконує роль центрального сховища стану для вебінтерфейсу та API, зберігаючи всі динамічні дані, які змінюються під час роботи системи та повинні зберігатися між сесіями користувачів.

**Навіщо потрібна БД** — база даних забезпечує персистентність даних між сесіями користувачів, дозволяючи зберігати профілі користувачів, історію прогнозів, чати та повідомлення, історію діалогів з AI-асистентом, налаштування користувачів та іншу інформацію, необхідну для роботи системи. Без бази даних всі дані втрачалися б при перезавантаженні сервера або закритті сесії користувача, що робило б систему непрактичною для реального використання. БД також забезпечує цілісність даних через транзакції, foreign keys та обмеження, що запобігає дублюванню та некоректним зв'язкам між даними.

**Що саме зберігається** — база даних зберігає сім основних типів даних: профілі користувачів (email, хеші паролів, імена, дати народження, стать, аватари, налаштування), історію прогнозів (всі виконані прогнози з вхідними параметрами, результатами, використаними моделями, топ факторами впливу, датами створення), чати між користувачами (унікальні ідентифікатори чатів, учасники, дати створення та оновлення, закріплення, порядок відображення), повідомлення в чатах (текст повідомлень, відправники, дати відправки, статуси прочитання), повідомлення AI-асистента (історія діалогів з асистентом, ролі авторів, контекст через зв'язок з прогнозами), блокування користувачів (інформація про блокування між користувачами для запобігання створенню чатів та відправці повідомлень), токени для відновлення пароля (унікальні токени, терміни дії, статуси використання).

**Які основні сутності** — база даних містить сім основних сутностей, які відповідають таблицям: User (користувачі системи), PredictionHistory (історія прогнозів), Chat (чати між користувачами), ChatMessage (повідомлення в чатах), AssistantMessage (повідомлення AI-асистента), UserBlock (блокування користувачів), PasswordResetToken (токени для відновлення пароля). Кожна сутність має свої поля, обмеження, індекси та зв'язки з іншими сутностями через foreign keys, що забезпечує структурованість та цілісність даних.

### 9.2. Технічна частина

Технічна реалізація бази даних організована через SQLite як легке файлове рішення, SQLModel як ORM для роботи з БД та SQLAlchemy як низькорівневий шар для створення engine та сесій.

**SQLite як lightweight рішення** — SQLite обрано як основну базу даних через кілька переваг: простота розгортання — не потребує окремого сервера БД, всі дані зберігаються в одному файлі на диску, що спрощує розгортання та резервне копіювання; легкість підтримки — не потрібно налаштовувати сервер БД, управляти процесами, моніторити з'єднання, що спрощує розробку та тестування; достатня продуктивність — для середніх навантажень SQLite забезпечує швидкий доступ до даних без мережевих затримок; підтримка транзакцій — SQLite підтримує ACID-транзакції, що забезпечує цілісність даних; підтримка SQL — стандартний SQL-синтаксис дозволяє використовувати звичайні запити та інтегруватися з ORM; вбудована підтримка в Python — драйвер sqlite3 вбудований в Python, не потрібні додаткові залежності.

**Чому SQLite підходить для локальної та R&D системи** — SQLite ідеально підходить для локальної розробки та дослідницьких проєктів через: відсутність необхідності в окремому сервері — розробник може запустити систему одразу без налаштування PostgreSQL або MySQL, що прискорює розробку; швидкість розробки — не потрібно налаштовувати з'єднання, створювати користувачів БД, управляти правами доступу, що економить час; простота тестування — тестова БД може бути створена в пам'яті або тимчасовому файлі, що забезпечує швидкі та ізольовані тести; переносимість — файл БД можна легко скопіювати, перенести на іншу машину або включити в резервне копіювання; достатність для R&D — для дослідницького проєкту з невеликою кількістю користувачів SQLite забезпечує достатню продуктивність без складності продакшен-БД; легкість масштабування — при необхідності можна легко мігрувати на PostgreSQL через SQLModel, який підтримує обидві БД.

**Де зберігається файл бази даних** — база даних зберігається у файлі `data/app.db` відносно кореня проєкту. Директорія `data/` створюється автоматично при першому запуску через `DATA_DIR.mkdir(parents=True, exist_ok=True)` у модулі `db.py`, якщо вона не існує. Повний шлях до файлу формується як `sqlite:///data/app.db` у форматі SQLAlchemy connection string. Файл БД містить всі таблиці, індекси, обмеження та дані в одному файлі, що спрощує резервне копіювання (достатньо скопіювати один файл) та перенесення на інші машини.

**Структура таблиць** — структура таблиць визначається через SQLModel ORM-моделі у файлі `src/service/models.py`. Кожна модель наслідується від `SQLModel` з параметром `table=True`, що вказує SQLModel створити таблицю в БД. Поля визначаються через `Field()` з типами даних (int, str, datetime, bool, dict для JSON), обмеженнями (nullable, unique, index), foreign keys через `foreign_key="table.column"` та relationships через `Relationship()`. Структура створюється автоматично при першому запуску через `SQLModel.metadata.create_all(bind=engine)` у функції `init_db()`, яка викликається в `lifespan` контекстному менеджері FastAPI при startup.

**Індекси** — індекси створюються автоматично для полів з параметром `index=True` у `Field()` та для foreign keys. Основні індекси включають: первинні ключі (автоматично індексовані), `email` в таблиці `user` (унікальний індекс для швидкого пошуку користувача за email), `user_id` в таблицях `predictionhistory`, `assistantmessage`, `passwordresettoken`, `userblock` (індекси для швидкого пошуку записів користувача), `token` в таблиці `passwordresettoken` (унікальний індекс для швидкого пошуку токену), `uuid` в таблиці `chat` (унікальний індекс для швидкого пошуку чату за UUID), `chat_id` в таблиці `chatmessage` (індекс для швидкого пошуку повідомлень чату), `sender_id` в таблиці `chatmessage` (індекс для швидкого пошуку повідомлень відправника), `user1_id`, `user2_id` в таблиці `chat` (індекси для швидкого пошуку чатів користувача), унікальний складений індекс на `(user_id, blocked_user_id)` в таблиці `userblock` для запобігання дублюванню блокувань. Індекси забезпечують швидкий пошук записів за ключовими полями та покращують продуктивність запитів.

**Типи полів** — база даних використовує стандартні типи SQLite з відображенням через SQLModel: integer для числових полів (id, user_id, chat_id), varchar/text для рядкових полів (email, display_name, content), datetime для дат та часу (created_at, updated_at, expires_at), boolean для логічних полів (is_active, is_pinned, used), JSON (через SQLITE_JSON) для структурованих даних (inputs в таблиці predictionhistory, який містить вхідні параметри прогнозу, топ фактори, метадані). SQLModel автоматично конвертує Python-типи в SQLite-типи при створенні таблиць та конвертує SQLite-типи в Python-типи при читанні даних.

### 9.3. Основні таблиці

База даних містить сім основних таблиць, кожна з яких виконує конкретну роль у системі та має свої зв'язки з іншими таблицями.

**Таблиця user (користувачі)** — це центральна таблиця системи, яка зберігає профілі всіх користувачів. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `email` (унікальний, індексований, обов'язковий рядок для електронної пошти), `hashed_password` (обов'язковий рядок з bcrypt-хешем пароля), `display_name` (обов'язковий рядок для імені відображення), `first_name`, `last_name` (опційні рядки для імені та прізвища), `date_of_birth` (опційний datetime для дати народження), `gender` (опційний рядок: male/female/other), `avatar_url` (опційний рядок для URL завантаженого аватару), `avatar_type` (обов'язковий рядок: "generated" або "uploaded"), `avatar_color` (опційний рядок для кольору згенерованого аватару), `is_active` (boolean, за замовчуванням True для активності акаунта), `created_at`, `updated_at` (datetime для відстеження часу створення та оновлення). Таблиця використовується API для аутентифікації (пошук користувача за email, перевірка пароля), управління профілем (оновлення даних, зміна пароля, завантаження аватару), відображення інформації про користувача на фронтенді. Таблиця пов'язана з іншими таблицями через foreign keys: один користувач може мати багато записів в `predictionhistory` (зв'язок один-до-багатьох), багато повідомлень в `assistantmessage` (зв'язок один-до-багатьох), багато чатів через `user1_id` та `user2_id` в таблиці `chat` (зв'язок багато-до-багатьох), багато токенів для відновлення пароля (зв'язок один-до-багатьох), багато блокувань через `user_id` та `blocked_user_id` в таблиці `userblock` (зв'язок один-до-багатьох, двоспрямований).

**Таблиця predictionhistory (історія прогнозів)** — це таблиця для збереження всіх прогнозувань ризиків здоров'я, виконаних користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий), `target` (обов'язковий рядок: "diabetes_present" або "obesity_present" для цільової змінної прогнозування), `model_name` (опційний рядок для назви використаної ML-моделі), `probability` (обов'язковий float, 0-1 для ймовірності позитивного класу), `risk_bucket` (обов'язковий рядок: "low", "medium" або "high" для категорії ризику), `inputs` (обов'язковий JSON, який містить вхідні параметри прогнозу: вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин, топ фактори впливу, метадані моделі), `created_at` (datetime, автоматично встановлюється при створенні). Таблиця використовується API для збереження результатів прогнозування після успішного прогнозу через `add_prediction_history()` у `repositories.py`, отримання історії прогнозів користувача для відображення на фронтенді через `get_all_prediction_history()`, використання в AI-асистенті для контексту через зв'язок з `assistantmessage` через `prediction_id`, аналізу трендів ризиків у часі, статистики для діаграм та звітів. Таблиця пов'язана з таблицею `user` через foreign key `user_id` (зв'язок багато-до-одного), що дозволяє легко отримувати всі прогнози користувача та забезпечує автоматичне видалення записів при видаленні користувача (якщо налаштовано CASCADE). Таблиця також пов'язана з таблицею `assistantmessage` через опційний foreign key `prediction_id` (зв'язок один-до-багатьох), що дозволяє AI-асистенту використовувати контекст конкретного прогнозу для більш точних рекомендацій.

**Таблиця chat (чати)** — це таблиця для зберігання чатів між двома користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `uuid` (унікальний, індексований рядок, автоматично генерується через UUID для використання в URL), `user1_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID першого учасника), `user2_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID другого учасника), `created_at` (datetime, автоматично встановлюється при створенні), `updated_at` (datetime, автоматично оновлюється при додаванні повідомлень через `chat.touch()`), `is_pinned` (boolean, за замовчуванням False для закріплення важливих чатів), `order` (integer, за замовчуванням 0 для порядку відображення чатів для drag and drop). Таблиця використовується API для створення або отримання існуючого чату між двома користувачами через `get_or_create_chat()` у `repositories.py`, отримання списку чатів користувача для відображення на фронтенді, управління порядком відображення чатів, закріплення важливих чатів. Таблиця пов'язана з таблицею `user` через два foreign keys `user1_id` та `user2_id` (зв'язок багато-до-багатьох), що дозволяє кожному користувачу мати багато чатів з різними користувачами, а кожен чат унікальний для пари користувачів. Таблиця також пов'язана з таблицею `chatmessage` через foreign key `chat_id` (зв'язок один-до-багатьох), що дозволяє легко отримувати всі повідомлення чату.

**Таблиця chatmessage (повідомлення в чатах)** — це таблиця для зберігання повідомлень у чатах між користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `chat_id` (зовнішній ключ до таблиці `chat`, індексований, обов'язковий), `sender_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID відправника), `content` (обов'язковий Text для тексту повідомлення), `created_at` (datetime, автоматично встановлюється при створенні), `read_at` (опційний datetime, None означає непрочитане повідомлення). Таблиця використовується API для додавання повідомлень у чат через `add_chat_message()` у `repositories.py`, отримання історії повідомлень чату для відображення на фронтенді через `get_chat_messages()`, відстеження статусу прочитання для підрахунку непрочитаних повідомлень через `mark_messages_as_read()`, побудови історії діалогів, сортування повідомлень за часом для відображення на фронтенді. Таблиця пов'язана з таблицею `chat` через foreign key `chat_id` (зв'язок багато-до-одного), що дозволяє легко отримувати всі повідомлення чату та забезпечує автоматичне видалення повідомлень при видаленні чату (якщо налаштовано CASCADE). Таблиця також пов'язана з таблицею `user` через foreign key `sender_id` (зв'язок багато-до-одного), що дозволяє легко отримувати інформацію про відправника повідомлення.

**Таблиця assistantmessage (повідомлення AI-асистента)** — це таблиця для зберігання історії повідомлень з AI-асистентом для кожного користувача. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий), `role` (обов'язковий рядок: "user" для користувача або "assistant" для AI-асистента), `content` (обов'язковий Text для тексту повідомлення), `created_at` (datetime, автоматично встановлюється при створенні), `prediction_id` (опційний зовнішній ключ до таблиці `predictionhistory` — зв'язок з конкретним прогнозом для контексту). Таблиця використовується API для збереження повідомлень користувача та відповідей асистента через `add_message()` у `repositories.py`, отримання історії діалогів для відображення на фронтенді через `get_user_messages()`, відновлення контексту діалогу при наступних запитах для більш точних рекомендацій, побудови історії чату для відображення на фронтенді. Таблиця пов'язана з таблицею `user` через foreign key `user_id` (зв'язок багато-до-одного), що дозволяє зберігати окрему історію діалогу з асистентом для кожного користувача. Таблиця також пов'язана з таблицею `predictionhistory` через опційний foreign key `prediction_id` (зв'язок багато-до-одного), що дозволяє AI-асистенту використовувати контекст конкретного прогнозу для більш точних рекомендацій.

**Таблиця userblock (блокування користувачів)** — це таблиця для зберігання інформації про блокування між користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID користувача, який заблокував), `blocked_user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID заблокованого користувача), `created_at` (datetime, автоматично встановлюється при створенні). Таблиця використовується API для додавання або видалення блокувань через `block_user()` та `unblock_user()` у `repositories.py`, перевірки наявності блокування між користувачами через `is_user_blocked()` та `get_blocked_user_ids()` для фільтрації при створенні чатів, відправці повідомлень, отриманні списку користувачів. Таблиця має унікальний складений індекс на парі `(user_id, blocked_user_id)` для запобігання дублюванню блокувань. Блокування одностороннє — якщо користувач A заблокував користувача B, це не означає, що B заблокував A. Таблиця пов'язана з таблицею `user` через два foreign keys `user_id` та `blocked_user_id` (зв'язок один-до-багатьох, двоспрямований), що дозволяє одному користувачу заблокувати багато інших користувачів, а один користувач може бути заблокований багатьма іншими.

**Таблиця passwordresettoken (токени для відновлення пароля)** — це таблиця для зберігання токенів для відновлення пароля, які генеруються при запиті "забув пароль" та відправляються на email користувача. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий), `token` (унікальний, індексований, обов'язковий рядок для унікального токену), `expires_at` (обов'язковий datetime для часу закінчення токену), `used` (boolean, за замовчуванням False для позначення використання токену), `created_at` (datetime, автоматично встановлюється при створенні). Таблиця використовується API для створення токенів при запиті відновлення пароля, перевірки валідності токену при встановленні нового пароля, запобігання повторному використанню токенів через поле `used`. Токени мають термін дії та можуть бути використані тільки один раз. Таблиця пов'язана з таблицею `user` через foreign key `user_id` (зв'язок багато-до-одного), що дозволяє одному користувачу мати багато токенів (наприклад, якщо запитує відновлення кілька разів).

### 9.4. Міграції (якщо логіка є)

Міграції бази даних реалізовані програмно через функцію `migrate_add_missing_columns()` у модулі `src/service/db.py`, яка додає відсутні колонки до існуючих таблиць при старті додатку.

**Створення нових таблиць** — нові таблиці створюються автоматично при першому запуску через `SQLModel.metadata.create_all(bind=engine)` у функції `init_db()`, яка викликається в `lifespan` контекстному менеджері FastAPI при startup. Функція перевіряє наявність таблиць через `inspector.get_table_names()` та створює їх, якщо вони не існують, на основі SQLModel-моделей, визначених у `src/service/models.py`. Після створення таблиць виконується міграція для додавання відсутніх колонок через `migrate_add_missing_columns()`. Це забезпечує, що структура БД завжди відповідає моделям, навіть якщо моделі були змінені після створення таблиць.

**Оновлення структури** — оновлення структури таблиць виконується через функцію `migrate_add_missing_columns()`, яка перевіряє наявність колонок у таблицях та додає відсутні через `ALTER TABLE`. Функція використовує SQLAlchemy inspector для отримання списку існуючих колонок через `inspector.get_columns(table_name)`, порівнює їх з очікуваними полями з моделей та додає відсутні колонки через SQL-запити `ALTER TABLE table_name ADD COLUMN column_name TYPE`. Міграції виконуються при кожному запуску додатку, що забезпечує актуальність схеми БД без необхідності ручного виконання міграцій. Наразі система міграцій проста та додає тільки нові колонки, не видаляючи старі та не змінюючи типи існуючих колонок.

**Додавання нових полів** — додавання нових полів до існуючих таблиць виконується через `migrate_add_missing_columns()`, яка перевіряє наявність полів та додає відсутні. Наприклад, для таблиці `user` функція перевіряє наявність полів `avatar_type`, `first_name`, `last_name`, `date_of_birth`, `gender` та додає їх, якщо вони відсутні. Для таблиці `chat` функція перевіряє наявність полів `is_pinned` та `order` та додає їх з значеннями за замовчуванням. Для таблиці `userblock` функція створює таблицю, якщо вона відсутня, разом з індексами. Це дозволяє додавати нові поля до існуючих таблиць без втрати даних та без необхідності ручного виконання SQL-скриптів. В майбутньому можна додати систему міграцій (наприклад, Alembic) для більш складних змін схеми, включаючи видалення колонок, зміну типів, перейменування полів.

### 9.5. Робота з БД у FastAPI

Робота з базою даних у FastAPI організована через SQLAlchemy engine, сесії та dependency injection для забезпечення ізоляції транзакцій та коректної обробки помилок.

**Пул з'єднань** — SQLAlchemy engine створюється один раз при імпорті модуля `db.py` через `create_engine()` та використовується для всіх підключень до БД. Engine налаштований з `echo=False` (без логування SQL-запитів) та `connect_args={"check_same_thread": False}` для підтримки багатопотоковості в ASGI. Engine автоматично керує пулом з'єднань, створюючи нові з'єднання при потребі та перевикористовуючи існуючі для оптимізації продуктивності. SQLite підтримує одночасні читання, але тільки один writer одночасно, що достатньо для середніх навантажень локальної системи.

**Асинхронність** — хоча FastAPI підтримує асинхронні операції через `async/await`, робота з SQLite через SQLAlchemy виконується синхронно, оскільки SQLite не підтримує нативну асинхронність. Для асинхронної роботи з БД потрібно використовувати асинхронні драйвери (наприклад, aiosqlite для SQLite або asyncpg для PostgreSQL) та асинхронні версії SQLAlchemy (SQLAlchemy 2.0 з async support). В поточній реалізації всі операції з БД виконуються синхронно, але FastAPI обробляє їх в thread pool для неблокуючої обробки запитів. Це забезпечує достатню продуктивність для локальної системи, але для продакшену з високим навантаженням варто розглянути перехід на асинхронну БД (PostgreSQL з asyncpg) або окремий сервіс для БД-операцій.

**Робота ORM чи raw SQL** — проєкт використовує ORM (SQLModel) як основний спосіб роботи з БД, що забезпечує типобезпеку, валідацію даних та спрощує роботу зі зв'язками між таблицями. SQLModel дозволяє визначати моделі, які використовуються і для валідації API (через Pydantic), і для роботи з БД (через SQLAlchemy), що забезпечує консистентність даних. Репозиторійний шар у `src/service/repositories.py` інкапсулює логіку роботи з БД через SQLModel-запити (наприклад, `select(User).where(User.email == email)`), що забезпечує читабельність коду та спрощує тестування. Raw SQL використовується тільки для міграцій через `text()` у функції `migrate_add_missing_columns()`, де потрібно виконувати `ALTER TABLE` запити, які не підтримуються SQLModel напряму. Це забезпечує баланс між зручністю ORM та гнучкістю raw SQL для спеціальних випадків.

## 10. Тестування (TESTING)

### 10.1. Загальний огляд

Система тестування проєкту HealthRisk.AI організована за принципом багаторівневої архітектури, що забезпечує перевірку коректності логіки, стабільності API, роботи ML моделей, UI та інтеграцій на різних рівнях абстракції.

**Що саме тестується в системі** — тести покривають всі ключові компоненти системи: функції бізнес-логіки (хешування паролів, JWT токени, обчислення ризиків, топ факторів), API ендпоінти (автентифікація, прогнозування, історія, чати, AI-асистент), ML моделі (завантаження, передбачення, діапазони ймовірностей, детермінізм), взаємодію між компонентами (API-БД, API-ML, повний цикл запиту прогнозу), обробку помилок (невалідні дані, неавтентифіковані запити, помилки БД, помилки ML), граничні випадки (екстремальні значення, пропущені дані, нереалістичні комбінації параметрів). Тести забезпечують, що система працює коректно при нормальному використанні, правильно обробляє помилки та граничні випадки, та залишається стабільною при змінах коду.

### 10.2. Типи тестів

Проєкт використовує декілька типів тестів для забезпечення якості коду та функціональності системи на різних рівнях абстракції.

**Юніт-тести** — це тести окремих функцій та утиліт ізольовано від інших компонентів системи. Юніт-тести покривають функції з бізнес-логіки (хешування паролів через `get_password_hash()`, перевірка паролів через `verify_password()`, генерація JWT токенів через `create_access_token()`, декодування токенів через `decode_token()`, обчислення ризиків через `get_risk_bucket()`, топ факторів через `calculate_top_factors_simple()`), утиліти (конвертери даних, форматування, обробка помилок, валідація), Pydantic схеми (валідація вхідних та вихідних даних API, перевірка типів, діапазонів, обов'язковості полів), невеликі сервісні класи (реєстр моделей, завантаження моделей, обробка даних). Юніт-тести розташовані у `tests/backend/unit/` для бекенду та `tests/ml/unit/` для ML, використовують моки для ізоляції компонентів та перевіряють коректність обробки валідних даних, граничних випадків та некоректних даних з очікуваними винятками.

**Інтеграційні тести** — це тести взаємодії між компонентами системи. Інтеграційні тести покривають взаємодію API і бази даних (тести перевіряють, що API коректно зберігає дані в БД, читає дані з БД, оновлює записи, видаляє записи, обробляє помилки БД, такі як дублювання email, неіснуючі записи), інтеграцію API з ML моделями (тести перевіряють, що API коректно завантажує моделі, виконує прогнозування, обробляє вхідні дані, повертає результати у правильному форматі, зберігає історію прогнозів), повний цикл запиту прогнозу (тести перевіряють весь процес від отримання вхідних даних через API до збереження результату в БД, включаючи валідацію, обробку, прогнозування, збереження). Інтеграційні тести розташовані у `tests/backend/integration/`, використовують тестову БД (тимчасову SQLite) для ізоляції та автоматичного очищення після завершення, використовують фікстури для підготовки даних (користувачі, токени, тестові дані) та перевіряють коректність роботи всіх компонентів разом.

**E2E-тести** — це тести повних сценаріїв користувача від початку до кінця. E2E-тести покривають повні сценарії користувача (реєстрація → логін → прогноз → історія → оновлення профілю), повний цикл роботи з системою (створення акаунту, виконання прогнозу, перегляд історії, генерація PDF-звіту, використання AI-асистента), навігацію між сторінками (перехід між секціями, збереження стану, відновлення після перезавантаження), автентифікацію (вхід, вихід, оновлення профілю, зміна пароля). E2E-тести розташовані у `tests/backend/e2e/`, використовують тестову БД та тестовий клієнт FastAPI для імітації повного циклу роботи користувача та перевіряють, що всі компоненти працюють разом коректно для реалістичних сценаріїв використання.

**Тести API** — це тести коректності роботи ендпоінтів, обробки запитів, валідації даних та обробки помилок. Тести API покривають ендпоінти логіну та реєстрації (тести перевіряють успішну реєстрацію, логін з правильними credentials, обробку дублювання email, невалідних email, порожніх паролів, неправильних credentials, неактивних акаунтів), прогноз ризику (тести перевіряють прогноз діабету, прогноз ожиріння, валідацію вхідних даних, обробку відсутніх обов'язкових полів, діапазони ймовірностей, категорії ризику, топ фактори, збереження в історії), історію (тести перевіряють отримання історії прогнозів, фільтрацію за користувачем, сортування за датою, обмеження кількості записів), чати (тести можуть перевіряти створення чатів, відправку повідомлень, отримання історії чатів), API-status (тести можуть перевіряти статус API, БД, Ollama). Тести API формують HTTP-запити через `TestClient` з FastAPI, перевіряють статус-коди відповідей (200 для успішних, 400 для помилок валідації, 401 для неавтентифікованих, 403 для відсутності прав, 404 для неіснуючих ресурсів, 422 для помилок валідації Pydantic), перевіряють структуру JSON-відповідей (наявність полів, значення, діапазони, допустимі значення) та перевіряють сценарії з помилками (401, 403, 422 з детальними повідомленнями).

**Тести ML-моделей** — це тести коректності завантаження моделей, стабільності передбачень, відповідності формату інпутів та аутпутів та якості метрик. Тести ML покривають завантаження моделей (тести перевіряють завантаження чемпіонських моделей для діабету та ожиріння, каліброваних моделей, конкретних моделей за ключем, обробку помилок при відсутності моделей), логіку прогнозування (тести перевіряють діапазони ймовірностей 0-1, детермінізм передбачень, реалістичні дані, суму ймовірностей = 1), екстремальні значення (тести перевіряють, що модель не падає на граничних значеннях параметрів, повертає валідні результати, обробляє нереалістичні комбінації параметрів), пропущені дані (тести перевіряють, що pipeline коректно обробляє None значення через імпутацію, що передбачення стабільні при пропущених опціональних полях), чутливість моделей (тести перевіряють, що збільшення факторів ризику збільшує ймовірність позитивного класу, що модель реагує на зміни параметрів логічно та передбачувано). Тести ML розташовані у `tests/ml/unit/` для unit тестів та `tests/ml/experimental/` для експериментальних тестів, використовують маркери `@pytest.mark.skipif` для пропуску тестів, якщо моделі не знайдено, та перевіряють, що моделі працюють коректно навіть при нестандартних вхідних даних.

**Експериментальні тести (нестандартні кейси)** — це тести нестандартних сценаріїв та граничних випадків для підтвердження надійності системи. Експериментальні тести покривають екстремальні значення параметрів (максимальний вік 120, максимальний ІМТ 60, максимальний тиск 250, максимальна глюкоза 400, мінімальні значення, нереалістичні комбінації), пропущені дані (один пропущений параметр, кілька пропущених параметрів, всі опціональні поля пропущені, обробка через імпутацію), чутливість моделей до змін факторів (чутливість до зміни ІМТ, глюкози, віку, перевірка що збільшення факторів ризику збільшує ймовірність). Експериментальні тести розташовані у `tests/ml/experimental/` та `tests/backend/experimental/`, допомагають виявити проблеми з обробкою граничних випадків, перевірити стабільність моделей на нестандартних даних, підтвердити що система не падає при неочікуваних вхідних даних, забезпечити що модель повертає валідні результати навіть при екстремальних значеннях, перевірити що обробка пропущених даних працює коректно.

### 10.3. Покриття

Покриття коду тестами відстежується через pytest-cov та аналіз структури тестів для виявлення непокритих частин коду та покращення якості тестів.

**Що має бути покрито** — покриття тестами має охоплювати всі критичні частини системи: функції аутентифікації (хешування паролів, JWT токени, перевірка паролів повинні бути покриті unit тестами для забезпечення безпеки), Pydantic схеми (валідація вхідних та вихідних даних повинна бути покрита unit тестами для забезпечення коректності даних), API ендпоінти (автентифікація та прогнозування повинні бути покриті інтеграційними тестами для забезпечення стабільності API), завантаження моделей (завантаження чемпіонських та конкретних моделей повинно бути покрито unit тестами для забезпечення коректності завантаження), логіка прогнозування (діапазони ймовірностей, детермінізм повинні бути покриті unit тестами для забезпечення коректності передбачень), обробка помилок (невалідні дані, неавтентифіковані запити, помилки БД повинні бути покриті тестами для забезпечення надійності системи), граничні випадки (екстремальні значення, пропущені дані повинні бути покриті експериментальними тестами для забезпечення стабільності).

**Чому це важливо** — покриття тестами важливе для забезпечення якості коду та надійності системи: виявлення помилок на ранніх етапах — тести допомагають виявити помилки до того, як вони потраплять у продакшен, що економить час та ресурси; запобігання регресіям — тести перевіряють, що зміни коду не зламали існуючий функціонал, що дозволяє безпечно рефакторити та додавати нові функції; документація поведінки — тести слугують документацією того, як повинна працювати система, що допомагає новим розробникам зрозуміти код; впевненість у змінах — високе покриття дає впевненість, що зміни не зламають систему, що дозволяє швидше розвивати проєкт; якість коду — покриття допомагає виявити непокритий код, що може містити помилки або невикористовуваний функціонал; інтеграція з CI/CD — покриття може бути інтегроване з CI/CD для автоматичної перевірки якості коду при кожному коміті.

### 10.4. Організація структури тестів

Структура тестів організована за принципом розділення за типами тестів та компонентами системи для зручності навігації та запуску окремих груп тестів.

**Де зберігаються** — всі тести розміщені у кореневій директорії `tests/` відносно кореня проєкту. Структура організована за типами тестів та компонентами системи: `tests/backend/unit/` для unit тестів бекенду, `tests/backend/integration/` для інтеграційних тестів бекенду, `tests/backend/e2e/` для e2e тестів бекенду, `tests/backend/experimental/` для експериментальних тестів бекенду, `tests/frontend/unit/` для unit тестів фронтенду, `tests/frontend/integration/` для інтеграційних тестів фронтенду, `tests/frontend/e2e/` для e2e тестів фронтенду, `tests/ml/unit/` для unit тестів ML, `tests/ml/experimental/` для експериментальних тестів ML, `tests/ml/metrics/` для тестів метрик моделей, `tests/utils/` для утиліт тестів (фікстури, генератори тестових даних), `tests/conftest.py` для загальних фікстур для всіх тестів.

**Логіка поділу** — тести розділені за типами та компонентами для зручності навігації та запуску: розділення за типами (unit, integration, e2e, experimental) дозволяє запускати тільки потрібний тип тестів для швидкої перевірки конкретної частини системи, розділення за компонентами (backend, frontend, ml) дозволяє запускати тести тільки для конкретного компонента, що економить час при розробці, окремі папки для утиліт та фікстур дозволяють повторно використовувати код між тестами, що спрощує підтримку. Це забезпечує чітку організацію тестів та дозволяє легко знаходити потрібні тести для конкретного компонента або типу.

**План для розширення** — структура тестів готова для майбутнього розширення: папки для фронтенду (`tests/frontend/unit/`, `tests/frontend/integration/`, `tests/frontend/e2e/`) створені та готові для додавання тестів, папка для експериментальних тестів бекенду (`tests/backend/experimental/`) готова для додавання нестандартних сценаріїв, папка для тестів метрик (`tests/ml/metrics/`) готова для додавання тестів якості моделей, утиліти для тестів (`tests/utils/`) готові для додавання нових генераторів тестових даних та фікстур. Це дозволяє легко додавати нові тести без зміни структури та забезпечує масштабованість системи тестування.

## 11. Архітектура системи (ARCHITECTURE OVERVIEW)

### 11.1. Загальна архітектура

Архітектура системи HealthRisk.AI організована за принципом багатошарової архітектури з чітким розділенням відповідальності між компонентами. Кожен шар виконує конкретні завдання та взаємодіє з іншими через чітко визначені інтерфейси.

**Компонентна схема** — система складається з кількох великих блоків: ETL & Data (фундаментальний шар для збору, обробки та підготовки даних), EDA (аналітичний шар для дослідження підготовленого датасету), ML-моделі (інтелектуальний шар для трансформації медичних параметрів в оцінки ризиків), Backend / API (центральний шар взаємодії, який об'єднує всі компоненти), Database (шар персистентності для збереження динамічних даних), Frontend (SPA) (інтерфейсний шар для взаємодії користувачів), AI (Ollama) (допоміжний інтелектуальний шар для AI-асистента), Reporting (шар генерації звітів), Testing (шар забезпечення якості). Кожен блок має свою відповідальність та інтегрується з іншими для створення єдиної системи.

**Основні блоки** — основні блоки системи включають: блок ETL & Data відповідає за збір, обробку та підготовку даних від сирих NHANES-таблиць до очищеного об'єднаного датасету `health_dataset.csv`, блок EDA відповідає за дослідження підготовленого датасету для розуміння розподілів, кореляцій та закономірностей, блок ML-моделі відповідає за навчання моделей машинного навчання та трансформацію медичних параметрів в оцінки ризиків, блок Backend / API відповідає за REST API для фронтенду, виконання ML inference, управління аутентифікацією, збереження та читання даних з БД, інтеграцію з Ollama, блок Database відповідає за збереження всіх динамічних даних системи, блок Frontend (SPA) відповідає за відображення інтерфейсу користувача, обробку взаємодії, комунікацію з API, генерацію звітів, блок AI (Ollama) відповідає за надання AI-асистента для пояснення результатів та надання рекомендацій, блок Reporting відповідає за генерацію PDF-звітів з результатами прогнозування, блок Testing відповідає за перевірку коректності роботи всіх компонентів системи.

**Як вони між собою взаємодіють** — взаємодія між блоками організована за принципом односпрямованого потоку даних: ETL → EDA → ML → API → Frontend. Дані проходять від сирих таблиць через обробку та аналіз до навчених моделей, які використовуються в API для обробки запитів користувачів. Фронтенд отримує дані через API та відображає їх користувачам. БД зберігає всі динамічні дані та використовується API для персистентності. AI-асистент та звіти працюють як допоміжні сервіси, які використовують дані з основних компонентів для надання додаткової функціональності. Тестування перевіряє коректність роботи всіх компонентів на різних рівнях абстракції.

### 11.2. Frontend

Фронтенд реалізований як Single Page Application (SPA) на чистому JavaScript без використання фреймворків, що забезпечує мінімалістичний, автономний та легкий клієнт з повною функціональністю системи.

**SPA + JS** — Single Page Application працює через один HTML-файл, який містить всі секції сторінок у прихованому стані. При завантаженні сторінки бекенд завжди повертає один і той самий HTML-файл незалежно від URL, а JavaScript визначає, яку секцію потрібно показати на основі поточного URL. Всі секції присутні в DOM з самого початку, але приховані через CSS-класи та атрибут `hidden`, що дозволяє швидко перемикатися між сторінками без додаткових HTTP-запитів. Перемикання секцій виконується через додавання класу `page--active` та видалення атрибута `hidden` для активної секції та приховування всіх інших. JavaScript виконує всю логіку SPA, включаючи маршрутизацію, управління станом, роботу з API, генерацію PDF, роботу з діаграмами, інтеграцію з AI-асистентом.

**Router** — маршрутизація реалізована через власну систему без використання зовнішніх бібліотек (Navigo використовується тільки як допоміжна утиліта). Система включає об'єкт `ROUTE_SECTIONS` для мапінгу URL на ID секцій, функцію `normalizePath()` для нормалізації шляхів (видалення подвійних слешів, обробка аліасів, конвертація в нижній регістр), функцію `getSectionByPath()` для визначення секції за URL, функцію `showSectionForPath()` для активації секції з перевіркою автентифікації, функцію `syncRouteFromLocation()` для синхронізації стану з URL, функцію `activateSection()` для активації конкретної секції з оновленням навігації та локалізації. Навігація між сторінками виконується без перезавантаження сторінки через History API браузера, що забезпечує плавну навігацію без затримок перезавантаження та зберігає історію перегляду для користувача.

**Умовно-компонентна логіка** — хоча фронтенд не використовує компонентну архітектуру фреймворків, логіка організована функціонально через функції у `app.js`, які відповідають за конкретні компоненти. Компоненти включають форми (форма прогнозування, форма входу, форма реєстрації, форма профілю), діаграми (Chart.js інстанси для різних типів графіків), модальні вікна (підтвердження дій, налаштування, інформація), нотифікації (toast-сповіщення для успіхів, помилок, інформації), sidebar (навігація, перемикання теми, статуси), чати (список чатів, детальний вигляд чату, повідомлення), AI-асистент (інтерфейс чату, історія повідомлень). Кожен компонент має свої функції для ініціалізації, оновлення та очищення, що забезпечує модульність та підтримуваність коду.

### 11.3. Backend

Бекенд реалізований на FastAPI з сервісно-орієнтованою архітектурою, де кожен компонент виконує конкретні завдання та інтегрується з іншими через чітко визначені інтерфейси.

**Шари: routing, services, ML, DB** — бекенд організований за принципом багатошарової архітектури: шар routing відповідає за обробку HTTP-запитів та маршрутизацію до відповідних обробників через FastAPI роутери (`src/service/api.py` для основних ендпоінтів, `src/service/routers/` для модульних роутерів, `src/service/routes_auth.py` для автентифікації), шар services відповідає за бізнес-логіку та інтеграцію з зовнішніми сервісами (`src/service/services/assistant_llm.py` для інтеграції з Ollama, `src/service/auth_utils.py` для аутентифікації, `src/service/avatar_utils.py` для управління аватарами), шар ML відповідає за завантаження та використання ML-моделей (`src/service/model_registry.py` для реєстру моделей, завантаження чемпіонських моделей, кешування), шар DB відповідає за роботу з базою даних (`src/service/db.py` для налаштування підключення, `src/service/models.py` для ORM-моделей, `src/service/repositories.py` для CRUD операцій). Кожен шар має свою відповідальність та взаємодіє з іншими через чітко визначені інтерфейси, що забезпечує модульність та підтримуваність коду.

**Схема request → process → response** — обробка запиту в бекенді організована як послідовний pipeline: request (HTTP-запит надходить до FastAPI через ASGI сервер Uvicorn, FastAPI визначає відповідний роутер на основі URL та методу HTTP, middleware обробляє запит для CORS, нормалізації шляхів, логування), process (роутер викликає відповідний обробник ендпоінта, dependency injection створює сесію БД через `Depends(get_session)`, перевіряє автентифікацію через `Depends(get_current_user)` для захищених ендпоінтів, валідує вхідні дані через Pydantic-схеми, виконує бізнес-логіку через сервіси та репозиторії, завантажує ML-моделі через реєстр моделей для прогнозування, зберігає дані в БД через репозиторії, формує відповідь), response (обробник повертає дані у форматі Pydantic-моделі, FastAPI серіалізує відповідь у JSON, middleware обробляє відповідь для додавання заголовків, логування, HTTP-відповідь повертається клієнту). Це забезпечує чітку структуру обробки запитів та дозволяє легко додавати нові ендпоінти або змінювати логіку обробки.

### 11.4. ML layer

ML-шар відповідає за завантаження навчених моделей, виконання інференсу та повернення результатів у форматі, зручному для API та фронтенду.

**Завантаження моделей** — моделі завантажуються в пам'ять при першому використанні через реєстр моделей у `src/service/model_registry.py`. Реєстр моделей завантажує champion-моделі (з пріоритетом каліброваних версій) для кожної цільової змінної (diabetes_present, obesity_present) з директорії `artifacts/models/{target}/`. Моделі зберігаються у форматі `.joblib` та завантажуються через `joblib.load()`. Реєстр кешує завантажені моделі в пам'яті для швидкого доступу при подальших запитах, що забезпечує швидкість інференсу без необхідності повторного завантаження з диску. Моделі також можуть бути завантажені за конкретним ключем (наприклад, "logreg", "random_forest") через функцію `load_model()`, якщо користувач вибрав конкретну модель замість автоматичного вибору champion.

**Інференс** — інференс виконується при запиті на прогноз через ендпоінт `/predict`. Процес включає кілька кроків: отримання вхідних параметрів користувача (вік, стать, ІМТ, тиск, глюкоза, холестерин) через Pydantic-схему `PredictRequest`, перетворення JSON-даних у pandas DataFrame, передачу через pipeline моделі (який виконує імпутацію пропущених значень через `SimpleImputer`, стандартизацію числових ознак через `StandardScaler`, one-hot encoding категоріальних ознак через `OneHotEncoder`), отримання ймовірності ризику через `pipeline.predict_proba()`, визначення категорії ризику (низький, середній, високий) на основі ймовірності через функцію `get_risk_bucket()`, обчислення топ-5 факторів впливу через функцію `calculate_top_factors_simple()`, формування JSON-відповіді з результатами. Інференс виконується синхронно, але FastAPI обробляє його в thread pool для неблокуючої обробки інших запитів.

**Повернення результатів** — результати інференсу повертаються у форматі JSON через Pydantic-схему `PredictResponse`, яка включає поля: `probability` (ймовірність ризику 0-1), `risk_bucket` (категорія ризику: "low", "medium" або "high"), `top_factors` (список факторів з їх впливом у відсотках), `model_name` (назва використаної моделі), `target` (цільова змінна). Відповідь також може включати метадані моделі (версія, дата навчання, метрики) для відображення на фронтенді. Результати зберігаються в БД через `add_prediction_history()` для історії прогнозів (якщо користувач автентифікований), що дозволяє користувачам переглядати свої попередні прогнози та аналізувати зміни ризиків у часі.

### 11.5. База даних

База даних виконує роль persistence layer, який зберігає всі динамічні дані та забезпечує персистентність між сесіями користувачів.

**Persistence layer** — база даних забезпечує персистентність даних через SQLite файл `data/app.db`, який зберігає всі дані в одному файлі на диску. Дані зберігаються структуровано через таблиці з визначеними полями, типами, обмеженнями та зв'язками між таблицями через foreign keys. SQLModel ORM забезпечує абстракцію над SQL, дозволяючи працювати з даними як з Python-об'єктами, що спрощує роботу з БД та забезпечує типобезпеку. Репозиторійний шар у `src/service/repositories.py` інкапсулює логіку роботи з БД, надаючи функції для CRUD операцій (створення, читання, оновлення, видалення) для всіх сутностей, що забезпечує консистентність та спрощує підтримку коду.

**Принцип збереження та читання** — збереження даних виконується через транзакції SQLite, які гарантують атомарність операцій (всі зміни виконуються разом або не виконуються взагалі). При створенні або оновленні запису сесія БД створюється через `get_session()`, дані додаються або оновлюються через SQLModel-моделі, транзакція комітиться через `session.commit()` при успішному завершенні або відкочується через `session.rollback()` при помилках. Читання даних виконується через SQL-запити через SQLModel (наприклад, `select(User).where(User.email == email)`), які автоматично конвертуються в SQL та виконуються через SQLAlchemy engine. Результати повертаються як Python-об'єкти, які можуть бути серіалізовані в JSON для API або використані безпосередньо в коді. Це забезпечує надійність збереження даних та швидкість читання через індекси на ключових полях.

### 11.6. AI-асистент

AI-асистент інтегрується з локальним Ollama сервером для надання персоналізованих рекомендацій щодо здоров'я на основі результатів прогнозування.

**Взаємодія з Ollama** — бекенд взаємодіє з Ollama через HTTP API через модуль `src/service/services/assistant_llm.py`. Модуль формує контекст про стан здоров'я користувача на основі останнього прогнозу через `build_health_context()`, який отримує дані з БД про останній прогноз користувача (цільова змінна, ймовірність, категорія ризику, ключові фактори) та форматує їх у текстовий контекст. Модуль конструює промпт для LLM з інструкціями та контекстом через `build_assistant_prompt()`, який включає системний промпт з інструкціями (асистент не ставить діагнозів, не призначає лікування), контекст користувача та запит користувача. Модуль викликає Ollama через HTTP POST-запит до `http://localhost:11434/api/generate` через `call_ollama()`, який відправляє промпт до Ollama та отримує відповідь від LLM. Відповідь обробляється та зберігається в БД через `add_message()` для історії діалогів.

**Обробка історії** — історія діалогів з AI-асистентом зберігається в таблиці `assistantmessage` для кожного користувача. Історія включає всі попередні повідомлення користувача та асистента, зберігає порядок хронологічно, включає timestamps для кожного повідомлення та може бути пов'язана з конкретним прогнозом через `prediction_id` для контексту. Історія завантажується при активації сторінки асистента через ендпоінт `/assistant/history`, який повертає всі повідомлення користувача, відсортовані за часом. Історія використовується для відображення діалогу на фронтенді та може бути використана для покращення контексту майбутніх відповідей (хоча наразі контекст формується тільки на основі останнього прогнозу).

**Алгоритм відповіді** — алгоритм формування відповіді AI-асистента включає кілька кроків: отримання повідомлення користувача через ендпоінт `/assistant/chat`, формування контексту про стан здоров'я користувача на основі останнього прогнозу (або конкретного прогнозу, якщо вказано `prediction_id`), конструювання промпту з інструкціями, контекстом та запитом користувача, виклик Ollama через HTTP API для генерації відповіді, обробка відповіді від Ollama (яка може бути у форматі NDJSON для streaming), збереження повідомлення користувача та відповіді асистента в БД, повернення відповіді фронтенду для відображення в чаті. Алгоритм забезпечує персоналізовані рекомендації на основі конкретних результатів прогнозування користувача та контексту його здоров'я.

**Кешування контексту** — контекст про стан здоров'я користувача формується на основі останнього прогнозу з БД через `get_latest_prediction()`, який отримує найновіший запис з таблиці `predictionhistory` для користувача. Контекст включає цільову змінну (діабет або ожиріння), ймовірність ризику, категорію ризику (низький, середній, високий), топ фактори впливу та вхідні параметри прогнозу. Контекст кешується в пам'яті на рівні запиту для уникнення повторних запитів до БД, але не зберігається між різними запитами для забезпечення актуальності даних. В майбутньому можна додати кешування контексту на рівні сесії користувача для покращення продуктивності при багаторазових запитах до асистента.

## 12. AI-МОДЕЛЬ OLLAMA

### 12.1. Що таке Ollama

Ollama — це локальний сервер для запуску великих мовних моделей (LLM) без необхідності підключення до хмарних сервісів, що забезпечує приватність, швидкість та незалежність від зовнішніх сервісів.

**Локальна LLM** — Ollama дозволяє запускати мовні моделі (наприклад, Llama3, Mistral, Phi) локально на комп'ютері користувача або сервері, без необхідності відправляти дані на зовнішні сервіси. Моделі завантажуються та запускаються через HTTP API, що дозволяє легко інтегрувати їх у додатки. Ollama автоматично керує завантаженням моделей, їх кешуванням у пам'яті та обробкою запитів, що спрощує роботу з LLM для розробників.

**Чому обрана** — Ollama обрана для проєкту HealthRisk.AI через кілька переваг: приватність — всі дані користувачів (результати прогнозів, запити до асистента) залишаються локально, не передаються на зовнішні сервіси, що критично важливо для медичних даних; швидкість — локальна обробка забезпечує низьку латентність без залежності від мережевих затримок; незалежність — система працює без необхідності інтернет-з'єднання для AI-асистента, що забезпечує стабільність роботи; безкоштовність — Ollama та багато моделей безкоштовні, не потрібні підписки на хмарні сервіси; гнучкість — можна використовувати різні моделі залежно від потреб, налаштовувати параметри генерації, додавати власні промпти; простота інтеграції — HTTP API дозволяє легко інтегрувати Ollama у будь-який додаток без складних налаштувань.

**Як працює інтеграція** — інтеграція з Ollama реалізована через модуль `src/service/services/assistant_llm.py`, який виконує HTTP-запити до локального Ollama сервера на адресі `http://localhost:11434/api/generate`. Модуль формує контекст про стан здоров'я користувача на основі останнього прогнозу, конструює промпт з інструкціями та контекстом, відправляє запит до Ollama через `requests.post()`, обробляє відповідь (яка може бути у форматі NDJSON для streaming або звичайного JSON), зберігає повідомлення в БД та повертає відповідь API. Інтеграція проста та не вимагає складних налаштувань, достатньо запустити Ollama сервер локально.

### 12.2. Архітектура інтеграції

Архітектура інтеграції з Ollama організована через модуль `assistant_llm.py`, який інкапсулює всю логіку взаємодії з LLM та забезпечує чистий інтерфейс для API.

**Виклики через API** — взаємодія з Ollama виконується через HTTP POST-запити до ендпоінту `/api/generate` на локальному сервері `http://localhost:11434`. Запит містить JSON з полями: `model` (назва моделі, наприклад "llama3"), `prompt` (текст промпту з інструкціями, контекстом та запитом користувача), `stream` (boolean, чи використовувати streaming відповідь), `options` (параметри генерації: температура, top_p, max_tokens). Відповідь від Ollama може бути у форматі звичайного JSON (якщо `stream=false`) або NDJSON (якщо `stream=true`), де кожен рядок містить частину відповіді. Модуль обробляє обидва формати та формує фінальну відповідь для API.

**Обробка відповідей** — обробка відповіді від Ollama включає кілька кроків: отримання HTTP-відповіді від Ollama через `requests.post()`, перевірка статус-коду (200 для успішних, інші для помилок), парсинг JSON або NDJSON відповіді, витягування тексту відповіді з поля `response`, обробка помилок (таймаути, помилки з'єднання, помилки Ollama), формування структурованої відповіді для API. Якщо відповідь у форматі NDJSON (streaming), модуль обробляє кожен рядок та збирає повну відповідь. Обробка включає обрізання зайвих пробілів, видалення спеціальних символів та форматування тексту для відображення на фронтенді.

**Токенізація** — Ollama автоматично виконує токенізацію вхідного тексту (промпту) та генерацію токенів для відповіді, тому модуль `assistant_llm.py` не виконує токенізацію безпосередньо. Модуль передає повний текст промпту до Ollama, який сам виконує токенізацію через свою модель. Параметри генерації (наприклад, `max_tokens`) контролюють максимальну кількість токенів у відповіді, що дозволяє обмежити довжину відповіді. Модуль не потребує знання про внутрішню структуру токенізації Ollama, що спрощує інтеграцію.

**Формування prompts** — формування промптів виконується через функцію `build_assistant_prompt()` у модулі `assistant_llm.py`. Промпт складається з кількох частин: системний промпт з інструкціями для асистента (асистент не ставить діагнозів, не призначає лікування, надає загальні рекомендації), контекст про стан здоров'я користувача (формується через `build_health_context()` на основі останнього прогнозу), запит користувача (текст повідомлення від користувача). Промпт формується як структурований текст з чіткими розділами, що забезпечує зрозумілість для LLM та коректність відповідей. Системний промпт включає обмеження та правила для забезпечення безпеки та відповідальності відповідей.

### 12.3. Використання у чаті

AI-асистент використовується у чаті для надання персоналізованих рекомендацій щодо здоров'я на основі результатів прогнозування користувача.

**Логіка підказок** — підказки для користувача формуються на основі контексту його останнього прогнозу через `build_health_context()`, який отримує дані з БД про останній прогноз (цільова змінна, ймовірність, категорія ризику, топ фактори). Контекст форматується як текстовий опис стану здоров'я користувача, який передається до LLM разом із запитом користувача. LLM використовує цей контекст для формування персоналізованих рекомендацій, які враховують конкретні результати прогнозування користувача. Підказки можуть включати рекомендації щодо зменшення ризиків, зміни способу життя, консультації з лікарем та інші корисні поради.

**Контекстні відповіді** — відповіді асистента формуються на основі контексту останнього прогнозу користувача, що забезпечує релевантність та персоналізацію. Контекст включає інформацію про цільову змінну (діабет або ожиріння), ймовірність ризику, категорію ризику (низький, середній, високий), топ фактори впливу (наприклад, високий ІМТ, підвищена глюкоза) та вхідні параметри прогнозу (вік, стать, артеріальний тиск). LLM використовує цей контекст для формування відповідей, які враховують конкретну ситуацію користувача та надають корисні рекомендації. Контекст оновлюється при кожному новому прогнозі, що забезпечує актуальність відповідей.

**Діалогова пам'ять** — історія діалогів з AI-асистентом зберігається в таблиці `assistantmessage` для кожного користувача, що дозволяє відстежувати попередні повідомлення та відповіді. Історія включає всі повідомлення користувача та асистента, зберігає порядок хронологічно, включає timestamps для кожного повідомлення та може бути пов'язана з конкретним прогнозом через `prediction_id` для контексту. Наразі контекст формується тільки на основі останнього прогнозу, але в майбутньому можна додати використання повної історії діалогів для покращення контексту та забезпечення послідовності розмови. Історія завантажується при активації сторінки асистента через ендпоінт `/assistant/history` та відображається на фронтенді для користувача.

### 12.4. Статуси та monitoring

Моніторинг стану Ollama виконується через ендпоінт `/assistant/health`, який перевіряє доступність сервера, вимірює латентність та повертає статус для відображення на фронтенді.

**Як перевіряється статус Ollama** — ендпоінт `/assistant/health` виконує HTTP-запит до локального Ollama сервера (`http://localhost:11434/api/generate`) з тестовим промптом ("ok"), вимірює латентність (час відповіді), перевіряє наявність поля `response` у відповіді. Запит виконується з таймаутом 10 секунд для запобігання довгим очікуванням. Результат повертається як JSON з полями: `status` ("online", "offline", "timeout", "error"), `is_available` (boolean), `latency_ms` (мілісекунди), `error` (текст помилки, якщо є), `timestamp`. Обробляються різні типи помилок: `Timeout` (таймаут 10 секунд), `ConnectionError` (Ollama не запущений), інші помилки (неочікувані помилки). Ендпоінт викликається періодично з фронтенду (кожні 10 секунд) для моніторингу стану Ollama.

**Чому інколи "лежить"** — Ollama може бути недоступна через кілька причин: сервер не запущений — якщо Ollama сервер не запущений локально, всі запити будуть повертати `ConnectionError`; таймаути — якщо Ollama завантажує велику модель або обробляє складний запит, він може не встигнути відповісти за 10 секунд, що призводить до таймауту; помилки моделі — якщо модель не завантажена або пошкоджена, Ollama може повертати помилки; нестача ресурсів — якщо на комп'ютері не вистачає пам'яті або CPU, Ollama може працювати повільно або не працювати взагалі; конфлікти портів — якщо порт 11434 зайнятий іншим процесом, Ollama не зможе запуститися. Для вирішення проблем потрібно перевірити, чи запущений Ollama сервер, чи завантажена модель, чи достатньо ресурсів системи.

**Як відображається статус на frontend** — статус Ollama відображається на сторінці `/api-status` через індикатори стану (зелений для онлайн, червоний для офлайн, жовтий для таймауту), графіки латентності (час відгуку в мілісекундах), детальну статистику (останній статус, середня латентність, кількість помилок), повідомлення про помилки (текст помилки, час останньої помилки). Фронтенд робить періодичні запити (кожні 10 секунд) до ендпоінту `/assistant/health`, зберігає історію статусів для побудови графіків та оновлює UI при зміні статусу. Індикатори стану відображаються у вкладці "Ollama" на сторінці `/api-status` разом з інформацією про API та БД.

## 13. Security (Безпека)

Система безпеки проєкту HealthRisk.AI організована через багатошаровий підхід, що забезпечує захист даних користувачів, API та ML-моделей від несанкціонованого доступу та зловмисних атак.

**JWT-токени** — система аутентифікації використовує JSON Web Tokens (JWT) для забезпечення безпечного доступу до захищених ендпоінтів. JWT токени генеруються при успішному логіні через функцію `create_access_token()` у модулі `auth_utils.py`, яка створює токен з полями: `sub` (email користувача), `exp` (час закінчення, за замовчуванням 60 хвилин), `iat` (час створення). Токен підписується через секретний ключ (SECRET_KEY з environment variables) за алгоритмом HS256, що забезпечує цілісність та автентичність токену. Токен передається клієнту у відповіді API та зберігається у `localStorage` на фронтенді для подальшого використання. При кожному захищеному запиті токен передається у заголовку `Authorization: Bearer <token>`, де він перевіряється через `get_current_user()` для отримання користувача з БД.

**Refresh/Access** — наразі система використовує тільки access токени без окремого refresh механізму. Access токени мають термін дії 60 хвилин, після чого користувач повинен увійти знову. В майбутньому можна додати refresh токени з довшим терміном дії (наприклад, 7 днів), які зберігаються у HTTP-only cookies для безпеки та використовуються для автоматичного оновлення access токенів без необхідності повторного логіну. Refresh токени повинні бути зберігані на сервері (у БД або Redis) для можливості відкликання при необхідності.

**CSRF — чому не потрібен у SPA** — Cross-Site Request Forgery (CSRF) захист не потрібен у Single Page Application (SPA), оскільки SPA використовує AJAX-запити через JavaScript, які автоматично включають cookies та заголовки з того ж домену. CSRF атаки працюють через міжсайтові запити з інших доменів, але SPA завжди робить запити з того ж домену, де розміщений фронтенд, тому CSRF токени не потрібні. Додатково, CORS налаштування на бекенді обмежують запити тільки з дозволених доменів, що забезпечує додатковий захист від міжсайтових атак. Для додаткової безпеки можна використовувати SameSite cookies та Content Security Policy (CSP) заголовки.

**Валідація даних** — валідація вхідних даних виконується на кількох рівнях: Pydantic схеми на рівні API для валідації структури, типів, діапазонів та обов'язковості полів у вхідних даних (наприклад, `PredictRequest`, `LoginRequest`, `RegisterRequest`), валідація на рівні бізнес-логіки для перевірки коректності значень (наприклад, перевірка email на унікальність, перевірка пароля на мінімальну довжину), валідація на рівні БД через обмеження (unique, not null, foreign keys) для забезпечення цілісності даних. Pydantic автоматично повертає детальні помилки валідації (HTTP 422) з описом проблем у кожному полі, що дозволяє фронтенду відображати зрозумілі повідомлення користувачам. Валідація забезпечує, що тільки коректні дані потрапляють у систему та обробляються ML-моделями.

**Валідація моделей** — ML-моделі валідуються на кількох етапах: валідація при завантаженні через перевірку наявності файлів моделей, коректності структури pipeline, наявності необхідних компонентів (imputer, scaler, encoder, classifier), валідація вхідних даних перед інференсом через перевірку наявності обов'язкових ознак, діапазонів значень, типів даних, валідація вихідних даних після інференсу через перевірку діапазонів ймовірностей (0-1), наявності всіх необхідних полів у відповіді, коректності категорій ризику. Валідація забезпечує, що моделі працюють коректно та повертають валідні результати навіть при нестандартних вхідних даних. Помилки валідації обробляються та повертаються як HTTP 500 з детальними повідомленнями для логування.

**Робота з паролями** — паролі користувачів ніколи не зберігаються у відкритому вигляді, а тільки як bcrypt-хеші через функцію `get_password_hash()` у модулі `auth_utils.py`. Bcrypt використовує salt (випадкову сіль для кожного пароля) та багато ітерацій хешування (за замовчуванням 12 раундів), що робить brute-force атаки практично неможливими. При логіні пароль перевіряється через `verify_password()`, яка порівнює хеш введеного пароля з хешем у БД без зберігання оригінального пароля. Паролі передаються через HTTPS (якщо налаштовано) для захисту від перехоплення під час передачі. Мінімальна довжина пароля та складність можуть бути додані через валідацію Pydantic для забезпечення безпеки.

**Захист API** — захист API організується через кілька механізмів: аутентифікація через JWT токени для захищених ендпоінтів (більшість ендпоінтів вимагають автентифікованого користувача через `Depends(get_current_user)`), CORS налаштування для обмеження запитів тільки з дозволених доменів, валідація вхідних даних через Pydantic для запобігання injection атакам, обробка помилок без розкриття внутрішніх деталей системи (повідомлення про помилки не містять стеку викликів або шляхів до файлів), rate limiting (може бути додано в майбутньому) для запобігання DDoS атакам. Публічні ендпоінти (наприклад, `/health`, `/api-status`) не вимагають аутентифікації, але не повертають чутливі дані. Захист забезпечує, що тільки авторизовані користувачі можуть отримувати доступ до захищених ресурсів та виконувати операції.

**Роль ізоляції ML-коду** — ML-код ізольований від основного API через модуль `model_registry.py`, який інкапсулює всю логіку завантаження та використання моделей. Ізоляція забезпечує: безпеку — моделі не можуть бути завантажені або модифіковані через API, вони доступні тільки через внутрішній код, захист від injection — вхідні дані валідуються перед передачею до моделей, моделі не виконують довільний код, тільки обробляють структуровані дані, контроль доступу — тільки авторизовані користувачі можуть виконувати прогнози через API, моделі не доступні напряму, тестованість — ML-код може бути протестований ізольовано від API, що спрощує тестування та налагодження. Ізоляція забезпечує, що ML-моделі використовуються тільки через безпечні інтерфейси та не можуть бути скомпрометовані через API.

**Чому PDF генерується локально** — PDF-звіти генеруються на фронтенді через jsPDF замість генерації на бекенді через кілька причин: безпека — дані користувачів не передаються на сервер для генерації PDF, всі дані залишаються локально у браузері, що зменшує ризик витоку даних, продуктивність — генерація PDF на клієнті не навантажує сервер, що дозволяє обробляти більше запитів одночасно, приватність — користувач має повний контроль над своїми даними, PDF генерується локально без передачі на сервер, швидкість — генерація PDF на клієнті швидша, оскільки не потрібні мережеві затримки для передачі даних на сервер та отримання готового PDF, масштабованість — генерація PDF на клієнті не вимагає додаткових ресурсів сервера, що дозволяє масштабувати систему без збільшення навантаження на сервер. Генерація PDF на фронтенді забезпечує безпеку, приватність та продуктивність системи.

## 14. DevOps / Deploy / Infrastructure

Інфраструктура проєкту HealthRisk.AI організована для локальної розробки та тестування з можливістю розгортання на продакшен сервери.

**Як запускати систему локально** — система запускається локально через кілька кроків: встановлення залежностей через `pip install -r requirements.txt` для Python залежностей, налаштування environment variables через копіювання `.env.example` у `.env` та заповнення необхідних значень (SECRET_KEY, DATABASE_URL), ініціалізація БД через автоматичне створення при першому запуску або через `make init-db` для ручної ініціалізації, запуск FastAPI сервера через `make run` або `uvicorn src.service.api:app --reload` для розробки з auto-reload, запуск Ollama сервера локально через `ollama serve` (якщо Ollama встановлена) для AI-асистента, відкриття браузера на `http://localhost:8000` для доступу до вебінтерфейсу. Система автоматично створює БД при першому запуску та налаштовує всі необхідні компоненти.

**Makefile** — Makefile містить команди для автоматизації розробки та розгортання: `make run` для запуску FastAPI сервера з auto-reload, `make test` для запуску всіх тестів, `make test-backend-unit` для запуску unit тестів бекенду, `make test-coverage` для запуску тестів з покриттям коду, `make init-db` для ініціалізації БД, `make clean` для очищення тимчасових файлів, `make lint` для перевірки коду через linter. Makefile спрощує роботу з проєктом та забезпечує консистентність команд між різними розробниками. Команди можуть бути розширені для додаткових завдань (наприклад, міграції БД, генерація документації, деплой).

**Навіщо Ollama у dev-середовищі** — Ollama потрібна у dev-середовищі для тестування та розробки AI-асистента, оскільки асистент вимагає локального LLM сервера для генерації відповідей. Без Ollama AI-асистент не працює, а ендпоінт `/assistant/chat` повертає помилки. Ollama дозволяє розробникам тестувати повний функціонал системи локально без необхідності підключення до хмарних сервісів. Для розробки можна використовувати легкі моделі (наприклад, Phi) для швидкої генерації відповідей, а для тестування — повні моделі (наприклад, Llama3) для реалістичних відповідей. Ollama може бути запущена у Docker контейнері для ізоляції або локально на комп'ютері розробника.

**Як працюють environment variables** — environment variables зберігаються у файлі `.env` у корені проєкту та завантажуються через `python-dotenv` при старті додатку. Основні змінні включають: `SECRET_KEY` (секретний ключ для JWT токенів, повинен бути унікальним та випадковим), `DATABASE_URL` (URL підключення до БД, за замовчуванням `sqlite:///data/app.db`), `OLLAMA_BASE_URL` (URL Ollama сервера, за замовчуванням `http://localhost:11434`), `DEBUG` (режим відлагодження, за замовчуванням `False`). Змінні завантажуються через `load_dotenv()` у модулі `db.py` та використовуються через `os.getenv()` у коді. Файл `.env` не комітиться у Git (доданий у `.gitignore`) для безпеки, а `.env.example` містить приклади значень для нових розробників.

**Які сервіси запускаються** — система вимагає запуску кількох сервісів: FastAPI сервер (основний бекенд, обробляє HTTP-запити, виконує ML inference, працює з БД), Ollama сервер (локальний LLM сервер для AI-асистента, опційний, якщо не потрібен асистент), веб-сервер (для розробки використовується Uvicorn, для продакшену можна використовувати Gunicorn з Uvicorn workers). FastAPI сервер є основним сервісом та повинен бути запущений завжди. Ollama сервер потрібен тільки для AI-асистента та може бути запущений окремо. Всі сервіси можуть бути запущені локально або в Docker контейнерах для ізоляції.

**Як розгортати систему** — розгортання системи на продакшен сервер включає кілька кроків: підготовка сервера (встановлення Python, залежностей, налаштування environment variables), копіювання файлів проєкту на сервер (через Git, FTP або інші методи), ініціалізація БД через `make init-db` або автоматично при першому запуску, запуск FastAPI сервера через systemd service або process manager (наприклад, PM2, Supervisor), налаштування reverse proxy (наприклад, Nginx) для обробки HTTP-запитів та SSL сертифікатів, запуск Ollama сервера (якщо потрібен AI-асистент), налаштування моніторингу та логування. Для продакшену рекомендується використовувати Gunicorn з Uvicorn workers для кращої продуктивності та стабільності. Система може бути розгорнута на хмарних платформах (наприклад, AWS, Google Cloud, Azure) або на власних серверах.

**Backup файлів** — резервне копіювання включає кілька компонентів: БД файл (`data/app.db`) — найважливіший файл, який містить всі дані користувачів, історію прогнозів, чати, повідомлення, повинен копіюватися регулярно (наприклад, щодня) через `cp data/app.db backups/app_$(date +%Y%m%d).db`, ML моделі (`artifacts/models/`) — навчені моделі, які важко відновити, повинні копіюватися при змінах, environment variables (`.env`) — чутливі дані, повинні зберігатися безпечно, конфігураційні файли (`configs/`) — налаштування проєкту, повинні копіюватися при змінах. Backup може виконуватися вручну або автоматично через cron jobs або скрипти. Backup файли повинні зберігатися на окремому сервері або у хмарному сховищі для захисту від втрати даних.

**Логи** — логування в системі виконується через стандартний Python logging модуль з різними рівнями (DEBUG, INFO, WARNING, ERROR, CRITICAL). Логи записуються у файли (наприклад, `logs/app.log`) або виводяться у консоль залежно від налаштувань. Логування включає: HTTP-запити (URL, метод, статус-код, час обробки), помилки (stack traces, деталі помилок, контекст), ML inference (час виконання, використані моделі, результати), БД операції (запити, помилки, транзакції), AI-асистент (запити до Ollama, відповіді, помилки). Логи можуть бути інтегровані з зовнішніми системами моніторингу (наприклад, ELK Stack, Sentry) для аналізу та алертів. Для продакшену рекомендується використовувати структуровані логи (JSON) для легшого парсингу та аналізу.

## 15. Інтернаціоналізація (i18n)

Система інтернаціоналізації проєкту HealthRisk.AI забезпечує підтримку кількох мов для вебінтерфейсу та дозволяє легко додавати нові мови.

**Чому вона потрібна** — інтернаціоналізація потрібна для забезпечення доступності системи для користувачів з різних країн та мов, що розширює аудиторію проєкту та покращує користувацький досвід. Для магістерського проєкту інтернаціоналізація демонструє професійний підхід до розробки та готовність системи до міжнародного використання. Підтримка української та англійської мов забезпечує доступність для українських користувачів та міжнародної аудиторії.

**Структура JSON-файлів** — переклади зберігаються у JSON-файлах у директорії `src/service/web/locales/` з назвами `uk.json` (українська) та `en.json` (англійська). Кожен файл містить структуровані ключі для всіх текстів у додатку, організовані за функціональними групами: `forms` (форми, поля вводу, кнопки), `history` (історія прогнозів, фільтри, сортування), `charts` (діаграми, легенди, підписи), `assistant` (AI-асистент, повідомлення, підказки), `errors` (повідомлення про помилки, валідація), `navigation` (меню, посилання, заголовки), `common` (загальні тексти, підтвердження, сповіщення). Структура ключів ієрархічна через вкладені об'єкти (наприклад, `forms.targets.diabetes_present`, `history.empty.title`), що дозволяє легко організувати та знаходити переклади. Кожен ключ містить текст перекладу для відповідної мови.

**Принцип завантаження мов** — мови завантажуються через модуль `i18n.js` на фронтенді, який визначає поточну мову користувача з `localStorage` (ключ `healthrisk_lang`) або з налаштувань браузера (через `navigator.language`). Модуль завантажує відповідний JSON-файл через `fetch()` та зберігає переклади у пам'яті для швидкого доступу. Якщо мова не підтримується, використовується українська як fallback. Завантаження виконується при ініціалізації сторінки та може бути повторено при зміні мови. Модуль надає функцію `i18n.t(key, vars)` для отримання перекладу за ключем з опційними змінними для інтерполяції (наприклад, `i18n.t('history.count', {count: 5})`).

**Як перемикається мова** — перемикання мови виконується через кнопку у sidebar або налаштуваннях, яка викликає функцію `setLanguage(lang)` у модулі `i18n.js`. Функція зберігає вибрану мову у `localStorage` (ключ `healthrisk_lang`), завантажує відповідний JSON-файл з перекладами, викликає `applyTranslations()` для оновлення всіх текстів на сторінці та оновлює атрибут `lang` на елементі `<html>` для правильного відображення тексту. Перемикання мови не вимагає перезавантаження сторінки, всі тексти оновлюються динамічно через JavaScript. Поточна мова зберігається між сесіями через `localStorage`, тому користувач не потребує повторного вибору мови при наступному відвідуванні.

**Локалізація атрибутів** — локалізація атрибутів HTML-елементів виконується через спеціальні атрибути з префіксом `data-i18n-`: `data-i18n-title` для атрибута `title`, `data-i18n-placeholder` для атрибута `placeholder`, `data-i18n-aria-label` для атрибута `aria-label`, `data-i18n-alt` для атрибута `alt` у зображень. Функція `applyTranslations()` обходить всі елементи з цими атрибутами, знаходить переклад через `i18n.t()` та встановлює його як значення відповідного атрибута. Це забезпечує локалізацію не тільки видимого тексту, але й допоміжних атрибутів для доступності та UX. Локалізація атрибутів виконується разом з локалізацією тексту при завантаженні сторінки та зміні мови.

**Локалізація UI компонентів** — UI компоненти локалізуються через атрибут `data-i18n` на HTML-елементах, який містить ключ перекладу. Функція `applyTranslations()` обходить всі елементи з цим атрибутом, знаходить переклад через `i18n.t()` та встановлює його як `textContent` елемента. Компоненти включають: форми (labels, placeholders, кнопки, повідомлення валідації), навігацію (меню, посилання, заголовки), нотифікації (toast-сповіщення для успіхів, помилок, інформації), модальні вікна (заголовки, тексти, кнопки підтвердження), діаграми (легенди, підписи осей, tooltips), AI-асистент (повідомлення, підказки, статуси). Локалізація виконується при ініціалізації компонентів та оновлюється при зміні мови.

**Підтримка динамічних текстів** — динамічні тексти (які містять змінні, наприклад, кількість записів, імена користувачів) локалізуються через функцію `i18n.t(key, vars)`, яка приймає ключ перекладу та об'єкт зі змінними для інтерполяції. Наприклад, `i18n.t('history.count', {count: 5})` замінює `{count}` у перекладі на значення `5`. Переклади можуть містити плейсхолдери у форматі `{variable_name}`, які замінюються значеннями з об'єкта `vars`. Це дозволяє створювати динамічні тексти з змінними без необхідності конкатенації рядків. Динамічні тексти використовуються для відображення кількості записів, імен користувачів, дат, часу та інших змінних значень.

**Масштабування під нові мови** — додавання нової мови вимагає кілька кроків: створення нового JSON-файлу у директорії `locales/` з тією ж структурою ключів, що й `uk.json` (наприклад, `de.json` для німецької), додавання коду мови до масиву `SUPPORTED_LANGUAGES` у `i18n.js` (наприклад, `['uk', 'en', 'de']`), додавання кнопки перемикання мови у UI (якщо потрібно), тестування перекладів для перевірки коректності та повноти. Модуль автоматично завантажує переклади для нової мови та використовує українську як fallback для відсутніх ключів. Структура ключів залишається незмінною, що забезпечує консистентність між мовами. Додавання нової мови не вимагає змін у коді, достатньо додати JSON-файл з перекладами.

## 16. Оптимізація продуктивності

Оптимізація продуктивності проєкту HealthRisk.AI організована на кількох рівнях для забезпечення швидкої роботи системи та комфортного користувацького досвіду.

**Чому SPA потребує оптимізації** — Single Page Application потребує оптимізації через кілька причин: великий розмір JavaScript файлу (`app.js` має близько 14667 рядків), що може сповільнити завантаження сторінки, велика кількість DOM-елементів (всі секції присутні в DOM з самого початку), що може сповільнити рендеринг, багаторазові API-запити для отримання даних, що може створювати затримки, складні операції (генерація PDF, рендеринг діаграм), які можуть блокувати UI, відсутність кешування даних між сесіями, що призводить до повторних запитів. Оптимізація забезпечує швидке завантаження сторінки, плавну навігацію, швидкі відповіді на дії користувача та ефективне використання ресурсів браузера.

**Оптимізація рендеру Canvas** — рендеринг Canvas для діаграм Chart.js оптимізується через кілька механізмів: використання `requestAnimationFrame` для плавної анімації та оновлення діаграм, обмеження частоти оновлень діаграм (наприклад, не більше 60 FPS), використання `will-change` CSS-властивості для оптимізації рендерингу, обмеження кількості одночасних діаграм на сторінці (показувати тільки видимі діаграми), використання `resizeObserver` для оптимізації зміни розміру діаграм, кешування даних діаграм для уникнення повторних обчислень, використання `debounce` для обмеження частоти оновлень при зміні фільтрів. Оптимізація забезпечує плавний рендеринг діаграм без лагів та блокування UI.

**Оптимізація PDF** — генерація PDF оптимізується через кілька підходів: асинхронне завантаження шрифтів (DejaVuSans) для уникнення блокування UI, використання `requestIdleCallback` для генерації PDF у вільний час браузера, обмеження розміру зображень діаграм (масштабування перед додаванням до PDF), використання `canvas.toDataURL()` з оптимальними параметрами якості для балансу між розміром та якістю, покрокова генерація PDF (генерація по одній сторінці за раз) для уникнення блокування UI, відображення прогресу генерації для інформування користувача. Оптимізація забезпечує швидку генерацію PDF без блокування UI та зберігає якість зображень.

**Мемоізація запитів** — мемоізація API-запитів реалізується через кешування відповідей у пам'яті на рівні запиту для уникнення повторних запитів з однаковими параметрами. Мемоізація включає: кешування результатів прогнозування для однакових вхідних параметрів (якщо користувач повторно запитує прогноз з тими ж даними), кешування історії прогнозів для уникнення повторних запитів до БД, кешування статусів API/БД/Ollama для обмеження частоти перевірок, кешування даних користувача (профіль, налаштування) для уникнення повторних запитів. Мемоізація забезпечує швидкість відповідей та зменшує навантаження на сервер. Кеш може бути очищений при зміні даних або при виході користувача.

**Кешування AI** — кешування відповідей AI-асистента реалізується через зберігання історії діалогів у БД та використання її для формування контексту без повторних запитів до Ollama для однакових питань. Кешування включає: зберігання повідомлень користувача та відповідей асистента у таблиці `assistantmessage` для подальшого використання, використання історії діалогів для покращення контексту майбутніх відповідей, кешування контексту про стан здоров'я користувача на рівні запиту для уникнення повторних запитів до БД. Кешування забезпечує швидкість відповідей та зменшує навантаження на Ollama. В майбутньому можна додати кешування відповідей для однакових питань для подальшого покращення продуктивності.

**Оптимізація JS** — оптимізація JavaScript коду включає кілька підходів: мінімізація коду через видалення коментарів, пробілів та невикористовуваного коду (через tools типу UglifyJS або Terser), розділення коду на модулі для lazy loading (завантаження тільки потрібних модулів), використання `async/defer` для скриптів, які не блокують рендеринг, обмеження глибини вкладеності функцій для покращення читабельності та продуктивності, використання `requestAnimationFrame` для анімацій та оновлень UI, оптимізація циклів та обробки масивів через ефективні алгоритми. Оптимізація забезпечує швидке виконання коду та зменшує час завантаження сторінки.

**Оптимізація завантаження сторінок** — оптимізація завантаження сторінок включає кілька механізмів: lazy loading секцій (завантаження тільки активної секції при першому відвідуванні), використання `IntersectionObserver` для lazy loading зображень та діаграм, кешування статичних ресурсів (CSS, JS, шрифти) через HTTP headers (Cache-Control), використання CDN для швидкого завантаження бібліотек (Chart.js, jsPDF, Lucide), мінімізація кількості HTTP-запитів через об'єднання файлів, використання `preload` для критичних ресурсів, оптимізація порядку завантаження скриптів (критичні скрипти спочатку). Оптимізація забезпечує швидке завантаження сторінки та покращує користувацький досвід. В майбутньому можна додати Service Workers для офлайн-роботи та кешування ресурсів. 

# Частина 5: Візуальні звіти, системні сторінки, чат, UX, безпека та висновки

## 17. Візуальні звіти та PDF-генерація

### 17.1. Концепція PDF-звіту

PDF-звіти у проєкті HealthRisk.AI слугують офіційним документом, який користувачі можуть зберігати, друкувати та використовувати для консультацій з лікарями або аналізу своїх ризиків здоров'я.

**Навіщо PDF** — PDF-звіти необхідні для кількох причин: переносимість — PDF-файли можна легко передавати, зберігати та відкривати на будь-яких пристроях без необхідності доступу до вебінтерфейсу, офіційність — PDF-формат визнається як офіційний документ, який можна використовувати для медичних консультацій, зручність — користувачі можуть друкувати звіти, зберігати їх у папках, ділитися з лікарями, аналізувати зміни ризиків у часі, повнота — PDF-звіти містять всю необхідну інформацію про прогноз (ймовірність, категорію ризику, топ фактори, діаграми, рекомендації) в структурованому вигляді, незалежність — звіти не залежать від доступності вебінтерфейсу, користувачі можуть переглядати їх навіть без інтернету. PDF-звіти є важливою частиною користувацького досвіду, оскільки надають користувачам конкретний результат їх взаємодії з системою.

**Які дані включає** — PDF-звіт містить комплексну інформацію про прогноз ризику здоров'я: титульна сторінка з назвою проєкту, датою генерації, інформацією про користувача (якщо автентифікований), результати прогнозування (цільова змінна — діабет або ожиріння, ймовірність ризику у відсотках, категорія ризику — низький, середній або високий), топ фактори впливу (список найважливіших факторів з їх впливом у відсотках, наприклад, ІМТ — 35%, глюкоза — 28%, вік — 15%), діаграми ризиків (візуалізація ймовірності, розподілу факторів, кореляцій, історії прогнозів), тлумачення результатів (пояснення що означає категорія ризику, як інтерпретувати ймовірність, що робити далі), метадані моделі (назва використаної ML-моделі, версія, дата навчання, метрики якості), технічні деталі (вхідні параметри прогнозу, час генерації, версія системи). Всі дані структуровані та відформатовані для легкого читання та розуміння.

**Як користувач взаємодіє з кнопками форматів** — користувачі можуть експортувати звіти у різних форматах через кнопки на сторінці історії прогнозів або на сторінці результатів: кнопка "PDF" — генерує PDF-звіт з усіма діаграмами, текстом та форматуванням, кнопка "Excel" — експортує дані у формат Excel для аналізу в таблицях, кнопка "CSV" — експортує дані у формат CSV для імпорту в інші системи, кнопка "JSON" — експортує сирі дані у формат JSON для програмної обробки. Кнопки розташовані поруч з кожним прогнозом у історії та на сторінці результатів. При натисканні кнопки PDF відображається overlay "Формуємо PDF-звіт..." з індикатором завантаження, який блокує інтерфейс під час генерації. Після завершення генерації PDF автоматично завантажується через браузер. Інші формати (Excel, CSV, JSON) генеруються миттєво без overlay, оскільки не потребують складних операцій.

### 17.2. Структура PDF

PDF-звіт має чітку структуру з послідовним розташуванням інформації для легкого читання та розуміння.

**Титульна частина** — перша сторінка PDF містить титульну інформацію: назва проєкту "HealthRisk.AI" великим шрифтом, підзаголовок "Система оцінки ризиків здоров'я" або "Health Risk Assessment System", дата генерації звіту у форматі "DD.MM.YYYY HH:MM", інформація про користувача (якщо автентифікований) — ім'я, email, дата народження, стать, логотип або іконка проєкту (якщо є), версія системи або метадані про звіт. Титульна сторінка оформлена у професійному стилі з використанням корпоративних кольорів та шрифтів. Вона слугує обкладинкою звіту та надає перше враження про якість документа.

**Ризик** — розділ з результатами прогнозування містить: цільову змінну (діабет або ожиріння) великим шрифтом, ймовірність ризику у відсотках (наприклад, "Ймовірність: 67%") з візуальним індикатором (прогрес-бар або кругова діаграма), категорію ризику (низький, середній, високий) з кольоровим кодуванням (зелений, жовтий, червоний), коротке пояснення що означає ця категорія, рекомендації щодо наступних кроків (консультація з лікарем, зміна способу життя, моніторинг показників). Розділ оформлений для швидкого розуміння основного результату без необхідності читати весь звіт.

**Фактори** — розділ з топ факторами впливу містить: список найважливіших факторів (зазвичай топ-5) з їх впливом у відсотках, візуалізацію факторів у вигляді горизонтальних барів або кругової діаграми, опис кожного фактора (що він означає, як впливає на ризик), рекомендації щодо зменшення впливу кожного фактора. Фактори відсортовані за впливом (від найбільшого до найменшого) для акцентування уваги на найважливіших. Кожен фактор має назву (наприклад, "Індекс маси тіла (ІМТ)"), значення (наприклад, "32.5"), вплив у відсотках (наприклад, "35%") та пояснення.

**Тлумачення** — розділ з тлумаченням результатів містить: детальне пояснення що означає категорія ризику (низький, середній, високий), як інтерпретувати ймовірність (що означає 67% ризику), що робити далі (консультація з лікарем, зміна способу життя, моніторинг показників), застереження (система не ставить діагнозів, не призначає лікування, надає тільки оцінку ризику), посилання на додаткові ресурси (якщо є). Тлумачення написане зрозумілою мовою без медичних термінів для забезпечення доступності для всіх користувачів.

**Моделі** — розділ з метаданими моделі містить: назву використаної ML-моделі (наприклад, "Logistic Regression", "Random Forest"), версію моделі або дату навчання, метрики якості моделі (ROC-AUC, Accuracy, Precision, Recall), інформацію про калібрування (чи використовується калібрована версія), опис моделі (як вона працює, які дані використовує). Метадані надають прозорість системі та дозволяють користувачам зрозуміти, як було отримано результат. Це важливо для довіри до системи та для медичних консультацій.

**Дата/метадані** — остання сторінка PDF містить технічні метадані: дата та час генерації звіту, версія системи або API, вхідні параметри прогнозу (вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин), унікальний ідентифікатор звіту (якщо є), інформація про авторські права або ліцензію, застереження про використання (система не замінює консультацію з лікарем). Метадані корисні для відстеження змін у часі, діагностики проблем та забезпечення прозорості системи.

### 17.3. Генерація PDF

Генерація PDF виконується повністю на фронтенді через бібліотеку jsPDF, що забезпечує швидкість, безпеку та незалежність від сервера.

**Чому jsPDF** — jsPDF обрана як основна бібліотека для генерації PDF через кілька переваг: клієнтська генерація — PDF генерується на клієнті, що зменшує навантаження на сервер та забезпечує швидкість, безпека — дані користувачів не передаються на сервер для генерації, всі дані залишаються локально у браузері, простота використання — інтуїтивний API для створення PDF-документів з текстом, зображеннями, таблицями, підтримка форматування — можливість налаштування шрифтів, кольорів, розмірів, відступів, підтримка багатосторінковості — автоматичне створення нових сторінок при переповненні, підтримка зображень — можливість вставляти зображення (діаграми) у PDF, широке використання — популярна бібліотека з активною підтримкою та документацією. jsPDF завантажується з CDN через тег `<script>` у HTML та доступна глобально через `window.jsPDF` або `window.jspdf.jsPDF`.

**Шрифти + проблема кирилиці** — стандартні шрифти jsPDF не підтримують кирилицю, тому для генерації PDF з українським текстом використовуються спеціальні шрифти. Проблема кирилиці виникає через те, що jsPDF за замовчуванням використовує шрифти, які підтримують тільки латиницю. При спробі використати кирилицю зі стандартними шрифтами текст відображається як порожні квадрати або некоректні символи. Це критична проблема для української локалізації, оскільки всі тексти в PDF повинні бути українською мовою.

**Рішення з DejaVuSans** — для вирішення проблеми кирилиці використовуються шрифти DejaVuSans, які підтримують кирилицю та багато інших мов. DejaVuSans — це вільний шрифт з повною підтримкою Unicode, включаючи кирилицю, грецьку, арабську та інші скрипти. Шрифти зберігаються у файлах `fonts/DejaVuSans.ttf` (звичайний) та `fonts/DejaVuSans-Bold.ttf` (жирний) у директорії фронтенду та завантажуються асинхронно при першій генерації PDF.

**Завантаження локального шрифту** — завантаження шрифтів виконується через функцію `ensurePdfFontInitialized()`, яка перевіряє, чи шрифти вже завантажені, та завантажує їх при потребі. Процес включає: завантаження TTF-файлів через `fetch()` з локальної директорії, конвертацію шрифтів у base64 для включення в PDF, додавання шрифтів до Virtual File System (VFS) jsPDF через `doc.addFileToVFS()`, реєстрацію шрифтів через `doc.addFont()` з вказанням назви та стилю (normal, bold), кешування завантажених шрифтів у пам'яті для швидкого доступу при подальших генераціях. Шрифти завантажуються один раз при першій генерації PDF та використовуються для всіх наступних генерацій без повторного завантаження.

**Верстка PDF у коді** — верстка PDF виконується програмно через API jsPDF: створення документа через `new jsPDF()` з параметрами формату (A4: 210x297 мм), встановлення шрифту через `doc.setFont('DejaVuSans', 'normal')` або `doc.setFont('DejaVuSans', 'bold')`, додавання тексту через `doc.text(text, x, y)` з координатами у міліметрах, встановлення розміру шрифту через `doc.setFontSize(size)`, встановлення кольору тексту через `doc.setTextColor(r, g, b)`, додавання зображень через `doc.addImage(imageData, format, x, y, width, height)`, створення нових сторінок через `doc.addPage()` при переповненні, збереження PDF через `doc.save(filename)`. Верстка виконується послідовно з обчисленням позицій елементів, відступів та розмірів для оптимального розміщення контенту на сторінці.

**Адаптивність для різних даних** — PDF-звіт адаптується до різних обсягів даних через: автоматичне створення нових сторінок при переповненні контенту, обчислення висоти тексту для визначення необхідності нової сторінки, масштабування діаграм для вміщення на сторінку з збереженням пропорцій, обрізання довгих текстів з додаванням многоточия або перенесення на нову сторінку, динамічне розташування елементів залежно від наявності даних (якщо немає діаграм, текст займає більше місця). Адаптивність забезпечує, що PDF-звіт виглядає професійно незалежно від обсягу даних.

### 17.4. Генерація графіків у PDF

Діаграми з Chart.js конвертуються у зображення та вставляються у PDF для візуалізації даних.

**Конвертація Chart.js → PNG** — конвертація діаграм Chart.js у PNG-зображення виконується через метод `toBase64Image()` або `canvas.toDataURL('image/png')`. Процес включає: отримання canvas-елемента з Chart.js інстансу через `chartInstance.canvas`, виклик методу `toBase64Image()` для експорту діаграми у base64-кодоване PNG-зображення, встановлення високої роздільної здатності для забезпечення якості (наприклад, scale 2x або 3x), обробка помилок (якщо canvas порожній або діаграма не відрендерена), збереження зображення у форматі data URL для передачі до jsPDF. Конвертація виконується для всіх діаграм на сторінці перед генерацією PDF.

**Проблема blank canvas** — проблема порожнього canvas виникає, коли діаграма не відрендерена або прихована під час експорту. Canvas може бути порожнім через: діаграма не ініціалізована, діаграма прихована через CSS (`display: none` або `visibility: hidden`), діаграма не оновлена після зміни даних, canvas не має розмірів (width або height = 0), діаграма ще не завершила анімацію появи. Порожній canvas призводить до того, що в PDF вставляється порожнє зображення або зображення з помилкою.

**Рішення через re-render** — для вирішення проблеми порожнього canvas виконується re-render діаграми перед експортом: тимчасове показування прихованої діаграми через зміну CSS (`display: block`, `visibility: visible`), оновлення діаграми через `chartInstance.update()` для перерисовки, очікування завершення рендерингу через `requestAnimationFrame()` або `setTimeout()`, експорт canvas після переконання, що він заповнений, відновлення оригінального стану діаграми (приховування, якщо було приховано). Re-render забезпечує, що canvas містить актуальні дані перед експортом.

**Оптимізація якості** — якість зображень діаграм оптимізується через: встановлення високої роздільної здатності при експорті (scale 2x або 3x для чіткості), збереження пропорцій діаграми при масштабуванні для PDF, використання оптимальних параметрів якості для `toDataURL()` (якість 1.0 для максимальної якості), обмеження розміру зображення для балансу між якістю та розміром файлу, використання PNG замість JPEG для збереження чіткості текстів та ліній. Оптимізація забезпечує, що діаграми виглядають чітко у PDF без розмиття або пікселізації.

**Стиснення → збереження читабельності** — баланс між стисненням та читабельністю досягається через: використання оптимального масштабу (2x для балансу між якістю та розміром), обмеження кількості діаграм на сторінку (4 діаграми максимум), масштабування діаграм для вміщення на сторінку без втрати читабельності, використання PNG замість JPEG для збереження чіткості, оптимізація розміру canvas перед експортом (не занадто великий, не занадто малий). Стиснення не виконується агресивно, оскільки читабельність діаграм важливіша за розмір файлу.

### 17.5. Макет багатосторінковості

PDF-звіт може містити кілька сторінок для вміщення всієї інформації та діаграм.

**4 графіки на сторінку** — оптимальна кількість діаграм на одну сторінку A4 — 4 діаграми (2x2 сітка) для забезпечення читабельності та зручності перегляду. Розташування включає: обчислення розмірів діаграм для вміщення 4 діаграм на сторінку з відступами, розташування діаграм у сітці 2x2 з рівномірними відступами, додавання заголовків до кожної діаграми для ідентифікації, збереження пропорцій діаграм при масштабуванні. Якщо діаграм більше 4, створюються нові сторінки з наступними 4 діаграмами.

**Центрування** — діаграми та текст центруються на сторінці для професійного вигляду: обчислення центру сторінки (ширина A4: 210 мм, центр: 105 мм), розташування елементів відносно центру, вирівнювання тексту по центру через `doc.text()` з параметром `align: 'center'`, центрування діаграм у сітці 2x2. Центрування забезпечує збалансований вигляд сторінки та легкість читання.

**Контроль пропорцій** — пропорції діаграм зберігаються при масштабуванні для вміщення на сторінку: обчислення оригінальних пропорцій діаграми (width/height), обчислення максимального розміру для вміщення на сторінку з відступами, масштабування з збереженням пропорцій (якщо оригінальна ширина більша за висоту, масштабується по ширині, і навпаки), обрізання діаграм, якщо необхідно, для вміщення на сторінку. Контроль пропорцій забезпечує, що діаграми не виглядають спотвореними у PDF.

**Генерація сторінок послідовно** — сторінки PDF генеруються послідовно для забезпечення коректного порядку та структури: створення першої сторінки (титульна), додавання контенту на першу сторінку, створення нової сторінки через `doc.addPage()` при переповненні, додавання контенту на нову сторінку, повторення процесу для всіх сторінок. Послідовна генерація забезпечує, що контент розташований у правильному порядку та не перетинається між сторінками.

## 18. Системні підсторінки

Системні підсторінки надають інформацію про стан системи, історію роботи та загальну інформацію про проєкт.

### 18.1. /api-status

Сторінка `/api-status` відображає поточний стан всіх компонентів системи для моніторингу та діагностики.

**Перевірка API** — перевірка стану API виконується через ендпоінт `/health`, який повертає інформацію про доступність API, версію, кількість маршрутів та timestamp. Фронтенд робить періодичні запити (кожні 10 секунд) до цього ендпоінта та відображає статус через індикатор (зелений для онлайн, червоний для офлайн). Статус включає: доступність API (онлайн/офлайн), версія API (якщо є), кількість маршрутів, час останньої перевірки, латентність запиту (час відгуку в мілісекундах). Інформація відображається у вкладці "API" на сторінці `/api-status`.

**Перевірка Ollama** — перевірка стану Ollama виконується через ендпоінт `/assistant/health`, який робить тестовий запит до локального Ollama сервера та вимірює латентність. Фронтенд робить періодичні запити (кожні 10 секунд) до цього ендпоінта та відображає статус через індикатор. Статус включає: доступність Ollama (онлайн/офлайн/таймаут/помилка), латентність запиту (час відгуку в мілісекундах), наявність моделі (якщо перевіряється), текст помилки (якщо є), час останньої перевірки. Інформація відображається у вкладці "Ollama" на сторінці `/api-status`.

**Індикатори доступності** — індикатори доступності відображаються через кольорові індикатори для швидкого розуміння стану: зелений індикатор — компонент онлайн та працює коректно, червоний індикатор — компонент офлайн або не відповідає, жовтий індикатор — компонент працює, але з затримками або помилками, сірий індикатор — статус невідомий або не перевірено. Індикатори оновлюються автоматично при кожній перевірці статусу та можуть бути оновлені вручну через кнопку "Оновити".

**Анімація «Перевірка…»** — під час перевірки статусу відображається анімація "Перевірка..." з трьома крапками, які анімуються послідовно для індикації процесу перевірки. Анімація виконується через CSS анімації або JavaScript та зникає після отримання відповіді від сервера. Анімація забезпечує, що користувач бачить, що система працює та обробляє запит.

**Табовий інтерфейс** — сторінка `/api-status` використовує табовий інтерфейс для перемикання між різними компонентами системи: вкладка "API" — статус API, версія, маршрути, вкладка "База даних" — статистика БД, кількість записів, розмір, активність, вкладка "Ollama" — статус Ollama, латентність, помилки. Табовий інтерфейс реалізований через HTML-структуру з CSS для стилізації та JavaScript для перемикання вкладок. Активна вкладка виділяється кольором або підкресленням для візуального розрізнення.

### 18.2. /api-status/history

Сторінка `/api-status/history` відображає історію статусів компонентів системи для аналізу трендів та діагностики проблем.

**Лог навантаження** — лог навантаження зберігає історію запитів до API, БД та Ollama для аналізу навантаження системи. Лог включає: час кожного запиту, латентність відповіді, статус (успіх/помилка), тип запиту (API, БД, Ollama), деталі помилок (якщо є). Лог зберігається у пам'яті на фронтенді (масив `apiStatusHistory`, `ollamaStatusHistory`) та може бути збережений у БД для довгострокового аналізу. Лог дозволяє виявити патерни навантаження, піки активності та проблеми з продуктивністю.

**Час відгуку** — час відгуку вимірюється для кожного запиту до компонентів системи та відображається у вигляді графіка для візуалізації трендів. Графік показує: латентність API у мілісекундах, латентність БД у мілісекундах, латентність Ollama у мілісекундах, тренди збільшення або зменшення латентності, піки латентності (можуть вказувати на проблеми). Графік оновлюється автоматично при кожній перевірці статусу та дозволяє виявити проблеми з продуктивністю.

**Ідея «uptime графіка»** — uptime графік відображає відсоток часу, коли компонент був онлайн, за певний період (наприклад, останні 24 години, тиждень, місяць). Графік показує: періоди онлайн (зелені смуги), періоди офлайн (червоні смуги), загальний uptime у відсотках, найдовші періоди офлайн, найкоротші періоди офлайн. Uptime графік дозволяє оцінити надійність системи та виявити проблеми з доступністю.

**Як збирається статистика** — статистика збирається через періодичні запити (кожні 10 секунд) до ендпоінтів статусів та збереження результатів у масивах на фронтенді. Статистика включає: час кожного запиту, латентність відповіді, статус компонента, помилки (якщо є). Статистика зберігається у пам'яті та може бути експортована у JSON для подальшого аналізу. Для довгострокового зберігання статистика може бути збережена у БД через окрему таблицю для логів статусів.

### 18.3. /about

Сторінка `/about` надає загальну інформацію про проєкт, його мету, історію та технології.

**Для чого сторінка** — сторінка `/about` слугує для: інформування користувачів про проєкт, його мету та призначення, надання інформації про технології, які використовуються, демонстрації професійного підходу до розробки, надання контактної інформації або посилань на додаткові ресурси, пояснення як працює система, які дані використовуються, як інтерпретувати результати. Сторінка допомагає користувачам зрозуміти систему та довіряти їй.

**Структура** — сторінка `/about` має структурований вигляд з розділами: заголовок "Про проєкт" або "About", опис проєкту (що це, навіщо, для кого), історія проєкту (коли створено, хто розробляв, версії), технології (які технології використовуються, чому вони обрані), джерела даних (NHANES, Kaggle, як дані використовуються), команда або автор (якщо є), контакти або посилання (якщо є), ліцензія або авторські права. Структура забезпечує легке читання та розуміння інформації.

**Історія проєкту** — розділ з історією проєкту містить: дату створення проєкту, мету проєкту (магістерська робота, дослідження, комерційний проєкт), етапи розробки (ETL, EDA, ML, API, Frontend), версії проєкту (якщо є), досягнення або нагороди (якщо є), майбутні плани розвитку. Історія допомагає користувачам зрозуміти контекст проєкту та його еволюцію.

**Компонування інформації** — інформація на сторінці `/about` компонується для легкого читання: використання заголовків та підзаголовків для структури, розділення інформації на блоки з візуальним розділенням, використання списків для переліку технологій або функцій, використання іконок або зображень для візуалізації, адаптивний дизайн для різних розмірів екранів. Компонування забезпечує професійний вигляд сторінки та легкість читання.

## 19. Чат та AI-асистент

AI-асистент надає персоналізовані рекомендації щодо здоров'я на основі результатів прогнозування користувача.

### 19.1. Призначення AI-асистента

AI-асистент слугує допоміжним інструментом для користувачів у розумінні результатів прогнозування та отриманні рекомендацій.

**Для чого він у системі** — AI-асистент виконує кілька функцій: пояснення результатів прогнозування зрозумілою мовою, надання рекомендацій щодо зменшення ризиків, відповіді на питання користувачів про їх стан здоров'я, надання контексту про фактори ризику та їх вплив, допомога у інтерпретації технічних термінів та метрик. Асистент не ставить діагнозів, не призначає лікування, а надає тільки загальні рекомендації на основі результатів прогнозування.

**Як допомагає користувачу** — асистент допомагає користувачу через: пояснення що означає категорія ризику (низький, середній, високий), інтерпретацію ймовірності ризику (що означає 67% ризику), рекомендації щодо наступних кроків (консультація з лікарем, зміна способу життя), пояснення факторів ризику та їх впливу, відповіді на питання про стан здоров'я в контексті прогнозу. Асистент працює як персональний консультант, який допомагає користувачу зрозуміти результати та прийняти рішення.

**Типи відповідей** — асистент надає різні типи відповідей: інформаційні відповіді (пояснення термінів, метрик, факторів), рекомендаційні відповіді (що робити для зменшення ризиків), пояснювальні відповіді (як інтерпретувати результати), застережувальні відповіді (нагадування про необхідність консультації з лікарем), підтримуючі відповіді (мотивація для зміни способу життя). Всі відповіді написані зрозумілою мовою без медичних термінів для забезпечення доступності.

### 19.2. Архітектура чату

Архітектура чату організована через розділення на фронтенд (UI) та бекенд (логіка обробки).

**Дві частини: фронт і бек** — чат складається з двох частин: фронтенд відповідає за відображення інтерфейсу чату, обробку введення користувача, відображення повідомлень, управління скролом, анімації, бекенд відповідає за обробку повідомлень, формування контексту, виклик Ollama, збереження історії, валідацію даних. Фронтенд та бекенд взаємодіють через REST API для передачі повідомлень та отримання відповідей.

**Потоки повідомлень** — потік повідомлень організований як послідовний процес: користувач вводить повідомлення у текстове поле, натискає кнопку "Відправити", фронтенд валідує повідомлення (не порожнє, не занадто довге), фронтенд відправляє POST-запит до `/assistant/chat` з повідомленням та опційним `prediction_id`, бекенд зберігає повідомлення користувача в БД, бекенд формує контекст про стан здоров'я користувача, бекенд викликає Ollama для генерації відповіді, бекенд зберігає відповідь асистента в БД, бекенд повертає відповідь фронтенду, фронтенд відображає відповідь у чаті. Потік забезпечує коректну обробку повідомлень та збереження історії.

**Обробка JSON-повідомлень** — повідомлення передаються у форматі JSON через REST API: запит містить поля `message` (текст повідомлення), `prediction_id` (опційний, для контексту конкретного прогнозу), `language` (uk або en), відповідь містить поля `response` (текст відповіді асистента), `timestamp` (час відповіді), `context` (опційний, контекст, який використовувався). JSON забезпечує структурованість даних та легкість обробки на обох сторонах.

**Збереження історії в БД** — історія діалогів зберігається в таблиці `assistantmessage` для кожного користувача: кожне повідомлення користувача зберігається з `role: "user"`, кожна відповідь асистента зберігається з `role: "assistant"`, повідомлення зберігаються хронологічно з timestamps, повідомлення можуть бути пов'язані з конкретним прогнозом через `prediction_id` для контексту. Історія завантажується при активації сторінки асистента через ендпоінт `/assistant/history` та відображається на фронтенді для користувача.

### 19.3. Логіка AI-відповідей

Логіка формування відповідей AI-асистента організована через формування промптів, контексту та виклик Ollama.

**Формування prompt** — промпт формується через функцію `build_assistant_prompt()` у модулі `assistant_llm.py` та включає: системний промпт з інструкціями для асистента (асистент не ставить діагнозів, не призначає лікування, надає загальні рекомендації), контекст про стан здоров'я користувача (формується через `build_health_context()` на основі останнього прогнозу), запит користувача (текст повідомлення від користувача). Промпт формується як структурований текст з чіткими розділами для зрозумілості LLM.

**Контекст** — контекст про стан здоров'я користувача формується через функцію `build_health_context()` на основі останнього прогнозу з БД: отримання останнього прогнозу користувача через `get_latest_prediction()`, форматування контексту як текстового опису (цільова змінна, ймовірність, категорія ризику, топ фактори), додавання контексту до промпту для LLM. Контекст забезпечує, що асистент надає персоналізовані рекомендації на основі конкретних результатів користувача.

**Пам'ять** — пам'ять діалогу зберігається в таблиці `assistantmessage` для кожного користувача: всі попередні повідомлення користувача та асистента зберігаються хронологічно, історія може бути використана для покращення контексту майбутніх відповідей (хоча наразі контекст формується тільки на основі останнього прогнозу), історія завантажується при активації сторінки асистента та відображається на фронтенді. В майбутньому можна додати використання повної історії діалогів для покращення контексту та забезпечення послідовності розмови.

**Як Ollama обробляє запити** — Ollama обробляє запити через HTTP API: бекенд відправляє POST-запит до `http://localhost:11434/api/generate` з JSON payload (`model`, `prompt`, `stream: false`), Ollama обробляє промпт через LLM (наприклад, Llama3), генерує відповідь на основі промпту та контексту, повертає відповідь у форматі JSON з полем `response`, бекенд обробляє відповідь та зберігає її в БД. Ollama працює локально, що забезпечує приватність даних та швидкість відповідей.

### 19.4. Реалізація UI чату

UI чату реалізований для забезпечення зручної взаємодії користувача з AI-асистентом.

**Адаптивність** — UI чату адаптується до різних розмірів екранів: на десктопі чат займає всю доступну ширину з фіксованою висотою, на мобільних пристроях чат займає весь екран з адаптивними розмірами, повідомлення автоматично переносяться на новий рядок при переповненні, кнопка "Відправити" адаптується до розміру екрану, скрол адаптується до висоти екрану. Адаптивність забезпечує зручну взаємодію на всіх пристроях.

**Система scroll-to-bottom** — автоматичний скрол до останнього повідомлення реалізується через: виклик `scrollIntoView()` для останнього повідомлення при додаванні нового, використання `requestAnimationFrame()` для плавного скролу, збереження позиції скролу при оновленні повідомлень, можливість ручного скролу для перегляду старих повідомлень. Scroll-to-bottom забезпечує, що користувач завжди бачить останнє повідомлення без необхідності ручного скролу.

**Обмежувачі контексту** — обмежувачі контексту забезпечують, що промпт не перевищує обмеження LLM: обмеження довжини повідомлення користувача (наприклад, максимум 1000 символів), обмеження довжини контексту (наприклад, тільки останній прогноз, не вся історія), обрізання довгих текстів з додаванням многоточия, валідація вхідних даних перед відправкою. Обмежувачі забезпечують, що запити до Ollama не перевищують обмеження та обробляються коректно.

**Завантаження старих повідомлень** — завантаження старих повідомлень виконується через ендпоінт `/assistant/history`, який повертає всі повідомлення користувача, відсортовані за часом: завантаження історії при активації сторінки асистента, відображення повідомлень у хронологічному порядку, можливість прокрутки вгору для перегляду старих повідомлень, кешування історії для швидкого доступу. Завантаження забезпечує, що користувач бачить всю історію діалогу з асистентом.

## 20. Користувацький досвід (UX) та доступність

UX та доступність забезпечують зручну та інклюзивну взаємодію користувачів з системою.

### 20.1. UX принципи

UX принципи орієнтовані на простоту, зрозумілість та ефективність взаємодії.

**Проста логіка** — логіка системи організована для мінімізації складності: мінімальна кількість кроків для виконання задач (наприклад, прогноз за 3 кроки: введення даних, натискання кнопки, перегляд результатів), інтуїтивна навігація (зрозумілі назви сторінок, логічне розташування елементів), передбачувана поведінка (кнопки працюють так, як очікує користувач), мінімальна кількість рішень для користувача (система надає рекомендації, не вимагає складних виборів). Проста логіка забезпечує, що користувачі можуть використовувати систему без навчання.

**Мінімум кнопок** — інтерфейс містить тільки необхідні кнопки для мінімізації плутанини: основні дії (прогноз, історія, профіль) доступні через навігацію, додаткові дії (експорт, налаштування) доступні через контекстні меню або іконки, невикористовувані кнопки приховані, кнопки мають зрозумілі назви або іконки. Мінімум кнопок забезпечує чистий інтерфейс та легкість навігації.

**Доступний текст** — текст у системі написаний зрозумілою мовою: мінімум технічних термінів, пояснення складних концепцій простими словами, використання коротких речень, використання активного замість пасивного стану, використання конкретних замість абстрактних слів. Доступний текст забезпечує, що всі користувачі можуть зрозуміти інформацію без медичної освіти.

**Правильна ієрархія** — ієрархія інформації організована для акцентування важливих елементів: заголовки використовуються для структури (H1 для головного заголовка, H2 для розділів, H3 для підрозділів), важлива інформація виділяється розміром, кольором або жирним шрифтом, менш важлива інформація прихована за розгортанням або на окремих сторінках, логічний порядок елементів (зверху вниз, зліва направо). Правильна ієрархія забезпечує, що користувачі швидко знаходять потрібну інформацію.

### 20.2. Анімації

Анімації використовуються для покращення користувацького досвіду та візуальної привабливості.

**Доти** — анімації при дотику (hover, click) забезпечують візуальний зворотний зв'язок: зміна кольору кнопок при наведенні (hover effect), зміна розміру або тіні при натисканні (active effect), плавні переходи між станами (transition), анімації появи елементів (fade in, slide in). Анімації дотиків забезпечують, що користувач бачить реакцію системи на свої дії.

**Модалки** — анімації модальних вікон забезпечують плавне відкриття та закриття: fade in/out для overlay, slide down/up для модального вікна, scale in/out для акцентування, затримка для послідовного відображення елементів. Анімації модалок забезпечують професійний вигляд та плавність взаємодії.

**Прелоадер PDF** — прелоадер PDF відображається під час генерації PDF для інформування користувача: overlay з напівпрозорим фоном, індикатор завантаження (спінер або прогрес-бар), текст "Формуємо PDF-звіт...", анімація завантаження (обертання спінера, анімація крапок). Прелоадер забезпечує, що користувач бачить, що система працює та обробляє запит.

### 20.3. Accessibility

Доступність забезпечує, що система може бути використана людьми з обмеженими можливостями.

**Контрастність** — контрастність кольорів забезпечує читабельність тексту: мінімальний контраст 4.5:1 для звичайного тексту, мінімальний контраст 3:1 для великого тексту, використання темної теми для покращення контрасту, перевірка контрасту через інструменти (наприклад, WCAG Contrast Checker). Контрастність забезпечує, що текст читабельний для всіх користувачів.

**Альтернативні тексти** — альтернативні тексти для зображень забезпечують доступність для screen readers: атрибут `alt` для всіх зображень з описом змісту, атрибут `title` для додаткової інформації, опис діаграм у тексті для користувачів з обмеженим зором. Альтернативні тексти забезпечують, що користувачі з screen readers можуть зрозуміти зміст зображень.

**ARIA-атрибути** — ARIA-атрибути забезпечують доступність для screen readers: `aria-label` для опису елементів, `aria-labelledby` для зв'язку з заголовками, `aria-describedby` для додаткового опису, `aria-hidden` для приховування декоративних елементів, `role` для визначення ролі елементів. ARIA-атрибути забезпечують, що screen readers можуть коректно інтерпретувати інтерфейс.

## 21. Резервне копіювання та збереження даних

Резервне копіювання забезпечує збереження даних та можливість відновлення при втраті.

**Резервне копіювання БД** — резервне копіювання бази даних виконується через копіювання файлу `data/app.db` на окремий сервер або у хмарне сховище: регулярне копіювання (наприклад, щодня через cron job), збереження кількох версій backup (останні 7 днів, останні 4 тижні, останній місяць), шифрування backup для безпеки, перевірка цілісності backup перед збереженням. Резервне копіювання забезпечує, що дані можуть бути відновлені при втраті.

**Робота з файлами** — робота з файлами включає: збереження аватарів користувачів у директорії `data/avatars/`, збереження ML моделей у директорії `artifacts/models/`, збереження датасетів у директорії `datasets/`, збереження логів у директорії `logs/` (якщо є). Всі файли повинні бути включені у резервне копіювання для повного відновлення системи.

**Де зберігати data** — дані зберігаються у директорії `data/` у корені проєкту: `data/app.db` — база даних, `data/avatars/` — аватари користувачів, інші дані (якщо є). Директорія `data/` повинна бути включена у `.gitignore` для запобігання коміту чутливих даних у Git. Дані повинні зберігатися на окремому сервері або у хмарному сховищі для безпеки.

**Як робити snapshot** — snapshot (знімок стану) системи виконується через: копіювання файлу БД у timestamp-названий файл (наприклад, `app_20240101_120000.db`), копіювання всіх файлів у директорії `data/`, збереження конфігураційних файлів (`.env`, `configs/`), створення архіву всіх файлів для зручності. Snapshot дозволяє відновити систему до конкретного стану.

**Відновлення** — відновлення системи виконується через: відновлення файлу БД з backup, відновлення файлів з директорії `data/`, відновлення конфігураційних файлів, перевірка цілісності даних після відновлення, тестування системи для переконання, що все працює коректно. Відновлення забезпечує, що система може бути відновлена при втраті даних.

**Міграції** — міграції БД виконуються через функцію `migrate_add_missing_columns()`, яка додає відсутні колонки до існуючих таблиць: автоматичне виконання міграцій при старті додатку, додавання нових колонок без втрати даних, перевірка наявності колонок перед додаванням. В майбутньому можна додати систему міграцій (наприклад, Alembic) для більш складних змін схеми.

## 22. Логування та моніторинг

Логування та моніторинг забезпечують відстеження роботи системи та діагностику проблем.

### 22.1. Логи бекенда

Логи бекенда записують інформацію про роботу API, обробку запитів та помилки.

**Успішні запити** — успішні запити логуються для відстеження активності: час запиту, URL, метод HTTP, статус-код, час обробки, користувач (якщо автентифікований). Логування успішних запитів дозволяє відстежувати навантаження системи, популярні ендпоінти, піки активності.

**Помилки** — помилки логуються для діагностики проблем: час помилки, URL, метод HTTP, статус-код, текст помилки, stack trace, контекст (користувач, дані запиту). Логування помилок дозволяє швидко виявити та виправити проблеми.

**Важливі події** — важливі події логуються для відстеження критичних операцій: створення користувачів, зміна паролів, блокування користувачів, генерація прогнозів, помилки БД, помилки ML. Логування важливих подій дозволяє відстежувати безпеку та стабільність системи.

### 22.2. Логи ML

Логи ML записують інформацію про роботу ML-моделей та прогнозування.

**Прогнозування** — прогнозування логуються для відстеження використання моделей: час прогнозування, використана модель, цільова змінна, вхідні параметри, результат (ймовірність, категорія ризику), час обробки. Логування прогнозування дозволяє відстежувати популярність моделей, якість передбачень, продуктивність.

**Метадані** — метадані моделей логуються для відстеження версій та якості: версія моделі, дата навчання, метрики якості, час завантаження, помилки завантаження. Логування метаданих дозволяє відстежувати зміни моделей та їх вплив на якість.

### 22.3. Моніторинг статусу системи

Моніторинг статусу системи забезпечує відстеження доступності компонентів.

**API** — моніторинг API виконується через ендпоінт `/health`, який перевіряє доступність API, версію, кількість маршрутів. Статус відображається на сторінці `/api-status` з індикаторами онлайн/офлайн.

**DB** — моніторинг БД виконується через ендпоінт `/system/database/stats`, який перевіряє доступність БД, кількість записів, розмір, активність. Статус відображається на сторінці `/api-status` з детальною статистикою.

**Ollama** — моніторинг Ollama виконується через ендпоінт `/assistant/health`, який перевіряє доступність Ollama, латентність, помилки. Статус відображається на сторінці `/api-status` з індикаторами та графіками латентності.

**Перевірка доступності** — перевірка доступності виконується періодично (кожні 10 секунд) через автоматичні запити до ендпоінтів статусів. Результати зберігаються у пам'яті для побудови графіків та аналізу трендів.

## 23. Масштабування

Масштабування забезпечує можливість розширення системи для обробки більшої кількості користувачів та даних.

**Винос БД у PostgreSQL** — перехід з SQLite на PostgreSQL забезпечує кращу продуктивність та масштабованість: підтримка одночасних запитів, краща продуктивність для великих обсягів даних, підтримка реплікації та шардінгу, кращі інструменти для моніторингу та оптимізації. Перехід виконується через зміну connection string у `.env` та міграцію даних з SQLite у PostgreSQL.

**Перенесення models у окремий microservice** — винесення ML-моделей у окремий мікросервіс забезпечує: незалежне масштабування ML-компонентів, використання GPU для швидшого інференсу, ізоляцію ML-коду від основного API, можливість використання різних мов програмування для ML. Мікросервіс комунікує з основним API через REST API або gRPC.

**Горизонтальне масштабування API** — горизонтальне масштабування API забезпечує обробку більшої кількості запитів: запуск кількох інстансів API на різних серверах, використання load balancer для розподілу навантаження, використання shared БД для синхронізації даних, використання Redis для кешування та сесій. Горизонтальне масштабування дозволяє обробляти тисячі одночасних користувачів.

**CDN для статичних файлів** — використання CDN для статичних файлів забезпечує швидке завантаження: розподіл статичних файлів (CSS, JS, шрифти, зображення) по серверах у різних регіонах, кешування файлів на CDN для швидкого доступу, зменшення навантаження на основний сервер. CDN забезпечує швидке завантаження сторінок для користувачів з різних регіонів.

**GPU inference для ML** — використання GPU для ML inference забезпечує швидший інференс: обробка тисяч прогнозів одночасно, зменшення часу обробки з секунд до мілісекунд, можливість використання складніших моделей, економія CPU ресурсів для інших компонентів. GPU inference особливо важливий для великих моделей та високого навантаження.

## 24. Висновок

Система HealthRisk.AI є комплексним рішенням для оцінки ризиків здоров'я на основі машинного навчання, яке об'єднує наукові дослідження, технологічну реалізацію та користувацький досвід у єдину систему.

**Що система робить** — система HealthRisk.AI надає користувачам можливість оцінити ризики розвитку діабету та ожиріння на основі їх медичних параметрів (вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин). Система використовує навчені ML-моделі для прогнозування ймовірності ризику, надає детальну інформацію про фактори впливу, генерує візуальні звіти у форматі PDF, надає AI-асистента для пояснення результатів та рекомендацій. Система працює як веб-додаток з повною функціональністю для реєстрації користувачів, збереження історії прогнозів, спілкування з іншими користувачами та отримання персоналізованих рекомендацій.

**Чому корисна** — система корисна для кількох груп користувачів: звичайні користувачі отримують швидку оцінку своїх ризиків здоров'я без необхідності консультації з лікарем, лікарі можуть використовувати систему як допоміжний інструмент для оцінки ризиків пацієнтів, дослідники можуть використовувати систему для аналізу даних та покращення моделей, студенти можуть використовувати систему для навчання ML та медичної інформатики. Система надає прозорість у процесі оцінки ризиків через пояснення факторів впливу та метадані моделей, що забезпечує довіру користувачів.

**Що реалізовано** — система реалізує повний цикл від сирих даних до вебінтерфейсу: ETL-процес для обробки NHANES датасету, EDA для аналізу даних та вибору ознак, навчання ML-моделей для прогнозування ризиків, калібрування моделей для реалістичних ймовірностей, FastAPI бекенд для обробки запитів та ML inference, SQLite база даних для збереження даних, SPA фронтенд для взаємодії користувачів, генерація PDF-звітів з діаграмами, AI-асистент на основі Ollama для персоналізованих рекомендацій, система чатів між користувачами, моніторинг статусу системи, інтернаціоналізація (українська та англійська мови), система тестування для забезпечення якості. Всі компоненти інтегровані та працюють разом для створення повнофункціональної системи.

**Які можливості для майбутнього** — система має великий потенціал для розвитку: додавання нових ризиків (серцево-судинні захворювання, онкологія, інші), покращення точності моделей через більші датасети та нові алгоритми, додавання нових функцій (нагадування, моніторинг показників у часі, інтеграція з медичними пристроями), перехід на хмарну інфраструктуру для масштабування, додавання мобільного додатку для зручності користувачів, інтеграція з електронними медичними картками, додавання функцій телемедицини, покращення AI-асистента через більші моделі та RAG (Retrieval-Augmented Generation). Система може стати основою для комерційного продукту або продовження наукових досліджень.

**Чому це завершена дипломна робота високого рівня** — проєкт HealthRisk.AI демонструє високий рівень технічної реалізації та наукового підходу: комплексність — система охоплює повний цикл від даних до вебінтерфейсу, включаючи ETL, EDA, ML, API, фронтенд, БД, AI, тестування, технічна складність — використання сучасних технологій (FastAPI, SQLModel, Chart.js, jsPDF, Ollama) та архітектурних підходів (SPA, REST API, ORM, мікросервіси), наукова обґрунтованість — використання офіційного медичного датасету (NHANES), науковий підхід до вибору ознак та навчання моделей, калібрування для реалістичних ймовірностей, практична корисність — система може бути використана реальними користувачами для оцінки ризиків здоров'я, надає конкретні результати та рекомендації, документація — повна технічна документація українською мовою, що описує всі аспекти системи, тестування — система тестування забезпечує якість та стабільність коду, масштабованість — архітектура дозволяє легко масштабувати систему для більшої кількості користувачів. Проєкт демонструє професійний підхід до розробки, глибоке розуміння технологій та здатність створювати складні системи, що робить його завершеною дипломною роботою високого рівня, яка може бути використана як основа для подальших досліджень або комерційного продукту.


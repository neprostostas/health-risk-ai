"""
–†–µ—î—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –∫–µ—à—É–≤–∞–Ω–Ω—è —á–µ–º–ø—ñ–æ–Ω—Å—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π.
"""

import json
from pathlib import Path
from typing import Dict, List, Tuple

import joblib
from sklearn.pipeline import Pipeline

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —à–ª—è—Ö—ñ–≤
PROJECT_ROOT = Path(__file__).resolve().parents[2]
MODELS_DIR = PROJECT_ROOT / "artifacts/models"

# –ö–µ—à –º–æ–¥–µ–ª–µ–π –≤ –ø–∞–º'—è—Ç—ñ
_MODEL_CACHE: Dict[str, Tuple[Pipeline, Dict]] = {}
_SPECIFIC_MODEL_CACHE: Dict[str, Tuple[Pipeline, Dict]] = {}

# –ú–∞–ø—ñ–Ω–≥ –∫–ª—é—á—ñ–≤ –º–æ–¥–µ–ª–µ–π –¥–æ –Ω–∞–∑–≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
MODEL_KEY_MAP: Dict[str, str] = {
    "logreg": "LogisticRegression",
    "random_forest": "RandomForest",
    "xgb": "XGBoost",
    "lgbm": "LightGBM",
    "svm": "SVC",
    "knn": "KNN",
    "mlp": "MLP",
}

# –õ—é–¥—Å—å–∫—ñ –Ω–∞–∑–≤–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
MODEL_LABELS: Dict[str, str] = {
    "LogisticRegression": "–õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è",
    "RandomForest": "Random Forest",
    "XGBoost": "XGBoost",
    "LightGBM": "LightGBM",
    "SVC": "SVM",
    "KNN": "K-Nearest Neighbors",
    "MLP": "–ù–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ (MLP)",
}


def load_champion(target: str, prefer_calibrated: bool = True) -> Tuple[Pipeline, Dict]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —á–µ–º–ø—ñ–æ–Ω—Å—å–∫—É –º–æ–¥–µ–ª—å –¥–ª—è —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó.
    
    Args:
        target: –ù–∞–∑–≤–∞ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó
        prefer_calibrated: –ß–∏ –≤—ñ–¥–¥–∞–≤–∞—Ç–∏ –ø–µ—Ä–µ–≤–∞–≥—É –∫–∞–ª—ñ–±—Ä–æ–≤–∞–Ω—ñ–π –º–æ–¥–µ–ª—ñ
    
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (pipeline, metadata)
    """
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–µ—à—É
    cache_key = f"{target}_{prefer_calibrated}"
    if cache_key in _MODEL_CACHE:
        print(f"‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ –∫–µ—à–æ–≤–∞–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è {target}")
        return _MODEL_CACHE[cache_key]
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–µ—Ç–∞–¥–∞–Ω–∏—Ö
    champion_path = MODELS_DIR / target / "champion.json"
    
    if not champion_path.exists():
        raise FileNotFoundError(f"–ú–µ—Ç–∞–¥–∞–Ω—ñ —á–µ–º–ø—ñ–æ–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {champion_path}")
    
    with open(champion_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)

    raw_name = metadata.get("model_name")
    if raw_name:
        metadata["model_name_raw"] = raw_name
        metadata["model_name"] = MODEL_LABELS.get(raw_name, raw_name)
        for key, folder in MODEL_KEY_MAP.items():
            if folder == raw_name:
                metadata["model_key"] = key
                break
    metadata.setdefault("version", "champion")

    # –°–ø—Ä–æ–±–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–∞–ª—ñ–±—Ä–æ–≤–∞–Ω—É –º–æ–¥–µ–ª—å
    if prefer_calibrated:
        calibrated_path = MODELS_DIR / target / "champion_calibrated.joblib"
        if calibrated_path.exists():
            print(f"üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–∞–ª—ñ–±—Ä–æ–≤–∞–Ω–æ—ó –º–æ–¥–µ–ª—ñ –¥–ª—è {target}...")
            pipeline = joblib.load(calibrated_path)
            metadata["is_calibrated"] = True
            metadata["model_path"] = str(calibrated_path)
            _MODEL_CACHE[cache_key] = (pipeline, metadata)
            print(f"‚úÖ –ö–∞–ª—ñ–±—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –¥–ª—è {target}")
            return pipeline, metadata
    
    # Fallback –¥–æ –∑–≤–∏—á–∞–π–Ω–æ—ó –º–æ–¥–µ–ª—ñ
    model_path = Path(metadata["path"])
    if not model_path.exists():
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å —á–µ–º–ø—ñ–æ–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {model_path}")
    
    print(f"üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –¥–ª—è {target}...")
    pipeline = joblib.load(model_path)
    metadata["is_calibrated"] = False
    metadata["model_path"] = str(model_path)
    _MODEL_CACHE[cache_key] = (pipeline, metadata)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –¥–ª—è {target}")
    
    return pipeline, metadata


def _read_metrics(model_dir: Path) -> Dict:
    """–ó—á–∏—Ç—É—î –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª—ñ –∑ —Ñ–∞–π–ª—É metrics.json, —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ."""
    metrics_path = model_dir / "metrics.json"
    if metrics_path.exists():
        with open(metrics_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def load_model(target: str, model_key: str) -> Tuple[Pipeline, Dict]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó –∑–∞ –∫–ª—é—á–µ–º.
    
    Args:
        target: –ù–∞–∑–≤–∞ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó
        model_key: –ö–ª—é—á –º–æ–¥–µ–ª—ñ (logreg, random_forest —Ç–æ—â–æ)
    
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (pipeline, metadata)
    """
    if model_key not in MODEL_KEY_MAP:
        raise ValueError(f"–ù–µ–≤—ñ–¥–æ–º–∏–π –∫–ª—é—á –º–æ–¥–µ–ª—ñ: {model_key}")

    model_folder = MODEL_KEY_MAP[model_key]
    cache_key = f"{target}_{model_folder}"

    if cache_key in _SPECIFIC_MODEL_CACHE:
        print(f"‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ –∫–µ—à–æ–≤–∞–Ω—É –º–æ–¥–µ–ª—å {model_folder} –¥–ª—è {target}")
        return _SPECIFIC_MODEL_CACHE[cache_key]

    model_dir = MODELS_DIR / target / model_folder
    model_path = model_dir / "model.joblib"

    if not model_path.exists():
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å {model_folder} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {model_path}")

    print(f"üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ {model_folder} –¥–ª—è {target}...")
    pipeline = joblib.load(model_path)

    metadata = {
        "model_name": MODEL_LABELS.get(model_folder, model_folder),
        "model_key": model_key,
        "model_path": str(model_path),
        "is_calibrated": False,
        "metrics": _read_metrics(model_dir),
        "version": "custom",
    }

    _SPECIFIC_MODEL_CACHE[cache_key] = (pipeline, metadata)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_folder} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –¥–ª—è {target}")

    return pipeline, metadata


def get_feature_schema() -> List[Dict]:
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å—Ö–µ–º—É –æ–∑–Ω–∞–∫ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö.
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤ –∑ –æ–ø–∏—Å–æ–º –æ–∑–Ω–∞–∫
    """
    schema = [
        {
            "name": "RIDAGEYR",
            "dtype": "float",
            "description": "–í—ñ–∫ –æ—Å–æ–±–∏ (—Ä–æ–∫–∏)",
            "required": True,
            "min": 0,
            "max": 120,
        },
        {
            "name": "RIAGENDR",
            "dtype": "int",
            "description": "–°—Ç–∞—Ç—å",
            "required": True,
            "allowed_values": [1, 2],
        },
        {
            "name": "BMXBMI",
            "dtype": "float",
            "description": "–Ü–Ω–¥–µ–∫—Å –º–∞—Å–∏ —Ç—ñ–ª–∞ (–Ü–ú–¢)",
            "required": True,
            "min": 10,
            "max": 60,
        },
        {
            "name": "BPXSY1",
            "dtype": "float",
            "description": "–°–∏—Å—Ç–æ–ª—ñ—á–Ω–∏–π –∞—Ä—Ç–µ—Ä—ñ–∞–ª—å–Ω–∏–π —Ç–∏—Å–∫ (–º–º —Ä—Ç.—Å—Ç.)",
            "required": False,
            "min": 50,
            "max": 250,
        },
        {
            "name": "BPXDI1",
            "dtype": "float",
            "description": "–î—ñ–∞—Å—Ç–æ–ª—ñ—á–Ω–∏–π –∞—Ä—Ç–µ—Ä—ñ–∞–ª—å–Ω–∏–π —Ç–∏—Å–∫ (–º–º —Ä—Ç.—Å—Ç.)",
            "required": False,
            "min": 30,
            "max": 150,
        },
        {
            "name": "LBXGLU",
            "dtype": "float",
            "description": "–†—ñ–≤–µ–Ω—å –≥–ª—é–∫–æ–∑–∏ –≤ –∫—Ä–æ–≤—ñ (–º–≥/–¥–ª)",
            "required": False,
            "min": 50,
            "max": 500,
        },
        {
            "name": "LBXTC",
            "dtype": "float",
            "description": "–ó–∞–≥–∞–ª—å–Ω–∏–π —Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω (–º–≥/–¥–ª)",
            "required": False,
            "min": 100,
            "max": 400,
        },
    ]
    
    return schema


def get_model_versions() -> Dict[str, Dict]:
    """
    –û—Ç—Ä–∏–º—É—î –≤–µ—Ä—Å—ñ—ó –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å—ñ—Ö targets.
    
    Returns:
        –°–ª–æ–≤–Ω–∏–∫ –∑ –≤–µ—Ä—Å—ñ—è–º–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ target
    """
    versions = {}
    targets = ["diabetes_present", "obesity_present"]
    
    for target in targets:
        champion_path = MODELS_DIR / target / "champion.json"
        if champion_path.exists():
            with open(champion_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
                raw_name = metadata.get("model_name")
                display_name = MODEL_LABELS.get(raw_name, raw_name)
                model_key = None
                for key, folder in MODEL_KEY_MAP.items():
                    if folder == raw_name:
                        model_key = key
                        break
                versions[target] = {
                    "model_name": display_name,
                    "model_key": model_key,
                    "is_calibrated": (MODELS_DIR / target / "champion_calibrated.joblib").exists(),
                    "metrics": metadata.get("metrics", {}),
                }
    
    return versions


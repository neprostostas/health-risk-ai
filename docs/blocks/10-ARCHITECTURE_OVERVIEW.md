# Архітектурний огляд системи HealthRisk.AI

HealthRisk.AI — це комплексна система для оцінки та прогнозування ризиків здоров'я на основі медичних даних NHANES (National Health and Nutrition Examination Survey). Система трансформує сирі медичні дані через етапи обробки, аналізу та машинного навчання в інтерактивний веб-застосунок, який дозволяє користувачам отримувати персоналізовані оцінки ризиків здоров'я та рекомендації.

Система складається з кількох великих шарів, які працюють разом для забезпечення повної функціональності: дані (ETL + EDA), ML моделі, API, фронтенд (SPA), база даних, AI-асистент (Ollama), система звітів (PDF/Excel/CSV), тестова інфраструктура. Кожен шар має свою відповідальність та інтегрується з іншими для створення єдиної системи.

Цей документ надає високорівневий огляд усіх взаємозв'язків між компонентами системи, показуючи, як дані проходять від сирих NHANES-таблиць до інтерактивного веб-інтерфейсу та звітів. Документ не повторює детальні технічні описи з інших блоків документації, а фокусується на архітектурних принципах, потоках даних та логічних зв'язках між компонентами.

## Високорівнева структура системи

Система HealthRisk.AI організована за принципом багатошарової архітектури з чітким розділенням відповідальності між компонентами. Кожен шар виконує конкретні завдання та взаємодіє з іншими через чітко визначені інтерфейси.

**Блок ETL & Data** — це фундаментальний шар системи, який відповідає за збір, обробку та підготовку даних. Сирі дані NHANES з Kaggle (шість CSV-файлів: демографія, обстеження, лабораторії, опитувальники, харчування, ліки) завантажуються та об'єднуються за унікальним ідентифікатором `SEQN`. ETL-скрипти виконують очищення даних (видалення дублікатів, обробка пропусків, фільтрація), відбір релевантних змінних та формування цільових змінних (obesity_present, diabetes_present). Результатом є очищений об'єднаний датасет `health_dataset.csv`, який слугує основою для всіх подальших етапів.

**Блок EDA** — це аналітичний шар, який досліджує підготовлений датасет для розуміння розподілів, кореляцій та закономірностей у даних. EDA генерує візуалізації (гістограми, боксплоти, діаграми розсіювання, кореляційні матриці), обчислює описові статистики та формулює висновки про ключові фактори ризику. Результати EDA використовуються для вибору ознак для моделей, обґрунтування архітектури моделей та інтегруються у веб-інтерфейс для прозорості системи.

**Блок ML-моделі** — це інтелектуальний шар системи, який трансформує медичні параметри в оцінки ризиків. На цьому етапі навчаються множина моделей машинного навчання (Logistic Regression, Random Forest, XGBoost, SVC, KNN, MLP) для прогнозування ризиків діабету та ожиріння. Моделі оцінюються за метриками (ROC-AUC, Average Precision, F1, Brier Score), після чого обирається найкраща (champion) модель для кожної задачі. Champion-моделі проходять калібрування для покращення якості ймовірностей та зберігаються як артефакти для використання в API.

**Блок Backend / API** — це центральний шар взаємодії, який об'єднує всі компоненти системи. FastAPI-бекенд забезпечує REST API для фронтенду, виконує ML inference через завантаження та використання навчених моделей, управляє аутентифікацією користувачів через JWT-токени, зберігає та читає дані з бази даних, інтегрується з Ollama для AI-асистента та надає системні ендпоінти для моніторингу стану системи. API працює як оркестратор, який координує роботу всіх компонентів для обробки запитів користувачів.

**Блок Database** — це шар персистентності, який зберігає всі динамічні дані системи. SQLite база даних містить таблиці для користувачів (профілі, хеші паролів, токени), історії прогнозів (всі виконані прогнози з параметрами та результатами), чатів та повідомлень (комунікація між користувачами), AI-асистента (історія діалогів), блокувань користувачів. БД є єдиним джерелом правди для всіх динамічних даних, які змінюються під час роботи системи.

**Блок Frontend (SPA)** — це інтерфейсний шар, який забезпечує взаємодію користувачів з системою. Single Page Application на чистому JavaScript надає форми для введення медичних параметрів, відображає результати прогнозування, діаграми та аналітику, інтегрує чати між користувачами та AI-асистента, генерує PDF-звіти з результатами, показує статус системи та забезпечує навігацію між сторінками без перезавантаження. Фронтенд працює як тонкий клієнт, який отримує дані через API та відображає їх користувачам.

**Блок AI (Ollama)** — це допоміжний інтелектуальний шар, який надає AI-асистента для пояснення результатів та надання рекомендацій. Локальна мовна модель Ollama (Llama3) працює як окремий сервіс, до якого бекенд звертається через HTTP API для генерації відповідей на запити користувачів. AI-асистент використовує контекст про стан здоров'я користувача (останні прогнози, історія) для надання персоналізованих рекомендацій.

**Блок Reporting** — це шар генерації звітів, який трансформує результати прогнозування в структуровані документи. PDF-звіти генеруються на фронтенді через jsPDF та Chart.js, включаючи текст з поясненнями, діаграми ризиків, топ фактори впливу та технічні деталі. Бекенд надає структуровані дані для звітів через API, а фронтенд відповідає за візуальне оформлення та експорт у різні формати (PDF, Excel, CSV).

**Блок Testing** — це шар забезпечення якості, який перевіряє коректність роботи всіх компонентів системи. Тестова інфраструктура включає unit тести для окремих функцій та утиліт, інтеграційні тести для перевірки взаємодії між компонентами (API-БД, API-ML), e2e тести для повних сценаріїв користувачів, ML тести для перевірки моделей та експериментальні тести для граничних випадків. Тести забезпечують стабільність системи та допомагають виявляти проблеми на ранніх етапах розробки.

**Логічні зв'язки між блоками** організовані за принципом односпрямованого потоку даних: ETL → EDA → ML → API → Frontend. Дані проходять від сирих таблиць через обробку та аналіз до навчених моделей, які використовуються в API для обробки запитів користувачів. Фронтенд отримує дані через API та відображає їх користувачам. БД зберігає всі динамічні дані та використовується API для персистентності. AI-асистент та звіти працюють як допоміжні сервіси, які використовують дані з основних компонентів для надання додаткової функціональності.

## Потік даних: від сирих NHANES до прогнозу ризику

Потік даних у системі HealthRisk.AI організований як послідовна трансформація від сирих медичних даних до персоналізованих оцінок ризиків для користувачів.

**Сирі дані NHANES → ETL** — процес починається з завантаження сирих таблиць NHANES з Kaggle (шість CSV-файлів: demographic.csv, examination.csv, labs.csv, questionnaire.csv, diet.csv, medications.csv). ETL-скрипти об'єднують таблиці за унікальним ідентифікатором `SEQN`, виконують очищення даних (видалення дублікатів, обробка пропусків, фільтрація рядків з надмірними пропусками), відбирають релевантні змінні (вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин) та формують цільові змінні (obesity_present, diabetes_present) на основі бізнес-правил. Результатом є очищений об'єднаний датасет `health_dataset.csv`, який містить структуровані дані для подальшого аналізу.

**health_dataset.csv → EDA** — підготовлений датасет передається до етапу дослідницького аналізу даних, де виконується аналіз розподілів змінних, кореляцій між ознаками, візуалізації ключових показників та формування висновків про фактори ризику. EDA генерує графіки (гістограми, боксплоти, діаграми розсіювання, кореляційні матриці), обчислює описові статистики та виявляє закономірності у даних. Результати EDA зберігаються у `artifacts/eda/` та використовуються для формування уявлення про ключові фактори ризику та обґрунтування вибору ознак для моделей.

**EDA → ML-моделі** — висновки з EDA впливають на вибір ознак для моделей машинного навчання. На основі аналізу кореляцій, розподілів та зв'язків між змінними обираються ключові ознаки (вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин), які використовуються для навчання моделей. Датасет розділяється на тренувальну та тестову вибірки, після чого навчаються множина моделей для прогнозування ризиків діабету та ожиріння. Моделі оцінюються за метриками (ROC-AUC, Average Precision, F1, Brier Score), обирається найкраща (champion) модель для кожної задачі, яка проходить калібрування для покращення якості ймовірностей. Навчені моделі зберігаються як артефакти у `artifacts/models/` для використання в API.

**Навчені моделі → API** — навчені моделі зберігаються у форматі `.joblib` у файловій системі та завантажуються в пам'ять при першому використанні через реєстр моделей. Під час запуску бекенд завантажує champion-моделі (з пріоритетом каліброваних версій) та кешує їх для швидкого доступу. При запиті на прогноз API отримує вхідні параметри користувача (вік, стать, ІМТ, тиск, глюкоза, холестерин), перетворює їх у DataFrame, передає через pipeline моделі (який виконує імпутацію, стандартизацію, кодування), отримує ймовірність ризику, визначає категорію ризику (низький, середній, високий) та обчислює топ фактори впливу. Результат повертається у форматі JSON для фронтенду та зберігається в БД для історії.

## Взаємодія користувача з системою

Типова взаємодія користувача з системою HealthRisk.AI організована як послідовний pipeline від введення даних до отримання результатів та звітів.

**Користувач заходить на фронтенд (SPA)** — при відкритті веб-застосунку бекенд повертає HTML-файл `index.html`, який містить всі секції сторінок у прихованому стані. JavaScript на фронтенді визначає, яку секцію показати на основі URL. Якщо користувач не залогінений, він перенаправляється на `/login`, якщо залогінений — на `/app` (форма прогнозування).

**На /app користувач заповнює форму показників** — форма містить поля для введення медичних параметрів: вік, стать, індекс маси тіла (ІМТ), систолічний та діастолічний артеріальний тиск, рівень глюкози в крові, загальний холестерин. Фронтенд виконує клієнтську валідацію форми (перевірка типів, діапазонів, обов'язковості полів) перед відправкою на сервер.

**Дані через fetch відправляються в /api/predict** — після заповнення форми та натискання кнопки "Прогнозувати" фронтенд формує HTTP POST-запит до ендпоінту `/predict` з JSON-даними користувача та цільовою змінною (діабет або ожиріння). Запит включає JWT-токен у заголовку `Authorization` для автентифікації (якщо користувач залогінений).

**API обробляє запит** — бекенд отримує запит, перевіряє JWT-токен для автентифікації (якщо потрібно), валідує вхідні дані через Pydantic-схему `PredictRequest`, завантажує відповідну ML-модель через реєстр моделей (чемпіон або конкретна модель за запитом), перетворює JSON-дані у pandas DataFrame, передає через pipeline моделі (який виконує імпутацію пропущених значень, стандартизацію числових ознак, one-hot encoding категоріальних), отримує ймовірність ризику через `predict_proba()`, визначає категорію ризику (низький, середній, високий) на основі ймовірності, обчислює топ-5 факторів впливу через функцію `calculate_top_factors_simple()`, зберігає прогноз в БД через `save_history_entry()` (якщо користувач автентифікований) та формує JSON-відповідь з результатами.

**Відповідь повертається у фронтенд** — API повертає JSON-відповідь з полями: `probability` (ймовірність ризику 0-1), `risk_bucket` (категорія ризику), `top_factors` (список факторів з їх впливом), `model_name` (назва використаної моделі), `target` (цільова змінна). Фронтенд отримує відповідь, зберігає результати в стані `modelResultsState`, відображає ймовірність ризику з візуалізацією (кольорові індикатори, прогрес-бари), показує топ фактори впливу у вигляді списку з відсотками, оновлює діаграми (якщо відкрита сторінка `/diagrams`) та надає можливість згенерувати PDF-звіт з результатами.

**Генерація PDF-звіту** — користувач може натиснути кнопку "Згенерувати звіт" для створення PDF-документа з результатами прогнозування. Фронтенд використовує jsPDF та Chart.js для генерації PDF на клієнті: отримує структуровані дані з API (результати прогнозу, топ фактори, метадані моделі), створює PDF-документ, додає текст з поясненнями, вставляє діаграми ризиків (як зображення з canvas), додає топ фактори впливу, технічні деталі та зберігає файл для завантаження користувачем.

## Логічні модулі та сторінки системи

Система HealthRisk.AI організована за принципом модульності, де кожна сторінка та функціональна область має свою роль у загальній архітектурі.

**Головна форма прогнозування (/app)** — це точка входу для прогнозів ризиків здоров'я. Сторінка містить форму для введення медичних параметрів, відображає результати прогнозування з візуалізацією ризиків, показує топ фактори впливу та надає можливість згенерувати PDF-звіт. Сторінка використовує API ендпоінт `/predict` для отримання прогнозів, зберігає результати в стані `modelResultsState` та інтегрується з AI-асистентом для отримання рекомендацій на основі результатів.

**Звіти (/reports)** — це сторінка для роботи з історією прогнозів та генерації звітів. Сторінка відображає список всіх збережених прогнозів користувача, дозволяє фільтрувати за цільовими змінними, категоріями ризику та датами, надає можливість згенерувати PDF/Excel/CSV звіти для вибраних прогнозів та показує статистику по історії. Сторінка використовує API ендпоінти `/users/history` для отримання історії, `/users/history/stats` для статистики та інтегрується з фронтенд-генераторами PDF/Excel/CSV для експорту даних.

**Діаграми (/diagrams)** — це сторінка для візуалізації результатів та EDA-статистики. Сторінка відображає діаграми ризиків (розподіли ймовірностей, категорії ризику), кореляції між ознаками, розподіли за віком та статтю, часові серії історії прогнозів та EDA-візуалізації з `artifacts/eda/`. Сторінка використовує Chart.js для побудови діаграм, отримує дані з API ендпоінтів `/users/history/stats` та `/metadata`, кешує дані в стані `diagramState` для швидкого оновлення та експортує діаграми у PDF-звіти.

**Історія (/history)** — це сторінка для перегляду всіх збережених прогнозів користувача. Сторінка відображає список прогнозів з датами, цільовими змінними, ймовірностями, категоріями ризику, дозволяє фільтрувати та сортувати записи, надає можливість видалити окремі прогнози або очистити всю історію та показує детальну інформацію про кожен прогноз. Сторінка використовує API ендпоінти `/users/history` для отримання списку, `/users/history/{id}` (DELETE) для видалення, `/users/history/clear` для очищення та зберігає дані в стані `authState.history` для швидкого доступу.

**Профіль (/profile)** — це сторінка для управління даними користувача. Сторінка відображає профіль користувача (ім'я, прізвище, email, дата народження, стать), дозволяє оновити профіль, змінити пароль, завантажити або видалити аватар, надає можливість видалити акаунт та показує статистику використання системи. Сторінка використовує API ендпоінти `/users/me` для отримання профілю, `/auth/update-profile` для оновлення, `/auth/change-password` для зміни пароля, `/users/avatar` для управління аватарами та зберігає дані в стані `authState.user`.

**AI-асистент (/assistant)** — це сторінка для взаємодії з AI-асистентом здоров'я. Сторінка містить чат-інтерфейс для відправки повідомлень асистенту, відображає історію діалогів, надає можливість очистити історію та показує статус Ollama сервера. Сторінка використовує API ендпоінти `/assistant/chat` для відправки повідомлень, `/assistant/history` для отримання історії, `/assistant/health` для перевірки статусу Ollama, інтегрується з бекенд-сервісом `assistant_llm.py` для генерації відповідей через Ollama та зберігає історію в стані `chatState` для швидкого доступу.

**Чати (/chats)** — це сторінка для комунікації між користувачами. Сторінка відображає список всіх чатів користувача з інформацією про останнє повідомлення та кількість непрочитаних, дозволяє створювати нові чати, відкривати існуючі чати, блокувати користувачів, закріплювати чати та змінювати порядок відображення. Сторінка використовує API ендпоінти `/api/chats` для отримання списку, `/api/chats` (POST) для створення, `/api/chats/{chat_uuid}` для деталей, `/api/chats/{chat_uuid}/messages` (POST) для відправки повідомлень, `/users/block` для блокування та зберігає дані в стані `chatState`.

**Статус системи (/api-status)** — це сторінка для моніторингу стану системи. Сторінка відображає статуси API (доступність, версія, маршрути), бази даних (кількість записів, розмір, активність), Ollama сервера (доступність, латентність, модель), показує історію змін статусів та надає можливість оновити статуси вручну. Сторінка використовує API ендпоінти `/health` для статусу API, `/system/database/stats` для статусу БД, `/assistant/health` для статусу Ollama, оновлює дані автоматично через інтервали та зберігає історію в стані `apiStatusState`.

**Про систему (/about)** — це інформаційна сторінка, яка пояснює, що таке HealthRisk.AI, як працює система, які дані використовуються, як інтерпретувати результати та де знайти додаткову інформацію. Сторінка не використовує API ендпоінти, а містить статичний контент, який локалізується через i18n модуль.

## Роль бази даних в архітектурі

База даних у системі HealthRisk.AI виконує роль центрального сховища стану, яке зберігає всі динамічні дані та забезпечує персистентність між сесіями користувачів.

**Частини системи, що залежать від БД** включають аутентифікацію (зберігання профілів користувачів, хешів паролів, токенів для відновлення пароля), історію прогнозів (всі виконані прогнози з параметрами, результатами, топ факторами впливу), чати та повідомлення (комунікація між користувачами, статуси прочитання, закріплення чатів), блокування користувачів (інформація про блокування для запобігання створенню чатів та відправці повідомлень), профіль користувача (ім'я, прізвище, email, дата народження, стать, аватар), AI-асистента (історія повідомлень з асистентом, зв'язки з конкретними прогнозами для контексту).

**ML-модель сама по собі не зберігається в БД** — навчені моделі машинного навчання зберігаються у файловій системі у форматі `.joblib` у директорії `artifacts/models/`. Моделі завантажуються в пам'ять при першому використанні через реєстр моделей та кешуються для швидкого доступу. БД зберігає тільки метадані про використані моделі (назва, версія) у таблиці `predictionhistory` для історії прогнозів, але самі моделі залишаються у файловій системі.

**БД є джерелом "живої" інформації про активність користувача** — база даних зберігає всі дані, які змінюються під час роботи системи: нові прогнози, повідомлення в чатах, оновлення профілів, блокування користувачів. Ці дані не можуть бути згенеровані з інших джерел та є унікальними для кожної сесії користувача. БД забезпечує персистентність між сесіями, дозволяючи користувачам повертатися до своїх даних при наступних візитах.

## Архітектура інтеграції з локальною AI-моделлю (Ollama)

Інтеграція з Ollama в системі HealthRisk.AI організована як окремий сервіс, який доповнює основну функціональність системи AI-асистентом для пояснення результатів та надання рекомендацій.

**Ollama — це окремий локальний сервіс** — Ollama працює як окремий процес на локальній машині, який надає HTTP API для генерації відповідей через локальну мовну модель (Llama3). Сервер запускається окремо від бекенду через команду `ollama serve` та слухає на порту 11434. Модель Llama3 завантажується через `ollama pull llama3` та зберігається локально для швидкого доступу.

**Бекенд взаємодіє з Ollama через HTTP API** — бекенд використовує модуль `services/assistant_llm.py` для інтеграції з Ollama. Модуль формує контекст про стан здоров'я користувача на основі останнього прогнозу через `build_health_context()`, конструює промпт для LLM з інструкціями та контекстом через `build_assistant_prompt()`, викликає Ollama через HTTP POST-запит до `http://localhost:11434/api/generate` через `call_ollama()`, обробляє відповіді (які можуть бути у форматі NDJSON для streaming), обробляє помилки та таймаути та зберігає історію повідомлень в БД через `add_message()`.

**Фронтенд через бекенд отримує відповіді AI** — фронтенд відправляє повідомлення асистенту через API ендпоінт `/assistant/chat`, який приймає текст повідомлення, формує контекст про стан користувача, викликає Ollama через бекенд-сервіс, отримує відповідь від Ollama, зберігає повідомлення та відповідь в БД, повертає відповідь у форматі JSON для фронтенду. Фронтенд відображає відповідь в чат-інтерфейсі, оновлює історію діалогів та надає можливість продовжити розмову.

**API-status перевіряє доступність Ollama** — сторінка `/api-status` використовує API ендпоінт `/assistant/health` для перевірки статусу Ollama сервера. Ендпоінт виконує HTTP GET-запит до `http://localhost:11434/api/tags` для перевірки доступності, вимірює латентність запиту, перевіряє наявність моделі Llama3 та повертає статус (доступний, недоступний, помилка) з деталями. Фронтенд відображає статус Ollama на сторінці API-status з візуальними індикаторами (зелений, жовтий, червоний) та оновлює статус автоматично через інтервали.

**Чат з AI вписується в загальну картину** — AI-асистент не впливає на core ML ризиків, а доповнює систему як помічник для пояснення результатів та надання рекомендацій. Асистент використовує контекст про стан здоров'я користувача (останні прогнози, історія) для надання персоналізованих відповідей, але не змінює логіку прогнозування ризиків, яка базується на навчених ML-моделях. Асистент працює як додатковий шар інтелектуальності, який допомагає користувачам розуміти результати та приймати рішення.

## Архітектура генерації звітів

Система генерації звітів у HealthRisk.AI організована як гібридна архітектура, де бекенд надає структуровані дані, а фронтенд відповідає за візуальне оформлення та експорт у різні формати.

**Бекенд дає структуровані дані для звіту** — API надає структуровані дані для звітів через ендпоінти `/predict` (результати прогнозування), `/users/history` (історія прогнозів), `/users/history/stats` (статистика для діаграм), `/explain` (пояснення моделі). Дані повертаються у форматі JSON з типізованими полями (ймовірність, категорія ризику, топ фактори, метадані моделі), що забезпечує консистентність та валідацію на рівні API. Бекенд не генерує PDF безпосередньо, а надає дані для генерації на фронтенді.

**Фронтенд за допомогою jsPDF + Chart.js формує PDF** — фронтенд використовує бібліотеку jsPDF для створення PDF-документів та Chart.js для експорту діаграм як зображень. Процес генерації включає: отримання структурованих даних з API (результати прогнозу, топ фактори, метадані), створення PDF-документа через `new jsPDF()`, додавання тексту з поясненнями (з підтримкою кирилиці через шрифт DejaVuSans), вставку діаграм ризиків (як зображення з canvas через `chart.toBase64Image()`), додавання топ факторів впливу у вигляді списку, додавання технічних деталей (назва моделі, версія, дата генерації), збереження файлу для завантаження користувачем. PDF генерується на клієнті, що зменшує навантаження на сервер та забезпечує швидкий відгук.

**Механізм пов'язаний з ML, API, фронтендом і БД** — генерація звітів інтегрується з усіма компонентами системи: ML-моделі надають результати прогнозування (ймовірність, категорія ризику, топ фактори), API передає дані у форматі JSON для фронтенду, фронтенд отримує дані та формує PDF-документ, БД зберігає історію прогнозів для включення в звіти. Звіти можуть включати дані з одного прогнозу або агреговані дані з історії прогнозів, що дозволяє користувачам аналізувати зміни ризиків у часі.

## Тестування як частина архітектури системи

Тестування в системі HealthRisk.AI інтегроване в архітектуру як невід'ємна частина забезпечення якості та стабільності системи.

**Unit тести перевіряють окремі модулі** — unit тести покривають окремі функції та утиліти ізольовано від інших компонентів: хешування паролів, JWT токени, валідація Pydantic схем, завантаження моделей, логіка прогнозування. Тести перевіряють коректність обробки валідних даних, граничних випадків та некоректних даних, що забезпечує надійність окремих компонентів перед інтеграцією.

**Інтеграційні тести перевіряють зв'язок API–БД–ML** — інтеграційні тести перевіряють взаємодію між компонентами: автентифікація через API з збереженням в БД, прогнозування через API з використанням ML-моделей та збереженням результатів в БД, повний цикл запиту прогнозу від вхідних даних до збереження в історії. Тести використовують тестову БД (тимчасову SQLite) для ізоляції та автоматичного очищення після завершення, що забезпечує стабільність та відтворюваність тестів.

**Тести для історії прогнозів, auth, блокування, чатів, API-status** — інтеграційні тести покривають всі ключові функціональні області системи: тести для автентифікації (реєстрація, логін, зміна пароля, відновлення пароля), тести для історії прогнозів (збереження, читання, видалення, статистика), тести для блокування користувачів (блокування, розблокування, фільтрація), тести для чатів (створення, відправка повідомлень, читання), тести для API-status (перевірка статусів компонентів). Тести забезпечують, що всі компоненти працюють коректно разом та обробляють помилки правильно.

**Як це допомагає гарантувати стабільність всієї системи** — тестова інфраструктура забезпечує автоматичну перевірку коректності роботи всіх компонентів при змінах коду, виявляє регресії на ранніх етапах розробки, підтверджує, що інтеграції між компонентами працюють коректно, перевіряє обробку граничних випадків та помилок, забезпечує відтворюваність результатів та допомагає підтримувати якість коду на високому рівні. Тести інтегруються з процесом розробки через автоматичний запуск перед комітами, перевірку coverage та блокування мерджу при невдалих тестах.

## Нефункціональні аспекти архітектури

Архітектура системи HealthRisk.AI враховує нефункціональні вимоги, які впливають на продуктивність, надійність, масштабованість та розширюваність системи.

**Продуктивність** — система оптимізована для локального використання з невеликою затримкою: ML-моделі завантажуються в пам'ять при першому використанні та кешуються для швидкого доступу, локальна SQLite БД забезпечує швидкий доступ до даних без мережевих затримок, фронтенд працює як SPA без перезавантаження сторінок, API обробляє запити асинхронно через FastAPI для підвищення продуктивності, Ollama працює локально для швидкої генерації відповідей. Для продакшену можна додати кешування результатів прогнозів, оптимізацію запитів до БД, використання більш потужної БД (PostgreSQL) та масштабування через load balancing.

**Надійність** — система забезпечує обробку помилок та відновлення після збоїв: API обробляє помилки через try/catch блоки та повертає структуровані JSON-відповіді з відповідними статус-кодами, БД використовує транзакції для забезпечення цілісності даних, ML-моделі обробляють граничні випадки (екстремальні значення, пропущені дані) через pipeline, API-status моніторить стан компонентів для виявлення проблем, тести перевіряють обробку помилок та граничних випадків. Для покращення надійності можна додати логування помилок у зовнішню систему (ELK stack, Sentry), автоматичне відновлення після збоїв, резервне копіювання БД та health checks для всіх компонентів.

**Масштабованість** — поточна архітектура оптимізована для середніх навантажень, але може бути масштабована для продакшену: SQLite може бути замінена на PostgreSQL для підтримки більшої кількості одночасних користувачів, ML-моделі можуть бути винесені в окремий сервіс для горизонтального масштабування, API може бути розгорнуто на кількох серверах з load balancing, Ollama може бути замінена на cloud-based LLM API для масштабування, фронтенд може бути розгорнуто на CDN для швидкого доступу. Для масштабування також потрібно додати кешування (Redis), асинхронні черги для обробки запитів, моніторинг продуктивності та автоматичне масштабування на основі навантаження.

**Розширюваність** — архітектура дозволяє легко додавати нові функції та компоненти: нові ML-моделі можуть бути додані через реєстр моделей без змін в API, нові мови інтерфейсу можуть бути додані через i18n модуль з додаванням JSON-файлів перекладів, нові типи звітів можуть бути додані через фронтенд-генератори без змін в бекенді, нові ендпоінти можуть бути додані через модульні роутери без впливу на існуючі, нові типи ризиків можуть бути додані через додавання нових цільових змінних та моделей. Модульна архітектура забезпечує, що зміни в одному компоненті не впливають на інші, що спрощує розширення та підтримку системи.

## Підсумок

HealthRisk.AI — це завершена система з повним циклом від сирих медичних даних до інтерактивного веб-інтерфейсу та звітів. Система трансформує сирі NHANES-таблиці через етапи ETL (обробка та очищення), EDA (аналіз та візуалізація), ML (навчання моделей) в інтерактивний веб-застосунок, який дозволяє користувачам отримувати персоналізовані оцінки ризиків здоров'я та рекомендації. Кожен етап має свою роль у загальній архітектурі та інтегрується з іншими для створення єдиної системи.

Архітектура продумана так, щоб розділити відповідальності між компонентами (ETL для обробки даних, EDA для аналізу, ML для прогнозування, API для взаємодії, фронтенд для інтерфейсу, БД для персистентності), спростити тестування через модульну структуру та ізоляцію компонентів, дати можливість розвитку через додавання нових моделей, нових форматів звітів, нових мов інтерфейсу без змін в існуючих компонентах. Система працює як оркестрована архітектура, де кожен компонент виконує свою роль, але разом вони створюють потужну систему для оцінки та прогнозування ризиків здоров'я.


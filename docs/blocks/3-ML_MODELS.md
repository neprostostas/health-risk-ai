# ML-моделі проєкту HealthRisk.AI

Система HealthRisk.AI містить набір моделей машинного навчання для прогнозування ризиків здоров'я (ожиріння та діабет). Моделі навчаються на датасеті NHANES, проходять оптимізацію, калібрування та інтегруються у веб-інтерфейс та API для реального використання. Кожна модель оцінюється за множиною метрик, після чого обирається найкраща (champion) модель для кожної задачі.

## Набір моделей

У проєкті навчаються та оцінюються наступні моделі машинного навчання для двох цільових змінних:

### Моделі для прогнозування діабету (`diabetes_present`)

**Розташування артефактів:** `artifacts/models/diabetes_present/`

1. **LogisticRegression** (Логістична регресія)
   - Використовує ознаки: вік, стать, ІМТ, артеріальний тиск, холестерин, глюкоза
   - Артефакти: `artifacts/models/diabetes_present/LogisticRegression/`

2. **RandomForest** (Випадковий ліс)
   - Використовує ті самі ознаки
   - Артефакти: `artifacts/models/diabetes_present/RandomForest/`

3. **XGBoost** (Gradient Boosting)
   - Використовує ті самі ознаки
   - Артефакти: `artifacts/models/diabetes_present/XGBoost/`

4. **SVC** (Support Vector Classifier)
   - Використовує ті самі ознаки
   - Артефакти: `artifacts/models/diabetes_present/SVC/`

5. **KNN** (K-Nearest Neighbors)
   - Використовує ті самі ознаки
   - Артефакти: `artifacts/models/diabetes_present/KNN/`

6. **MLP** (Multi-Layer Perceptron, нейромережа)
   - Використовує ті самі ознаки
   - Артефакти: `artifacts/models/diabetes_present/MLP/`

### Моделі для прогнозування ожиріння (`obesity_present`)

**Розташування артефактів:** `artifacts/models/obesity_present/`

Всі перелічені вище моделі також навчаються для прогнозування ожиріння з тими самими ознаками. Структура артефактів аналогічна: `artifacts/models/obesity_present/{ModelName}/`

### Основні ознаки

Всі моделі використовують наступний набір ознак:

- **`RIDAGEYR`** — вік особи (роки)
- **`RIAGENDR`** — стать (1 = чоловік, 2 = жінка)
- **`BMXBMI`** — індекс маси тіла (ІМТ)
- **`BPXSY1`** — систолічний артеріальний тиск (мм рт.ст.)
- **`BPXDI1`** — діастолічний артеріальний тиск (мм рт.ст.)
- **`LBXTC`** — загальний холестерин (мг/дл)
- **`LBXGLU`** — рівень глюкози в крові (мг/дл) — додається, якщо доступна в датасеті

## Навчання моделей

### Скрипти навчання

Основна логіка навчання реалізована у файлі **`src/models/train_many.py`** (приблизно 631 рядок коду). Цей скрипт відповідає за:

- Завантаження та підготовку даних
- Створення пайплайнів попередньої обробки
- Навчання всіх моделей для кожної цільової змінної
- Оцінку метрик та збереження результатів

### Pipeline навчання

Процес навчання складається з наступних етапів:

1. **Завантаження даних**
   - Зчитування `datasets/processed/health_dataset.csv`
   - Вибір доступних ознак з базового списку
   - Додавання глюкози (`LBXGLU`), якщо вона присутня в датасеті

2. **Підготовка даних**
   - Видалення рядків з пропущеними значеннями в обраних ознаках та цільовій змінній
   - Розділення на тренувальну та тестову вибірки (80/20) зі стратифікацією за цільовою змінною
   - Використання `random_state=42` для відтворюваності результатів

3. **Попередня обробка (preprocessing)**
   - **Для числових ознак:**
     - Імпутація пропущених значень медіаною (`SimpleImputer`)
     - Стандартизація (нормалізація) за допомогою `StandardScaler`
   - **Для категоріальних ознак:**
     - Імпутація найчастішим значенням
     - One-hot encoding з `drop='first'` для уникнення мультиколінеарності
   - Створення `ColumnTransformer` для об'єднання обох пайплайнів

4. **Навчання моделей**
   - Створення повного пайплайну: `Pipeline([("preprocessor", preprocessor), ("model", model)])`
   - Навчання на тренувальній вибірці
   - Передбачення на тестовій вибірці

5. **Обчислення метрик**
   - **ROC-AUC** (Area Under ROC Curve) — основна метрика для бінарної класифікації
   - **Average Precision** (AUPRC) — метрика для незбалансованих класів
   - **Accuracy** — загальна точність
   - **Precision** — точність позитивних передбачень
   - **Recall** — повнота (чутливість)
   - **F1-score** — гармонійне середнє precision та recall
   - **Brier Score** — метрика калібрування ймовірностей

6. **Збереження артефактів**
   - Модель зберігається у форматі `.joblib` у `artifacts/models/{target}/{ModelName}/model.joblib`
   - Метрики записуються у `metrics.json`
   - Побудова та збереження графіків:
     - `roc.png` — ROC-крива
     - `pr.png` — Precision-Recall крива
     - `calibration.png` — крива калібрування

7. **Створення лідерборду**
   - Всі моделі ранжуються за ROC-AUC та Average Precision
   - Результати зберігаються у `leaderboard.csv` у директорії цільової змінної

### Вибір "Champion Model"

Після навчання всіх моделей для кожної цільової змінної автоматично обирається чемпіонська модель:

1. **Критерії відбору:** Модель з найвищим ROC-AUC, а у разі рівності — з найвищим Average Precision
2. **Збереження метаданих:** Інформація про чемпіона записується у `champion.json`, який містить:
   - Назву моделі
   - Шлях до файлу моделі
   - Всі метрики продуктивності
3. **Обчислення важливості ознак:** Для чемпіонської моделі обчислюється permutation importance:
   - Використовується метод `permutation_importance` з scikit-learn
   - Результати зберігаються у `champion_importance.json`
   - Побудова графіка важливості ознак у `champion_importance.png`

**Розташування чемпіонів:**
- Діабет: `artifacts/models/diabetes_present/champion.json`
- Ожиріння: `artifacts/models/obesity_present/champion.json`

## Калібрування моделей

### Процес калібрування

Після вибору чемпіонських моделей вони проходять калібрування для покращення якості ймовірностей. Це реалізовано у файлі **`src/models/calibrate_champions.py`** (приблизно 376 рядків коду).

**Методи калібрування:**
- **Isotonic Regression** — непараметричний метод, який намагається знайти монотонну функцію для калібрування
- **Platt Scaling (Sigmoid)** — параметричний метод, який використовує логістичну регресію

**Процес:**
1. Завантаження чемпіонської моделі
2. Розділення тренувальних даних на train та validation (80/20)
3. Тестування обох методів калібрування на validation set
4. Вибір методу з найкращим Brier Score
5. Переобучення каліброваної моделі на всіх тренувальних даних
6. Оцінка покращення метрик (Brier Score, ROC-AUC, AUPRC)

**Артефакти калібрування:**
- Калібрована модель: `champion_calibrated.joblib`
- Графіки калібрування: `calibration_before.png` та `calibration_after.png`
- Метрики до/після: `metrics_before_after.json`

**Призначення калібрування:** Забезпечити, щоб ймовірності ризику, які повертає модель, були реалістичними та лінійними. Наприклад, якщо модель повертає ймовірність 0.7, то приблизно 70% випадків з такою ймовірністю повинні бути позитивними. Це критично важливо для медичних застосунків, де точність ймовірностей впливає на прийняття рішень.

## Інференс (прогнозування) у API

### API endpoints

Логіка інференсу реалізована у файлі **`src/service/api.py`** (приблизно 921 рядок коду) та використовує реєстр моделей з **`src/service/model_registry.py`**.

**Основні endpoints:**

1. **`POST /predict`** — прогнозування ризику
   - **Вхідні параметри:**
     - `target` — цільова змінна (`diabetes_present` або `obesity_present`)
     - `model` — назва моделі (за замовчуванням `auto` — використовує чемпіона)
     - Дані користувача через `PredictRequest`: вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин
   - **Процес:**
     1. Завантаження моделі (чемпіон або конкретна модель за запитом)
     2. Валідація вхідних даних за схемою ознак
     3. Створення DataFrame з одного рядка
     4. Передбачення ймовірності через `pipeline.predict_proba()`
     5. Визначення категорії ризику (низький, середній, високий) на основі ймовірності
     6. Обчислення топ-5 факторів, які найбільше впливають на прогноз
     7. Збереження історії прогнозування в базі даних (якщо користувач автентифікований)
   - **Вихід:**
     - `probability` — ймовірність ризику (0–1)
     - `risk_bucket` — категорія ризику
     - `top_factors` — список факторів з їх впливом
     - `model_name` — назва використаної моделі

2. **`POST /explain`** — пояснення моделі
   - **Вхідні параметри:**
     - `target` — цільова змінна
   - **Процес:**
     1. Завантаження чемпіонської моделі
     2. Завантаження тестових даних з `health_dataset.csv`
     3. Вибір випадкової вибірки (n=256)
     4. Обчислення permutation importance на цій вибірці
     5. Формування списку важливості ознак
   - **Вихід:**
     - `feature_importances` — список ознак з їх важливістю
     - `method` — метод обчислення (`permutation_importance`)

### Завантаження моделей

Моделі завантажуються через реєстр моделей (`model_registry.py`), який забезпечує:

- **Кешування в пам'яті** — моделі завантажуються один раз і зберігаються в пам'яті для швидкого доступу
- **Підтримка каліброваних моделей** — за замовчуванням використовується калібрована версія чемпіона, якщо вона доступна
- **Fallback до звичайних моделей** — якщо калібрована модель відсутня, використовується оригінальна

## Інтерпретація та фактори ризику

### Обчислення важливості ознак

У проєкті використовується два підходи для визначення важливості ознак:

1. **Permutation Importance** (для глобального пояснення моделі)
   - Обчислюється під час навчання для чемпіонської моделі
   - Зберігається у `champion_importance.json`
   - Використовується в endpoint `/explain` для глобального пояснення моделі
   - Показує, наскільки знижується продуктивність моделі при випадковому перемішуванні значень ознаки

2. **Спрощений підхід для індивідуальних прогнозів** (для `/predict`)
   - Використовує нормалізовані значення ознак як проксі для впливу
   - Кожна ознака нормалізується до діапазону [0, 1] на основі типових значень
   - Повертає топ-5 факторів, які найбільше впливають на конкретний прогноз

### Інтеграція у веб-інтерфейс та PDF

Важливість ознак інтегрована у:

- **Веб-інтерфейс** — відображається після кожного прогнозування у вигляді списку факторів з відсотками впливу
- **PDF-звіти** — включаються у звіти про прогнози, де показуються ключові фактори ризику для користувача
- **API відповіді** — повертаються у форматі JSON для використання у фронтенді

**Формат відображення:**
- Назви ознак перекладаються на зрозумілі користувачу терміни (наприклад, `RIDAGEYR` → "Вік", `BMXBMI` → "ІМТ")
- Вплив показується у відсотках або нормалізованих значеннях
- Фактори сортуються за спаданням впливу

## Роль ML-моделей у проєкті

ML-моделі є основою системи HealthRisk.AI, яка трансформує сирі медичні параметри (вік, стать, ІМТ, артеріальний тиск, лабораторні показники) в оцінку ризику здоров'я. Вони використовуються у всіх ключових компонентах проєкту:

- **Веб-інтерфейс** — користувачі вводять свої показники здоров'я та отримують прогнози ризиків у реальному часі
- **API** — забезпечує програмний доступ до моделей для інтеграції з іншими системами
- **PDF-звіти** — генеруються персоналізовані звіти з прогнозами та поясненнями факторів ризику
- **Історія прогнозування** — всі прогнози зберігаються в базі даних для подальшого аналізу та відстеження змін у стані здоров'я користувачів

Без ML-моделей система була б лише зберігачем даних. Моделі додають інтелектуальний шар, який дозволяє виявляти закономірності, оцінювати ризики та надавати персоналізовані рекомендації на основі науково обґрунтованих підходів машинного навчання.


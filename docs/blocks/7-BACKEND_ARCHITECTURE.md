# Архітектура бекенду HealthRisk.AI

Бекенд проєкту HealthRisk.AI побудований на FastAPI — сучасному асинхронному веб-фреймворку для Python, який забезпечує високу продуктивність, автоматичну генерацію документації API та типобезпеку через Pydantic. Архітектура бекенду організована за принципом сервісно-орієнтованої архітектури з чітким розділенням відповідальності між компонентами.

## Загальний огляд бекенду

Бекенд HealthRisk.AI виконує кілька ключових ролей в системі, об'єднуючи різні сервіси та компоненти для забезпечення повної функціональності додатку.

**Бекенд побудований на FastAPI** — сучасному асинхронному веб-фреймворку, який базується на Starlette та Pydantic. FastAPI забезпечує автоматичну генерацію OpenAPI-документації, валідацію даних через Pydantic-схеми, асинхронну обробку запитів через ASGI та високу продуктивність завдяки використанню async/await. Фреймворк інтегрується з Uvicorn як ASGI-сервером для запуску додатку.

**Архітектура сервісів** включає кілька логічно розділених компонентів:
- **Auth сервіс** — обробка аутентифікації, реєстрації, управління токенами, хешування паролів
- **ML моделі сервіс** — завантаження, кешування та інференс машинного навчання моделей
- **Чати сервіс** — управління чатами між користувачами, повідомленнями, блокуванням
- **Статус-система** — моніторинг стану API, бази даних та зовнішніх сервісів (Ollama)
- **AI-інтеграція** — інтеграція з локальним Ollama сервером для AI-асистента
- **PDF/Excel/CSV сервіси** — генерація звітів (реалізована на фронтенді, але бекенд надає дані)

**Бекенд працює як API для SPA** — всі HTML-роути повертають один і той самий HTML-файл (index.html), а JavaScript на фронтенді визначає, яку секцію показати на основі URL. API-ендпоінти повертають JSON-відповіді з даними для фронтенду, включаючи прогнози, історію, профілі користувачів, чати та статуси системи.

**Бекенд працює як ML inference engine** — завантажує навчені моделі машинного навчання з диску, обробляє вхідні дані користувачів, виконує прогнозування через scikit-learn pipelines, обчислює ймовірності ризиків, категорії ризику та топ фактори впливу, та повертає результати у структурованому форматі для відображення на фронтенді.

**Бекенд працює як інтерфейс до БД** — використовує SQLModel (ORM на основі SQLAlchemy) для роботи з SQLite базою даних, виконує CRUD операції (створення, читання, оновлення, видалення) для користувачів, прогнозів, чатів, повідомлень та інших сутностей, забезпечує транзакційність операцій та обробку помилок БД.

**Бекенд працює як middleware для auth та логів** — перевіряє JWT-токени для захищених ендпоінтів, обробляє автентифікацію через OAuth2PasswordBearer, логує помилки та важливі події (якщо налаштовано), нормалізує URL-шляхи, обробляє CORS для кросдоменних запитів та забезпечує безпеку через валідацію вхідних даних.

## Структура файлів бекенду

Бекенд організований у директорії `src/service/` з чітким розділенням відповідальності між модулями та файлами.

**`api.py`** — головний файл FastAPI додатку, який містить створення екземпляра FastAPI, налаштування middleware (CORS, нормалізація URL), монтування статичних файлів, HTML-роути для SPA, API-ендпоінти для прогнозування (`/predict`, `/explain`, `/metadata`), ендпоінти для статусів (`/health`, `/system/database/stats`), catch-all роут для обробки невідомих маршрутів та функцію `serve_frontend()` для повернення HTML-файлу. Файл також включає логіку обчислення ризиків, топ факторів та збереження історії прогнозів.

**`routers/`** — директорія з модульними роутерами для різних функціональних груп:
- **`assistant.py`** — роутер для AI-асистента (`/assistant/history`, `/assistant/chat`, `/assistant/health`), який інтегрується з Ollama для генерації відповідей на запити користувачів
- **`chats.py`** — роутер для чатів між користувачами (`/api/chats/*`), включаючи створення чатів, відправку повідомлень, блокування користувачів, управління непрочитаними повідомленнями

**`routes_auth.py`** — роутер для аутентифікації та управління користувачами, який включає ендпоінти для реєстрації (`/auth/register`), входу (`/auth/login`), оновлення профілю (`/users/me`), зміни пароля (`/auth/change-password`), відновлення пароля (`/auth/forgot-password`, `/auth/reset-password`), управління аватарами (`/users/me/avatar`), блокування користувачів (`/users/block`, `/users/unblock`), отримання історії прогнозів (`/users/history`) та статистики (`/users/history/stats`)

**`schemas.py`** — Pydantic-схеми для валідації вхідних та вихідних даних API, включаючи `PredictRequest`, `PredictResponse`, `FeatureImpact`, `ExplainResponse`, `MetadataResponse`, `UserRegisterRequest`, `UserLoginRequest`, `TokenResponse`, `UserProfileResponse`, `PredictionHistoryItem`, `ChatListItem`, `ChatDetailResponse`, `SendMessageRequest`, `CreateChatRequest` та інші схеми для всіх ендпоінтів

**`models.py`** — SQLModel-моделі для ORM, які визначають структуру таблиць бази даних, включаючи `User` (користувачі), `PredictionHistory` (історія прогнозів), `AssistantMessage` (повідомлення асистента), `Chat` (чати між користувачами), `ChatMessage` (повідомлення в чатах), `PasswordResetToken` (токени для відновлення пароля), `UserBlock` (блокування користувачів). Моделі включають relationships для зв'язків між таблицями та методи для роботи з даними

**`db.py`** — модуль для налаштування підключення до бази даних, який визначає `DATABASE_URL` для SQLite, створює SQLAlchemy engine, функції `init_db()` для створення таблиць, `get_session()` для отримання сесій БД, `session_scope()` для контекстних менеджерів транзакцій та `migrate_add_missing_columns()` для міграцій схеми БД

**`repositories.py`** — репозиторійний шар для абстракції роботи з БД, який містить функції для CRUD операцій: `get_user_by_email()`, `create_user()`, `save_history_entry()`, `get_all_prediction_history()`, `delete_prediction()`, `get_user_messages()`, `add_message()`, `delete_user_messages()`, `list_all_users()`, `get_or_create_chat()`, `get_chat_by_uuid()`, `get_user_chats()`, `get_chat_messages()`, `add_chat_message()`, `mark_messages_as_read()`, `get_unread_count()`, `block_user()`, `unblock_user()`, `is_user_blocked()`, `toggle_chat_pin()`, `reorder_chats()` та інші функції для роботи з даними

**`auth_utils.py`** — утиліти для аутентифікації, які включають функції `verify_password()` для перевірки паролів, `get_password_hash()` для хешування паролів через bcrypt, `create_access_token()` для генерації JWT-токенів, `decode_token()` для декодування токенів, `get_current_user()` для отримання поточного користувача з токена (опційна автентифікація), `require_current_user()` для обов'язкової автентифікації, налаштування `SECRET_KEY`, `ALGORITHM`, `ACCESS_TOKEN_EXPIRE_MINUTES` та `OAuth2PasswordBearer` схему

**`model_registry.py`** — реєстр моделей машинного навчання, який забезпечує завантаження та кешування моделей з диску, функції `load_champion()` для завантаження чемпіонських моделей (з пріоритетом каліброваних), `load_model()` для завантаження конкретних моделей за ключем, `get_feature_schema()` для отримання схеми ознак для валідації, `get_model_versions()` для отримання версій моделей, кешування моделей в пам'яті для швидкого доступу та мапінг ключів моделей до назв директорій

**`services/assistant_llm.py`** — сервіс інтеграції з Ollama, який включає функції `build_health_context()` для формування контексту про стан користувача на основі останнього прогнозу, `build_assistant_prompt()` для конструювання промпту для LLM з інструкціями та контекстом, `call_ollama()` для виклику локального Ollama сервера через HTTP-запити, налаштування `OLLAMA_URL` та `OLLAMA_MODEL`, обробку помилок та таймаутів

**`avatar_utils.py`** — утиліти для роботи з аватарами користувачів, які включають функції `save_avatar()` для збереження завантажених аватарів з оптимізацією зображень, `delete_avatar()` для видалення аватарів, `validate_image_file()` для валідації файлів зображень, `get_avatar_path()` та `get_avatar_url()` для роботи з шляхами, обмеження розміру файлів (5MB), підтримку форматів PNG/JPEG та оптимізацію зображень через Pillow

**`i18n.py`** — модуль інтернаціоналізації для бекенду, який забезпечує завантаження перекладів з JSON-файлів (`web/locales/uk.json`, `web/locales/en.json`), функцію `t()` для перекладу ключів з підтримкою інтерполяції змінних, функцію `get_accept_language()` для визначення мови з заголовка `Accept-Language`, кешування перекладів в пам'яті та fallback на українську мову

## ASGI / FastAPI архітектура

Бекенд працює на основі ASGI (Asynchronous Server Gateway Interface) протоколу, який забезпечує асинхронну обробку HTTP-запитів та підтримку WebSocket (якщо потрібно в майбутньому).

**Запуск сервісу** виконується через Uvicorn ASGI-сервер, який запускає FastAPI додаток на вказаному порту (зазвичай 8000). Uvicorn обробляє HTTP-запити, передає їх до FastAPI додатку через ASGI протокол та повертає відповіді клієнтам. Запуск може виконуватися через команду `uvicorn src.service.api:app --reload` для розробки або через `make run` для продакшену.

**ASGI lifecycle** включає події startup та shutdown, які обробляються через `lifespan` контекстний менеджер у FastAPI. При startup виконується ініціалізація бази даних через `init_db()`, яка створює всі таблиці, якщо вони не існують, та виконує міграції для додавання відсутніх колонок. При shutdown виконується очищення ресурсів (закриття з'єднань з БД, очищення кешів, якщо потрібно).

**Робота event loop** забезпечується через asyncio event loop, який обробляє асинхронні операції (async/await) у FastAPI. Event loop дозволяє обробляти кілька запитів одночасно без блокування, що підвищує продуктивність при великій кількості одночасних запитів. Асинхронні операції використовуються для роботи з БД (через SQLModel/SQLAlchemy), HTTP-запитів до Ollama (через `requests` або `httpx`), та інших I/O операцій.

**Інтеграція FastAPI з фронтендом** реалізована через HTML-роути, які завжди повертають один і той самий HTML-файл (`index.html`) незалежно від URL. Фронтенд (JavaScript) визначає, яку секцію показати на основі поточного URL. API-ендпоінти повертають JSON-відповіді з даними для фронтенду, включаючи прогнози, історію, профілі, чати та статуси.

**`serve_frontend()` логіка** — функція, яка повертає `FileResponse` з HTML-файлом `index.html` з директорії `web/`. Функція перевіряє існування файлу та викидає `HTTPException` зі статусом 404, якщо файл не знайдено. Функція використовується всіма HTML-роутами (`/`, `/app`, `/login`, `/register`, `/profile`, `/history`, `/diagrams`, `/assistant`, `/chats`, `/reports`, `/api-status`, `/about`).

**Маршрут `/api-status`** — HTML-роут для сторінки моніторингу стану системи, який повертає HTML-файл, але також має API-ендпоінти для отримання статусів (`/health`, `/system/database/stats`, `/assistant/health`). Фронтенд використовує ці API-ендпоінти для відображення статусів компонентів системи.

**HTML-маршрути** включають всі маршрути для SPA, які завжди повертають HTML-файл. Деякі маршрути (наприклад, `/`) перевіряють автентифікацію через `get_current_user()` та перенаправляють на `/login`, якщо користувач не залогінений. Інші маршрути (наприклад, `/login`, `/register`, `/about`) є публічними та не вимагають автентифікації.

**Middleware: CORS** — `CORSMiddleware` налаштований для дозволу кросдоменних запитів з будь-яких джерел (`allow_origins=["*"]`), підтримки credentials (`allow_credentials=True`), всіх HTTP-методів (`allow_methods=["*"]`) та всіх заголовків (`allow_headers=["*"]`). Це дозволяє фронтенду робити запити до API з будь-якого домену.

**Middleware: auth** — автентифікація реалізована через `Depends(get_current_user)` або `Depends(require_current_user)` у ендпоінтах, які вимагають автентифікації. Middleware не використовується для глобальної автентифікації, оскільки деякі ендпоінти публічні (наприклад, `/health`, `/auth/login`, `/auth/register`).

**Middleware: логування** — наразі глобальне логування не налаштоване, але помилки обробляються через try/catch у ендпоінтах та повертаються як `HTTPException` з відповідними статус-кодами. В майбутньому можна додати middleware для логування всіх запитів, помилок та важливих подій у зовнішню систему (наприклад, ELK stack, Sentry).

**Middleware: нормалізація URL** — `PathNormalizationMiddleware` нормалізує URL-шляхи, видаляючи подвійні та множинні слеші, видаляючи trailing slash (крім кореневого `/`), та робить 301 редірект на нормалізований URL, якщо path змінився. Це забезпечує консистентність URL та покращує SEO.

## Архітектура маршрутів (Routers)

Маршрути організовані через APIRouter для модульності та зручності підтримки. Кожен роутер відповідає за конкретну функціональну область.

**`auth_router`** (префікс `/auth`) — обробляє аутентифікацію та управління користувачами:
- `/auth/register` — реєстрація нового користувача з валідацією email, пароля та інших полів
- `/auth/login` — вхід користувача з перевіркою credentials та поверненням JWT-токена
- `/auth/refresh-token` — оновлення access токена (якщо реалізовано)
- `/auth/change-password` — зміна пароля для залогіненого користувача
- `/auth/forgot-password` — відправка токена для відновлення пароля на email
- `/auth/reset-password` — встановлення нового пароля через токен

**`users_router`** (префікс `/users`) — управління користувачами та профілями:
- `/users/me` — отримання профілю поточного користувача
- `/users/me` (PUT) — оновлення профілю користувача
- `/users/me/avatar` (POST) — завантаження аватару
- `/users/me/avatar` (DELETE) — видалення аватару
- `/users/block` — блокування користувача
- `/users/unblock` — розблокування користувача
- `/users/blocked` — список заблокованих користувачів
- `/users/history` — історія прогнозів користувача
- `/users/history/stats` — статистика історії прогнозів

**`prediction_router`** (в `api.py`) — прогнозування та робота з ML моделями:
- `/predict` — виконання прогнозування ризику на основі вхідних даних
- `/explain` — пояснення моделі через permutation importance
- `/metadata` — метадані моделей (версії, метрики, доступні цільові змінні)

**`reports_router`** — генерація звітів (реалізована на фронтенді, бекенд надає дані через `/users/history` та `/metadata`)

**`diagrams_router`** — передача даних для графіків (реалізована через `/users/history/stats` та `/metadata`)

**`chat_router`** (префікс `/api/chats`) — чати між користувачами:
- `/api/chats` (GET) — список чатів користувача
- `/api/chats` (POST) — створення нового чату
- `/api/chats/{chat_uuid}` (GET) — деталі чату
- `/api/chats/{chat_uuid}/messages` (POST) — відправка повідомлення
- `/api/chats/{chat_uuid}/read` (POST) — позначення повідомлень як прочитаних
- `/api/chats/{chat_uuid}` (DELETE) — видалення чату
- `/api/chats/{chat_uuid}/pin` (PATCH) — закріплення/відкріплення чату
- `/api/chats/reorder` (PATCH) — зміна порядку чатів
- `/api/chats/users` (GET) — список користувачів для створення чатів
- `/api/chats/unread-count` (GET) — кількість непрочитаних повідомлень

**`assistant_router`** (префікс `/assistant`) — AI-асистент:
- `/assistant/history` (GET) — історія повідомлень з асистентом
- `/assistant/chat` (POST) — відправка повідомлення асистенту та отримання відповіді
- `/assistant/history` (DELETE) — очищення історії повідомлень
- `/assistant/health` (GET) — перевірка статусу Ollama

**`status_router`** (в `api.py`) — статуси API, БД, Ollama:
- `/health` — статус API зі списком маршрутів
- `/system/database/stats` — статистика бази даних (кількість записів, розмір БД)

## Система аутентифікації

Система аутентифікації реалізована через JWT (JSON Web Tokens) з підтримкою access токенів та опційно refresh токенів.

**JWT токени (access/refresh)** — access токени містять email користувача (`sub`) та час закінчення (`exp`), підписуються секретним ключем (`SECRET_KEY`) через алгоритм HS256, мають термін дії 60 хвилин (налаштовується через `ACCESS_TOKEN_EXPIRE_MINUTES`). Refresh токени наразі не реалізовані, але можуть бути додані в майбутньому для продовження сесії без повторного входу.

**Де зберігаються токени** — токени зберігаються на клієнті (фронтенді) у LocalStorage під ключем `hr_auth_token`. Токени не зберігаються на сервері, що робить систему stateless та масштабованою. При кожному запиті токен передається в заголовку `Authorization: Bearer <token>`.

**Як працює `Depends(get_current_user)`** — функція `get_current_user()` використовується як dependency у FastAPI ендпоінтах через `Depends()`. Функція отримує токен з заголовка `Authorization` через `OAuth2PasswordBearer`, декодує токен через `decode_token()`, отримує email з токена, знаходить користувача в БД за email, перевіряє активність користувача (`is_active`) та повертає об'єкт `User` або `None` (якщо токен відсутній або некоректний). Якщо токен некоректний або користувач не знайдений, викидається `HTTPException` зі статусом 401.

**Логіка перевірки прав** — для обов'язкової автентифікації використовується `Depends(require_current_user)`, яка викликає `get_current_user()` та викидає `HTTPException` зі статусом 401, якщо користувач не автентифікований. Для опційної автентифікації використовується `Depends(get_current_user)`, яка повертає `None` для неавтентифікованих користувачів, дозволяючи ендпоінту вирішити, як обробити такий випадок.

**Як API повертає 401/403** — при помилці автентифікації (некоректний токен, прострочений токен, користувач не знайдений) викидається `HTTPException` зі статусом 401 та заголовком `WWW-Authenticate: Bearer`. При відсутності прав доступу (наприклад, спроба доступу до чужих даних, блокування користувача) викидається `HTTPException` зі статусом 403. Фронтенд обробляє ці помилки та перенаправляє на `/login` або показує повідомлення про помилку.

**Refresh-механізм** — наразі не реалізований, але може бути доданий через ендпоінт `/auth/refresh-token`, який приймає refresh токен, перевіряє його валідність, генерує новий access токен та повертає його клієнту. Refresh токени мають більший термін дії (наприклад, 7 днів) та зберігаються в БД для можливості відкликання.

## Взаємодія бекенду з ML-моделями

Бекенд інтегрується з навченими моделями машинного навчання для виконання прогнозування ризиків здоров'я.

**Де зберігаються моделі** — моделі зберігаються у директорії `artifacts/models/` з структурою `{target}/{model_name}/model.joblib` (наприклад, `artifacts/models/diabetes_present/XGBoost/model.joblib`). Чемпіонські моделі зберігаються як `{target}/champion.json` (метадані) та `{target}/champion_calibrated.joblib` (калібрована модель) або `{target}/{model_name}/model.joblib` (звичайна модель). Моделі зберігаються у форматі joblib (pickle-серіалізація scikit-learn pipelines).

**Як бекенд їх завантажує** — моделі завантажуються через `model_registry.py` функціями `load_champion()` (для чемпіонських моделей) або `load_model()` (для конкретних моделей за ключем). Моделі кешуються в пам'яті (`_MODEL_CACHE`, `_SPECIFIC_MODEL_CACHE`) для швидкого доступу без повторного завантаження з диску. При першому запиті модель завантажується з диску через `joblib.load()`, зберігається в кеші та повертається разом з метаданими (назва моделі, версія, метрики, чи калібрована).

**Як обчислюється прогноз** — при запиті на `/predict` бекенд отримує вхідні дані користувача (`PredictRequest`), валідує їх через Pydantic-схему, завантажує модель через `load_champion()` або `load_model()`, підготовлює дані для моделі (створює DataFrame з ознаками), виконує прогнозування через `pipeline.predict_proba()` для отримання ймовірності позитивного класу, обмежує ймовірність у діапазоні (0.0001, 0.9999) для стабільності, визначає категорію ризику через `get_risk_bucket()`, обчислює топ фактори через `calculate_top_factors_simple()`, формує відповідь (`PredictResponse`) та повертає її клієнту.

**Як обробляються інпути** — вхідні дані валідуються через Pydantic-схему `PredictRequest`, яка перевіряє наявність обов'язкових полів (`RIDAGEYR`, `RIAGENDR`, `BMXBMI`), тип даних (float, int), діапазони значень (наприклад, вік 0-120, ІМТ 10-60), опційні поля (`BPXSY1`, `BPXDI1`, `LBXGLU`, `LBXTC`). При помилках валідації повертається `HTTPException` зі статусом 400 та деталями помилок.

**Підготовка фічей** — вхідні дані конвертуються у pandas DataFrame з колонками, що відповідають назвам ознак моделі (`RIDAGEYR`, `RIAGENDR`, `BMXBMI`, `BPXSY1`, `BPXDI1`, `LBXGLU`, `LBXTC`). DataFrame передається в scikit-learn pipeline, який виконує попередню обробку (imputation, scaling, encoding) перед прогнозуванням. Pipeline включає всі кроки попередньої обробки, які були використані при навчанні моделі.

**Обробка відсутніх значень** — відсутні значення обробляються через `SimpleImputer` у pipeline, який замінює NaN на середнє значення (для числових ознак) або найчастіше значення (для категоріальних ознак). Якщо відсутні обов'язкові поля, валідація Pydantic викидає помилку до передачі даних у модель.

**Розрахунок ризиків** — ймовірність позитивного класу (0-1) конвертується у категорію ризику через `get_risk_bucket()`: низький ризик (<0.2), помірний ризик (0.2-0.5), високий ризик (>0.5). Категорії використовуються для відображення на фронтенді (кольорові індикатори, текстові мітки) та включення в PDF-звіти.

**Логіка FeatureImpact** — топ фактори обчислюються через `calculate_top_factors_simple()`, яка використовує нормалізовані абсолютні значення ознак як проксі для впливу на прогноз. Для кожної ознаки обчислюється нормалізоване значення (ділення на типовий діапазон), фактори сортуються за впливом (за спаданням) та повертаються топ-5 факторів. Фактори використовуються для відображення на фронтенді (діаграми, списки) та включення в PDF-звіти.

**Повернення результату фронтенду** — результат повертається як `PredictResponse` (Pydantic-схема), яка включає `target` (цільова змінна), `probability` (ймовірність), `risk_bucket` (категорія ризику), `model_name` (назва моделі), `version` (версія моделі), `is_calibrated` (чи калібрована), `top_factors` (список топ факторів), `note` (примітка про метод обчислення). Якщо користувач автентифікований, результат також зберігається в історії прогнозів через `save_history_entry()`.

## Робота з базою даних

Бекенд використовує SQLite як базу даних з SQLModel (ORM на основі SQLAlchemy) для роботи з даними.

**ORM** — SQLModel поєднує Pydantic (для валідації) та SQLAlchemy (для роботи з БД), дозволяючи визначати моделі, які використовуються і для валідації API, і для роботи з БД. Моделі визначаються через класи, що наслідуються від `SQLModel` з атрибутом `table=True`, поля визначаються через `Field()` з типами, обмеженнями та індексами.

**Структура бази даних** — SQLite база даних зберігається у файлі `data/app.db` з наступними таблицями:
- `user` — користувачі системи
- `predictionhistory` — історія прогнозів
- `assistantmessage` — повідомлення AI-асистента
- `chat` — чати між користувачами
- `chatmessage` — повідомлення в чатах
- `passwordresettoken` — токени для відновлення пароля
- `userblock` — блокування користувачів

**Таблиця `user`** містить поля: `id` (primary key), `email` (унікальний, індексований), `hashed_password`, `display_name`, `first_name`, `last_name`, `date_of_birth`, `gender`, `avatar_url`, `avatar_type`, `avatar_color`, `is_active`, `created_at`, `updated_at`. Таблиця має relationship до `PredictionHistory`, `AssistantMessage`, `Chat` (через `user1_id` та `user2_id`), `ChatMessage`, `PasswordResetToken`, `UserBlock`.

**Таблиця `predictionhistory`** містить поля: `id` (primary key), `user_id` (foreign key до `user.id`, індексований), `target` (цільова змінна), `model_name`, `probability`, `risk_bucket`, `inputs` (JSON з вхідними даними та топ факторами), `created_at`. Таблиця має relationship до `User` та `AssistantMessage` (через `prediction_id`).

**Таблиця `chat`** містить поля: `id` (primary key), `uuid` (унікальний, індексований), `user1_id` (foreign key до `user.id`), `user2_id` (foreign key до `user.id`), `created_at`, `updated_at`, `is_pinned`, `order`. Таблиця має relationship до `ChatMessage`.

**Таблиця `chatmessage`** містить поля: `id` (primary key), `chat_id` (foreign key до `chat.id`, індексований), `sender_id` (foreign key до `user.id`), `content` (текст повідомлення), `created_at`, `read_at` (час прочитання). Таблиця має relationships до `Chat` та `User` (sender).

**Як створюються записи** — записи створюються через SQLModel-моделі: створюється екземпляр моделі з даними, додається до сесії через `session.add()`, виконується commit через `session.commit()`, оновлюється об'єкт через `session.refresh()` для отримання згенерованих полів (наприклад, `id`). Транзакції забезпечують атомарність операцій: при помилці виконується rollback через `session.rollback()`.

**Як читаються дані** — дані читаються через SQLModel queries: `select(Model).where(...)` для фільтрації, `.order_by(...)` для сортування, `.limit(...)` для обмеження кількості, `.options(selectinload(...))` для eager loading relationships. Виконання запиту через `session.exec(statement)` повертає результат, який можна перетворити у список через `list()` або отримати перший елемент через `.first()`.

**Як працює pooling** — SQLite не підтримує connection pooling у традиційному розумінні (як PostgreSQL), але SQLAlchemy engine може використовувати пул з'єднань для оптимізації. Налаштування `connect_args={"check_same_thread": False}` дозволяє використовувати одне з'єднання з різних потоків (для ASGI це важливо). Кожна сесія використовує з'єднання з пулу, повертає його після закриття сесії.

**Як обробляються помилки** — помилки БД обробляються через try/catch у репозиторіях та ендпоінтах: `IntegrityError` для помилок унікальності (наприклад, дублювання email), `SQLAlchemyError` для загальних помилок БД, `Exception` для неочікуваних помилок. При помилках виконується rollback транзакції через `session.rollback()`, повертається `HTTPException` з відповідним статус-кодом (400 для валідації, 409 для конфліктів, 500 для серверних помилок).

## Обробка історії прогнозів

Історія прогнозів зберігається в БД для відображення на фронтенді, аналізу та використання в AI-асистенті.

**Зберігання прогнозів** — при успішному прогнозуванні (якщо користувач автентифікований) результат зберігається в таблиці `predictionhistory` через `save_history_entry()` у `repositories.py`. Функція створює новий запис `PredictionHistory` з полями `user_id`, `target`, `model_name`, `probability`, `risk_bucket`, `inputs` (JSON з вхідними даними та топ факторами), `created_at` (поточна дата/час).

**Структура записів** — кожен запис містить унікальний `id`, зв'язок з користувачем через `user_id`, цільову змінну (`diabetes_present` або `obesity_present`), назву моделі, ймовірність (0-1), категорію ризику (`low`, `medium`, `high`), JSON з вхідними даними (всі ознаки, топ фактори, метадані) та timestamp створення.

**Як будується історія** — історія отримується через `get_all_prediction_history()` у `repositories.py`, яка виконує SQL-запит `select(PredictionHistory).where(PredictionHistory.user_id == user_id).order_by(PredictionHistory.created_at.desc())` для отримання всіх прогнозів користувача, відсортованих за датою (найновіші спочатку). Результат конвертується у список та повертається ендпоінту.

**Як фронт отримує дані** — фронтенд робить GET-запит на `/users/history`, який викликає `get_all_prediction_history()` та повертає список `PredictionHistoryItem` (Pydantic-схеми) з полями `id`, `target`, `model_name`, `probability`, `risk_bucket`, `inputs`, `created_at`. Фронтенд відображає історію у вигляді списку або сітки з можливістю фільтрації, сортування та видалення записів.

**Як працює фільтрація** — фільтрація може виконуватися на рівні БД через додавання умов до SQL-запиту (наприклад, фільтр за `target`, `risk_bucket`, діапазон дат) або на рівні фронтенду через JavaScript. Наразі фільтрація реалізована на фронтенді для швидкості та зручності, але може бути перенесена на бекенд для великих обсягів даних.

## API статуси (API-Status System)

Система моніторингу стану компонентів системи для відображення на сторінці `/api-status`.

**Як бекенд перевіряє статус API** — ендпоінт `/health` виконує базову перевірку стану API: отримує список маршрутів з `app.routes`, повертає JSON з полями `status` ("ok"), `message`, `version`, `timestamp`, `routes` (список маршрутів), `total_routes` (загальна кількість). Ендпоінт не вимагає автентифікації та використовується для моніторингу доступності API.

**Як перевіряється база даних** — ендпоінт `/system/database/stats` виконує SQL-запити для отримання статистики БД: підраховує кількість записів у кожній таблиці через `func.count()`, обчислює розмір БД через SQL-запит до SQLite метаданих, отримує активність (останні записи, найновіші користувачі, останні прогнози). Результат повертається як JSON з полями `users_count`, `predictions_count`, `chats_count`, `messages_count`, `assistant_messages_count`, `database_size_bytes`, `last_activity` (timestamp останньої активності).

**Як перевіряється Ollama** — ендпоінт `/assistant/health` виконує HTTP-запит до локального Ollama сервера (`http://localhost:11434/api/generate`) з тестовим промптом ("ok"), вимірює латентність (час відповіді), перевіряє наявність поля `response` у відповіді. Результат повертається як JSON з полями `status` ("online", "offline", "timeout", "error"), `is_available` (boolean), `latency_ms` (мілісекунди), `error` (текст помилки, якщо є), `timestamp`. Обробляються помилки: `Timeout` (таймаут 10 секунд), `ConnectionError` (Ollama не запущений), інші помилки.

**Що повертається фронту** — всі ендпоінти статусів повертають JSON з полями `status`, `is_available` (для Ollama), `timestamp`, додатковими полями залежно від типу статусу. Фронтенд використовує ці дані для відображення індикаторів стану (онлайн/офлайн), графіків латентності, детальної статистики та повідомлень про помилки.

**Як це використовується в UI** — фронтенд робить періодичні запити (кожні 10 секунд) до всіх ендпоінтів статусів, зберігає історію статусів для побудови графіків, відображає індикатори стану (зелений/червоний/жовтий) для кожного компонента, показує детальну статистику на сторінці `/api-status` та оновлює UI при зміні статусів.

## Chat API

API для чатів між користувачами з підтримкою повідомлень, блокування та управління чатами.

**Створення чату** — ендпоінт `POST /api/chats` приймає `CreateChatRequest` з `user_id` іншого користувача, перевіряє, чи користувач не намагається створити чат з самим собою, перевіряє активність обох користувачів, перевіряє блокування (чи не заблоковані користувачі один одним), викликає `get_or_create_chat()` для отримання існуючого чату або створення нового, повертає `ChatDetailResponse` з деталями чату, повідомленнями та кількістю непрочитаних.

**Отримання чатів** — ендпоінт `GET /api/chats` викликає `get_user_chats()` для отримання всіх чатів користувача, які мають хоча б одне повідомлення, виключає чати з заблокованими користувачами, сортує чати (спочатку закріплені за `order`, потім незакріплені за `updated_at`), для кожного чату визначає іншого користувача, отримує останнє повідомлення, підраховує непрочитані повідомлення, повертає список `ChatListItem` з деталями чатів.

**Повідомлення** — ендпоінт `POST /api/chats/{chat_uuid}/messages` приймає `SendMessageRequest` з `content`, перевіряє доступ до чату, перевіряє блокування, викликає `add_chat_message()` для збереження повідомлення в БД, оновлює `updated_at` чату, повертає `ChatMessageItem` з деталями повідомлення. Ендпоінт `GET /api/chats/{chat_uuid}` повертає всі повідомлення чату через `get_chat_messages()`.

**Блокування/розблокування** — ендпоінти `/users/block` та `/users/unblock` викликають `block_user()` та `unblock_user()` у `repositories.py` для створення/видалення записів у таблиці `userblock`. Блокування перевіряється при створенні чатів, відправці повідомлень та отриманні списку користувачів. Заблоковані користувачі не можуть створювати чати, відправляти повідомлення та бачитися в активних чатах.

**Unread-логіка** — непрочитані повідомлення визначаються через поле `read_at` у таблиці `chatmessage`: якщо `read_at` є `None` та `sender_id != current_user.id`, повідомлення вважається непрочитаним. Ендпоінт `GET /api/chats/unread-count` викликає `get_unread_count()` для підрахунку всіх непрочитаних повідомлень користувача. Ендпоінт `POST /api/chats/{chat_uuid}/read` викликає `mark_messages_as_read()` для позначення всіх непрочитаних повідомлень в чаті як прочитаних (встановлює `read_at` на поточний час).

**Оновлення статусів** — при відправці повідомлення оновлюється `updated_at` чату через `chat.touch()`, що впливає на сортування чатів (найновіші спочатку). При закріпленні/відкріпленні чату оновлюється `is_pinned` та `order` через `toggle_chat_pin()`. При зміні порядку чатів оновлюється `order` для всіх чатів через `reorder_chats()`.

## AI-Assistant API (Ollama)

API для інтеграції з локальним Ollama сервером для AI-асистента здоров'я.

**Як бекенд відправляє запит до Ollama** — ендпоінт `POST /assistant/chat` отримує повідомлення користувача, опційний `prediction_id` для контексту, мову (`uk` або `en`), зберігає повідомлення користувача в БД через `add_message()`, викликає `build_health_context()` для формування контексту про стан користувача на основі останнього або вибраного прогнозу, викликає `build_assistant_prompt()` для конструювання промпту з інструкціями та контекстом, викликає `call_ollama()` для відправки HTTP POST-запиту до `http://localhost:11434/api/generate` з JSON payload (`model`, `prompt`, `stream: false`), отримує відповідь від Ollama, зберігає відповідь асистента в БД через `add_message()`, повертає відповідь клієнту.

**Як відбувається стрімінг** — наразі стрімінг не використовується (`stream: false`), що означає, що Ollama повертає повну відповідь одним JSON-об'єктом. В майбутньому можна додати стрімінг через `stream: true` для отримання відповіді частинами (NDJSON формат) та передачі їх клієнту через Server-Sent Events (SSE) або WebSocket для відображення відповіді в реальному часі.

**Як обробляються помилки моделі** — помилки обробляються через try/catch у `call_ollama()`: `requests.RequestException` для помилок HTTP (ConnectionError, Timeout), обробка порожніх відповідей, обробка некоректного JSON. При помилках повертається дружнє повідомлення українською мовою замість технічної помилки. Помилки логуються (якщо налаштовано) для діагностики.

**Таймаути** — HTTP-запит до Ollama має таймаут 60 секунд (налаштовується в `call_ollama()`). При перевищенні таймауту викидається `requests.exceptions.Timeout`, який обробляється та повертається як повідомлення про помилку. Таймаут забезпечує, що запит не зависає назавжди при проблемах з Ollama.

**Контроль черги** — наразі контроль черги не реалізований, що означає, що всі запити обробляються одночасно. В майбутньому можна додати чергу (наприклад, через Celery або Redis) для обмеження кількості одночасних запитів до Ollama, пріоритизації запитів та обробки черги в фоновому режимі.

## Error handling

Обробка помилок у бекенді реалізована через try/catch у ендпоінтах та повернення структурованих JSON-відповідей.

**Глобальний обробник помилок** — наразі глобальний обробник помилок не налаштований, але можна додати через `@app.exception_handler()` для обробки всіх необроблених винятків, логування помилок у зовнішню систему (наприклад, Sentry), повернення уніфікованих JSON-відповідей з помилками та додавання трейсів для діагностики.

**Формування JSON-відповідей** — помилки повертаються через `HTTPException` з полями `status_code` (400, 401, 403, 404, 409, 422, 500) та `detail` (текст помилки). FastAPI автоматично конвертує `HTTPException` у JSON-відповідь з полями `detail` та опційними полями (наприклад, `errors` для валідації). Pydantic валідація автоматично повертає детальні помилки для кожного поля у форматі JSON.

**Статус-коди** — використовуються стандартні HTTP статус-коди: 200 (OK), 201 (Created), 204 (No Content), 400 (Bad Request — валідація), 401 (Unauthorized — неавтентифікований), 403 (Forbidden — немає прав), 404 (Not Found — ресурс не знайдено), 409 (Conflict — конфлікт, наприклад, дублювання email), 422 (Unprocessable Entity — помилка валідації Pydantic), 500 (Internal Server Error — серверна помилка).

**Користувацькі помилки** — помилки формулюються українською мовою (або англійською, залежно від `Accept-Language`) через модуль `i18n.py` для зручності користувачів. Помилки включають детальну інформацію про причину (наприклад, "Email вже використовується", "Невірний пароль", "Модель не знайдено") та рекомендації для вирішення (якщо можливо).

## Безпека

Безпека бекенду забезпечується через валідацію, автентифікацію, хешування паролів та контроль доступу.

**Контроль CORS** — CORS налаштований через `CORSMiddleware` з дозволом всіх джерел (`allow_origins=["*"]`) для розробки. Для продакшену слід обмежити джерела конкретними доменами (наприклад, `allow_origins=["https://healthrisk.ai"]`) для запобігання CSRF атак. `allow_credentials=True` дозволяє передачу cookies та Authorization headers.

**Rate-limits** — наразі rate-limiting не реалізований, але можна додати через middleware (наприклад, `slowapi`) для обмеження кількості запитів з одного IP адреси за одиницю часу (наприклад, 100 запитів на хвилину) для запобігання DDoS атак та зловживань.

**JWT безпечність** — JWT токени підписуються секретним ключем (`SECRET_KEY`), який має бути змінено на випадковий рядок у продакшені (зараз використовується `"change_this_secret_to_env_variable"`). Токени мають термін дії (60 хвилин), що обмежує час дії при компрометації. Токени не зберігаються на сервері, що робить систему stateless, але також означає, що токени не можуть бути відкликані до закінчення терміну дії.

**Хешування паролів** — паролі хешуються через bcrypt з автоматичною генерацією salt, що забезпечує унікальність хешів навіть для однакових паролів. Bcrypt має обмеження 72 байти для пароля, тому паролі обмежуються до 72 байтів перед хешуванням. Хеші зберігаються в БД, а оригінальні паролі ніколи не зберігаються.

**Валідація інпутів** — всі вхідні дані валідуються через Pydantic-схеми, які перевіряють типи, діапазони, обов'язковість полів, формати (наприклад, email), унікальність (для email). Валідація виконується автоматично FastAPI перед виконанням ендпоінту, що запобігає обробці некоректних даних та SQL injection через ORM.

**Захист від SQL injection** — SQL injection запобігається через використання ORM (SQLModel/SQLAlchemy), який автоматично екранує параметри запитів. Прямі SQL-запити (якщо використовуються) виконуються через параметризовані запити (`text()` з параметрами), а не через конкатенацію рядків.

**Захист від XSS** — XSS запобігається через автоматичне екранування HTML у JSON-відповідях FastAPI та валідацію вхідних даних. Фронтенд також виконує екранування при відображенні даних користувачів.

**Захист від CSRF** — CSRF запобігається через використання JWT токенів у заголовку `Authorization`, які не передаються автоматично браузером (на відміну від cookies). CORS також допомагає запобігти CSRF через перевірку джерела запиту.

## Майбутні покращення

Бекенд має потенціал для покращень у різних напрямках для підвищення продуктивності, масштабованості та функціональності.

**Кешування моделей** — моделі вже кешуються в пам'яті, але можна додати кешування на рівні Redis для розподіленого кешування між кількома інстансами бекенду, TTL для кешу (автоматичне оновлення при зміні моделей), кешування метаданих моделей та статистики для швидкого доступу.

**Асинхронні черги** — можна додати черги (наприклад, через Celery або RQ) для асинхронної обробки довгих операцій (генерація PDF, обробка великих обсягів даних, інтеграція з зовнішніми сервісами), що дозволить швидше відповідати клієнтам та обробляти операції в фоновому режимі.

**Розділення API на мікросервіси** — можна розділити монолітний бекенд на мікросервіси: auth-сервіс (аутентифікація, користувачі), ML-сервіс (прогнозування, моделі), chat-сервіс (чати, повідомлення), assistant-сервіс (Ollama інтеграція), що дозволить масштабувати кожен сервіс незалежно та використовувати різні технології для різних сервісів.

**Розділення ML inference в окремий сервіс** — можна винести ML inference в окремий сервіс (наприклад, через TensorFlow Serving, TorchServe або власний gRPC сервіс) для оптимізації продуктивності, використання GPU для інференсу, масштабування інференсу незалежно від API та кешування результатів прогнозування.

**Логування у зовнішню систему** — можна додати інтеграцію з системами логування (наприклад, ELK stack, Splunk, CloudWatch) для централізованого збору логів, моніторингу помилок, аналізу продуктивності та алертів при критичних помилках.

**S3 або cloud для зберігання PDF** — зараз PDF генеруються на фронтенді, але можна додати генерацію PDF на бекенді з збереженням у S3 або іншому cloud storage для швидкого доступу, резервного копіювання та можливості відправки PDF на email.

**Покращення безпеки** — можна додати rate-limiting для захисту від DDoS, 2FA (двофакторна автентифікація) для підвищення безпеки, refresh токени для продовження сесій, відкликання токенів через blacklist, шифрування чутливих даних у БД, аудит логів для відстеження доступу до даних.

**Покращення продуктивності** — можна додати connection pooling для БД (якщо перейти на PostgreSQL), кешування запитів до БД через Redis, індексацію БД для швидших запитів, пагінацію для великих списків, lazy loading для relationships, оптимізацію SQL-запитів через explain plans.

**Покращення моніторингу** — можна додати метрики (наприклад, через Prometheus) для відстеження продуктивності, латентності, кількості запитів, помилок, використання ресурсів (CPU, пам'ять, диск), інтеграцію з системами моніторингу (наприклад, Grafana, Datadog) для візуалізації метрик та налаштування алертів.


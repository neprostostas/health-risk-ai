# Технологічний стек проєкту HealthRisk.AI

Проєкт HealthRisk.AI складається з бекенду (API та сервіси), фронтенду (веб-інтерфейс), ML-частини (моделі машинного навчання), бази даних (SQLite) та інструментів для тестування та розробки. Нижче наведено детальний опис технологічного стеку, організований по шарах та призначенню.

## Backend

### FastAPI

FastAPI використовується як основний веб-фреймворк для реалізації REST API. Через нього фронтенд отримує прогнози ризиків, історію прогнозування, автентифікацію користувачів, чати з AI-асистентом та інші сервіси. FastAPI забезпечує автоматичну генерацію OpenAPI-документації, валідацію даних через Pydantic та підтримку асинхронних операцій.

### Uvicorn

Uvicorn — ASGI-сервер, який використовується для запуску FastAPI-додатку. Він обслуговує HTTP-запити, обробляє WebSocket-з'єднання (якщо потрібно) та забезпечує високу продуктивність завдяки асинхронній архітектурі.

### Starlette

Starlette використовується безпосередньо в middleware для обробки запитів та відповідей. Він є базовим компонентом FastAPI та дозволяє створювати кастомні middleware для CORS, обробки помилок та інших перехоплень запитів.

### SQLModel та SQLAlchemy

SQLModel — ORM (Object-Relational Mapping), який поєднує можливості Pydantic для валідації даних та SQLAlchemy для роботи з базою даних. Використовується для визначення моделей даних (користувачі, історія прогнозів, чати), створення таблиць та виконання запитів до бази даних. SQLAlchemy забезпечує низькорівневу роботу з БД, включаючи міграції та інспекцію схем.

### SQLite

SQLite використовується як основна база даних проєкту. Файл бази даних зберігається у `data/app.db` та містить таблиці користувачів, історії прогнозів, чатів та інших даних. SQLite обрано через простоту розгортання, відсутність необхідності в окремому сервері БД та достатню продуктивність для середнього навантаження.

### Pydantic

Pydantic використовується для валідації та серіалізації даних у всьому бекенді. Всі схеми запитів та відповідей API (PredictRequest, PredictResponse, ExplainResponse тощо) визначені через Pydantic-моделі, що забезпечує автоматичну валідацію типів та значень на рівні API.

### JWT (JSON Web Tokens)

JWT-токени реалізовані через бібліотеку `python-jose` та використовуються для автентифікації користувачів. Після успішного входу користувач отримує JWT-токен, який зберігається у localStorage фронтенду та передається в заголовку `Authorization` при кожному запиті до API.

### OAuth2PasswordBearer

OAuth2PasswordBearer — компонент FastAPI, який використовується для автоматичного витягування JWT-токенів з заголовків запитів та їх валідації. Забезпечує стандартизовану схему автентифікації через Bearer токени.

### Bcrypt та Passlib

Bcrypt та Passlib використовуються для хешування паролів користувачів. Паролі ніколи не зберігаються у відкритому вигляді — замість цього зберігається bcrypt-хеш, що забезпечує безпеку навіть у разі компрометації бази даних.

### Pillow (PIL)

Pillow використовується для обробки зображень аватарів користувачів. Дозволяє змінювати розмір, форматувати та зберігати згенеровані аватари у потрібному форматі.

### Requests

Бібліотека `requests` використовується для HTTP-запитів до локального Ollama API. Через неї бекенд звертається до LLM-моделі для генерації відповідей у чаті з AI-асистентом.

### Python-multipart

Python-multipart використовується для обробки multipart/form-data запитів, зокрема для завантаження файлів (аватари користувачів).

## Frontend

### Vanilla JavaScript

Фронтенд реалізований на чистому JavaScript без використання фреймворків (React, Vue тощо). Весь код знаходиться у файлі `src/service/web/app.js` (приблизно 14667 рядків) та реалізує SPA (Single Page Application) з клієнтським роутингом.

### Chart.js

Chart.js використовується для побудови інтерактивних діаграм та графіків. Бібліотека завантажується через CDN та використовується на сторінці `/diagrams` для відображення аналітики датасету (розподіли ІМТ, холестерину, кореляційна матриця тощо), а також для візуалізації історії прогнозів користувача та експорту графіків у PDF-звіти.

### jsPDF

jsPDF використовується для генерації PDF-звітів з прогнозами ризиків. Бібліотека дозволяє створювати PDF-документи з текстом, графіками (експортованими з Chart.js), таблицями та форматуванням. PDF-звіти включають інформацію про прогноз, фактори ризику, графіки та рекомендації.

### xlsx-js-style

xlsx-js-style використовується для експорту даних у формат Excel. Дозволяє створювати структуровані таблиці з форматуванням для зручного аналізу історії прогнозів.

### Navigo

Navigo — легкий JavaScript-роутер для SPA, який використовується для клієнтського роутингу. Забезпечує навігацію між сторінками без перезавантаження сторінки (SPA-навігація).

### Lucide

Lucide — бібліотека іконок, яка використовується для візуального оформлення інтерфейсу. Іконки завантажуються через CDN та використовуються у навігації, кнопках, індикаторах статусу та інших UI-елементах. Також інтегровані у PDF-звіти для візуального оформлення.

### Власний i18n модуль

Проєкт містить власну реалізацію інтернаціоналізації у файлі `src/service/web/i18n.js`. Модуль завантажує переклади з JSON-файлів (`locales/uk.json`, `locales/en.json`) та забезпечує підтримку української та англійської мов. Використовується для локалізації всіх текстів у веб-інтерфейсі.

### CSS

Стилі реалізовані у файлі `src/service/web/app.css` без використання CSS-фреймворків (Bootstrap, Tailwind тощо). Використовується кастомна система дизайну з підтримкою темної та світлої теми.

## ML та аналіз даних

### Pandas

Pandas використовується для роботи з датафреймами на всіх етапах проєкту: завантаження сирих NHANES-даних, обробка та очищення під час ETL, аналіз розподілів та кореляцій під час EDA, підготовка даних для навчання моделей та обробка результатів прогнозування у API.

### NumPy

NumPy використовується для математичних обчислень: обчислення регресійних ліній на графіках, робота з масивами ймовірностей, обчислення метрик та інші числові операції.

### Scikit-learn

Scikit-learn — основна бібліотека для машинного навчання у проєкті. Використовується для:
- Навчання моделей (LogisticRegression, RandomForest, SVC, KNN, MLP)
- Попередньої обробки даних (StandardScaler, SimpleImputer, OneHotEncoder)
- Обчислення метрик (ROC-AUC, Precision-Recall, F1-score, Brier Score)
- Калібрування моделей (CalibratedClassifierCV)
- Обчислення важливості ознак (permutation_importance)
- Розділення даних на тренувальну та тестову вибірки

### XGBoost

XGBoost використовується як одна з моделей машинного навчання для прогнозування ризиків. Це градієнтний бустинг-алгоритм, який часто показує високу продуктивність на структурованих даних.

### Joblib

Joblib використовується для збереження та завантаження навчених моделей. Всі моделі зберігаються у форматі `.joblib` у директорії `artifacts/models/` та завантажуються під час інференсу через API.

### Matplotlib та Seaborn

Matplotlib та Seaborn використовуються для побудови графіків під час EDA та навчання моделей. Створюються гістограми, боксплоти, діаграми розсіювання, ROC-криві, Precision-Recall криві, криві калібрування та теплокарти кореляцій. Всі графіки зберігаються у форматі PNG у директоріях `artifacts/eda/` та `artifacts/models/`.

### PyYAML

PyYAML використовується для завантаження конфігураційних файлів. Конфігурація ETL зберігається у `configs/nhanes.yaml` та містить налаштування шляхів до даних, списку ознак та правил формування цільових змінних.

## База даних та сховище

### SQLite

SQLite використовується як основна база даних проєкту. Файл бази даних знаходиться за шляхом `data/app.db` та містить наступні таблиці:

- **user** — користувачі системи (email, хеш пароля, профіль, аватар)
- **predictionhistory** — історія прогнозів користувачів (цільова змінна, модель, ймовірність, категорія ризику, вхідні параметри)
- **chat** — чати користувачів з AI-асистентом
- **message** — повідомлення у чатах

### SQLModel ORM

SQLModel використовується як ORM для роботи з базою даних. Моделі визначені у `src/service/models.py` та включають зв'язки між таблицями (relationships). Репозиторії у `src/service/repositories.py` інкапсулюють логіку роботи з БД.

### Міграції

Міграції бази даних виконуються програмно через функцію `migrate_add_missing_columns()` у `src/service/db.py`, яка додає відсутні колонки до існуючих таблиць при старті додатку.

## Інфраструктура та інструменти розробки

### Makefile

Makefile — це система автоматизації збірки та виконання команд, яка використовується для спрощення роботи з проєктом. У проєкті Makefile містить наступні основні команди:

- **`make run`** — запуск API/веб-сервера
- **`make install`** — встановлення Python-залежностей
- **`make db-shell`** — відкриття SQLite shell для роботи з базою даних
- **`make clean`** — видалення кешових файлів та артефактів збірки
- **`make ollama`** — запуск локального Ollama сервера
- **`make ollama-pull`** — завантаження моделі llama3 для Ollama
- **`make dev`** — запуск Ollama та API разом у режимі розробки
- **`make test`** — запуск всіх тестів
- **`make test-backend`**, **`make test-ml`**, **`make test-frontend`** — запуск тестів для конкретних компонентів
- **`make test-coverage`** — запуск тестів з генерацією звіту про покриття коду

Makefile спрощує роботу з проєктом, дозволяючи виконувати складні послідовності команд однією командою.

### Pytest

Pytest — основний фреймворк для автоматизованих тестів у проєкті. Використовується для тестування бекенду, ML-моделей та фронтенду. Конфігурація знаходиться у `pytest.ini` та включає налаштування маркерів (unit, integration, e2e, ml, experimental), асинхронних тестів та виводу результатів.

### Pytest-asyncio

Pytest-asyncio забезпечує підтримку асинхронних тестів для FastAPI endpoints. Дозволяє тестувати асинхронні функції та коректно обробляти async/await у тестах.

### Pytest-cov

Pytest-cov використовується для вимірювання покриття коду тестами. Генерує звіти у форматі HTML (у директорії `htmlcov/`) та терміналу, що дозволяє оцінити якість тестового покриття.

### Httpx

Httpx використовується як HTTP-клієнт для тестування FastAPI endpoints. Дозволяє робити HTTP-запити до API під час тестів та перевіряти відповіді.

### Pyright

Pyright — статичний аналізатор типів для Python, конфігурація якого знаходиться у `pyrightconfig.json`. Використовується для перевірки типів у коді та виявлення потенційних помилок на етапі розробки.

### Typer

Typer використовується для створення CLI-інтерфейсу проєкту. Через нього реалізовані команди у `scripts/cli.py`, зокрема команда `data` для запуску ETL-процесу.

## AI-асистент та Ollama

### Ollama

Ollama — локальний сервер для запуску великих мовних моделей (LLM), який використовується для реалізації AI-асистента здоров'я у проєкті. Ollama працює на `http://localhost:11434` та обслуговує модель `llama3`.

### Інтеграція з Ollama

Інтеграція з Ollama реалізована у модулі `src/service/services/assistant_llm.py`. Бекенд звертається до Ollama через HTTP POST-запити до `/api/generate` з використанням бібліотеки `requests`. 

**Функціональність:**
- **`build_health_context()`** — формує короткий контекст про останній прогноз ризику користувача (цільова змінна, ймовірність, категорія ризику, ключові фактори)
- **`build_assistant_prompt()`** — конструює повний промпт для LLM з інструкціями (асистент не ставить діагнозів, не призначає лікування) та контекстом користувача
- **`call_ollama()`** — виконує HTTP-запит до Ollama API та повертає текст відповіді від LLM

**Використання:**
AI-асистент доступний через endpoint `/assistant/chat` та використовується у веб-інтерфейсі на сторінці `/assistant`. Користувачі можуть задавати питання про свої прогнози ризиків, а асистент надає персоналізовані рекомендації та пояснення простими словами українською мовою.

**Статус Ollama:**
Веб-інтерфейс містить сторінку моніторингу статусу Ollama (`/api-status`), яка відображає доступність сервера, латентність запитів та графік часу відгуку.

## Підсумок

Технологічний стек проєкту HealthRisk.AI підібраний так, щоб поєднати ML-компоненти (навчання та інференс моделей), веб-інтерфейс (SPA з інтерактивними діаграмами) та API (REST endpoints для прогнозування та управління даними). Використання сучасних інструментів (FastAPI, SQLModel, scikit-learn) забезпечує швидку розробку та підтримку, а інтеграція з Ollama додає інтелектуальний шар для пояснення результатів користувачам.

Інфраструктура включає інструменти для тестування (pytest), моніторингу покриття коду (pytest-cov) та автоматизації (Makefile), що забезпечує якість коду та спрощує процес розробки. Повна технічна архітектура проєкту, включаючи детальний опис взаємодії компонентів, буде описана в окремому документі ARCHITECTURE.


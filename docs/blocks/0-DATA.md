# Дані та підготовка датасету (NHANES → health_dataset.csv)

У цьому проєкті використовується офіційний медичний датасет NHANES (National Health and Nutrition Examination Survey), який доступний на платформі Kaggle. З цього датасету формується власний узгоджений датасет `health_dataset.csv`, який використовується для подальшого аналізу, тренування моделей машинного навчання та інференсу (прогнозування ризиків здоров'я).

## Джерело даних: NHANES (National Health and Nutrition Examination Survey)

**Посилання на датасет:** https://www.kaggle.com/datasets/cdc/national-health-and-nutrition-examination-survey

NHANES — це репрезентативне дослідження стану здоров'я та харчування населення США, яке проводиться Центром контролю та профілактики захворювань (CDC). Це дослідження включає комплексні медичні вимірювання, лабораторні аналізи, антропометричні дані та опитувальники, що охоплюють широкий спектр показників здоров'я.

У цьому проєкті використовуються наступні компоненти NHANES, які зберігаються у вигляді окремих CSV-файлів у директорії `datasets/raw/`:

- **demographic.csv** — демографічні дані (вік, стать, раса/етнічність)
- **examination.csv** — дані фізичного обстеження (антропометрія, артеріальний тиск)
- **labs.csv** — лабораторні показники (глюкоза, холестерин та інші біохімічні маркери)
- **questionnaire.csv** — дані з опитувальників (статус діабету, медична історія)
- **diet.csv** — дані про харчування
- **medications.csv** — дані про прийом ліків

Всі таблиці об'єднуються за унікальним ідентифікатором респондента `SEQN` (Sequence Number).

## Цільовий датасет проєкту: health_dataset.csv

**Розташування:** `datasets/processed/health_dataset.csv`

Це об'єднаний, очищений і підготовлений датасет, який є результатом ETL-процесу з сирих NHANES-таблиць. Він використовується для:

- дослідницького аналізу даних (EDA)
- тренування моделей машинного навчання для прогнозування ризиків
- інференсу (реального прогнозування ризиків здоров'я через веб-інтерфейс та API)

### Основні групи змінних

Датасет містить наступні ключові групи змінних:

**Демографія:**
- `SEQN` — унікальний ідентифікатор респондента
- `RIDAGEYR` — вік у роках
- `RIAGENDR` — стать (1 = чоловік, 2 = жінка)

**Антропометрія:**
- `BMXBMI` — індекс маси тіла (Body Mass Index)

**Артеріальний тиск:**
- `BPXSY1` — систолічний артеріальний тиск
- `BPXDI1` — діастолічний артеріальний тиск

**Лабораторні показники:**
- `LBXGLU` — рівень глюкози в крові
- `LBXTC` — загальний холестерин

**Статус захворювань:**
- `DIQ010` — діагностований діабет (з опитувальника)

**Цільові змінні (створені в процесі ETL):**
- `obesity_present` — наявність ожиріння (1 = так, якщо BMI ≥ 30; 0 = ні)
- `diabetes_present` — наявність діабету (1 = так, якщо DIQ010 == 1; 0 = ні)

Ці цільові змінні використовуються для навчання моделей бінарної класифікації, які прогнозують ризик ожиріння та діабету на основі інших показників здоров'я.

## ETL-процес: як формувався health_dataset.csv

### Скрипти ETL

Процес обробки даних реалізовано у двох основних ETL-скриптах:

1. **`src/data/nhanes_etl.py`** — основний ETL-пайплайн з жорстко закодованими параметрами
2. **`src/health_risk_ai/data/nhanes_etl.py`** — альтернативна реалізація з використанням конфігураційного файлу

Конфігурація ETL зберігається у файлі **`configs/nhanes.yaml`**, який визначає шляхи до сирих даних, список ознак для збереження та правила формування цільових змінних.

ETL-процес також можна запустити через CLI-команду:
```bash
python -m scripts.cli data
```

### Послідовність ETL-кроків

Процес перетворення сирих NHANES-таблиць у фінальний `health_dataset.csv` складається з наступних етапів:

1. **Завантаження сирих таблиць**
   - Зчитування всіх 6 CSV-файлів з директорії `datasets/raw/`
   - Обробка різних кодувань (спроба UTF-8, fallback на latin-1)

2. **Об'єднання таблиць (merge)**
   - Злиття всіх таблиць за спільним ключем `SEQN` (Sequence Number)
   - Використання зовнішнього злиття (outer join) для збереження всіх респондентів

3. **Вибір ключових ознак**
   - Відбір необхідних колонок з об'єднаної таблиці
   - Збереження лише релевантних змінних для моделювання:
     - `SEQN`, `RIDAGEYR`, `RIAGENDR` (демографія)
     - `BMXBMI` (антропометрія)
     - `BPXSY1`, `BPXDI1` (артеріальний тиск)
     - `LBXGLU`, `LBXTC` (лабораторні показники)
     - `DIQ010` (статус діабету)

4. **Очищення даних**
   - Видалення дублікатів за ключем `SEQN`
   - Видалення рядків з понад 50% пропусків у числових колонках
   - Конвертація числових колонок у тип float з обробкою помилок

5. **Створення цільових змінних (derive targets)**
   - **`obesity_present`**: бінарна змінна, яка дорівнює 1, якщо `BMXBMI >= 30`, інакше 0
   - **`diabetes_present`**: бінарна змінна, яка дорівнює 1, якщо `DIQ010 == 1` (діагностований діабет), інакше 0
   - Пропущені значення заповнюються як 0 (False)

6. **Збереження результату**
   - Запис фінального датасету у файл `datasets/processed/health_dataset.csv`
   - Кодування UTF-8, без індексів

### Примітки щодо обробки даних

- У процесі ETL змінні зберігають свої оригінальні NHANES-назви (наприклад, `RIDAGEYR`, `BMXBMI`, `BPXSY1`). Це дозволяє легко звірятися з оригінальною документацією NHANES.
- Пропущені значення обробляються консервативно: рядки з великою кількістю пропусків видаляються, але окремі пропуски залишаються для подальшої обробки моделями або імпутації.
- Цільові змінні (`obesity_present`, `diabetes_present`) створюються на основі бізнес-правил, визначених у коді ETL, а не безпосередньо з оригінальних даних.

### Повторне виконання ETL

ETL-процес вже виконаний, і готовий датасет `health_dataset.csv` зберігається в репозиторії. При потребі можна повторити процес обробки, запустивши відповідний ETL-скрипт:

```bash
python -m src.data.nhanes_etl
```

або через CLI:

```bash
python -m scripts.cli data
```

Це може бути корисно, якщо сирі дані були оновлені або якщо потрібно змінити параметри обробки.

## Роль цього датасету в магістерському проєкті

ETL-процес та підготовка датасету `health_dataset.csv` були першим етапом магістерського проєкту. Вони забезпечили фундамент для всіх подальших етапів:

1. **Дослідницький аналіз даних (EDA)** — на основі `health_dataset.csv` було виконано аналіз розподілів, кореляцій та візуалізацій ключових показників здоров'я. Результати EDA зберігаються у директорії `artifacts/eda/`.

2. **Тренування моделей машинного навчання** — датасет використовувався для навчання множини моделей (Logistic Regression, Random Forest, XGBoost, KNN, SVC, MLP) для прогнозування ризиків ожиріння та діабету. Навчені моделі зберігаються у `artifacts/models/` з метриками та візуалізаціями їх продуктивності.

3. **Розробка веб-інтерфейсу та API** — фінальний датасет та навчені моделі інтегровані у веб-застосунок, який дозволяє користувачам вводити свої показники здоров'я та отримувати прогнози ризиків у реальному часі. API використовує той самий формат даних, що й `health_dataset.csv`, для забезпечення консистентності.

Таким чином, `health_dataset.csv` є центральним елементом проєкту, який пов'язує етапи збору даних, аналізу, моделювання та практичного застосування.


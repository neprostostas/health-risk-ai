# Частина 4: База даних, тестування, архітектура, безпека та інфраструктура

## 9. База даних (DATABASE)

### 9.1. Загальна концепція

База даних у проєкті HealthRisk.AI виконує роль центрального сховища стану для вебінтерфейсу та API, зберігаючи всі динамічні дані, які змінюються під час роботи системи та повинні зберігатися між сесіями користувачів.

**Навіщо потрібна БД** — база даних забезпечує персистентність даних між сесіями користувачів, дозволяючи зберігати профілі користувачів, історію прогнозів, чати та повідомлення, історію діалогів з AI-асистентом, налаштування користувачів та іншу інформацію, необхідну для роботи системи. Без бази даних всі дані втрачалися б при перезавантаженні сервера або закритті сесії користувача, що робило б систему непрактичною для реального використання. БД також забезпечує цілісність даних через транзакції, foreign keys та обмеження, що запобігає дублюванню та некоректним зв'язкам між даними.

**Що саме зберігається** — база даних зберігає сім основних типів даних: профілі користувачів (email, хеші паролів, імена, дати народження, стать, аватари, налаштування), історію прогнозів (всі виконані прогнози з вхідними параметрами, результатами, використаними моделями, топ факторами впливу, датами створення), чати між користувачами (унікальні ідентифікатори чатів, учасники, дати створення та оновлення, закріплення, порядок відображення), повідомлення в чатах (текст повідомлень, відправники, дати відправки, статуси прочитання), повідомлення AI-асистента (історія діалогів з асистентом, ролі авторів, контекст через зв'язок з прогнозами), блокування користувачів (інформація про блокування між користувачами для запобігання створенню чатів та відправці повідомлень), токени для відновлення пароля (унікальні токени, терміни дії, статуси використання).

**Які основні сутності** — база даних містить сім основних сутностей, які відповідають таблицям: User (користувачі системи), PredictionHistory (історія прогнозів), Chat (чати між користувачами), ChatMessage (повідомлення в чатах), AssistantMessage (повідомлення AI-асистента), UserBlock (блокування користувачів), PasswordResetToken (токени для відновлення пароля). Кожна сутність має свої поля, обмеження, індекси та зв'язки з іншими сутностями через foreign keys, що забезпечує структурованість та цілісність даних.

### 9.2. Технічна частина

Технічна реалізація бази даних організована через SQLite як легке файлове рішення, SQLModel як ORM для роботи з БД та SQLAlchemy як низькорівневий шар для створення engine та сесій.

**SQLite як lightweight рішення** — SQLite обрано як основну базу даних через кілька переваг: простота розгортання — не потребує окремого сервера БД, всі дані зберігаються в одному файлі на диску, що спрощує розгортання та резервне копіювання; легкість підтримки — не потрібно налаштовувати сервер БД, управляти процесами, моніторити з'єднання, що спрощує розробку та тестування; достатня продуктивність — для середніх навантажень SQLite забезпечує швидкий доступ до даних без мережевих затримок; підтримка транзакцій — SQLite підтримує ACID-транзакції, що забезпечує цілісність даних; підтримка SQL — стандартний SQL-синтаксис дозволяє використовувати звичайні запити та інтегруватися з ORM; вбудована підтримка в Python — драйвер sqlite3 вбудований в Python, не потрібні додаткові залежності.

**Чому SQLite підходить для локальної та R&D системи** — SQLite ідеально підходить для локальної розробки та дослідницьких проєктів через: відсутність необхідності в окремому сервері — розробник може запустити систему одразу без налаштування PostgreSQL або MySQL, що прискорює розробку; швидкість розробки — не потрібно налаштовувати з'єднання, створювати користувачів БД, управляти правами доступу, що економить час; простота тестування — тестова БД може бути створена в пам'яті або тимчасовому файлі, що забезпечує швидкі та ізольовані тести; переносимість — файл БД можна легко скопіювати, перенести на іншу машину або включити в резервне копіювання; достатність для R&D — для дослідницького проєкту з невеликою кількістю користувачів SQLite забезпечує достатню продуктивність без складності продакшен-БД; легкість масштабування — при необхідності можна легко мігрувати на PostgreSQL через SQLModel, який підтримує обидві БД.

**Де зберігається файл бази даних** — база даних зберігається у файлі `data/app.db` відносно кореня проєкту. Директорія `data/` створюється автоматично при першому запуску через `DATA_DIR.mkdir(parents=True, exist_ok=True)` у модулі `db.py`, якщо вона не існує. Повний шлях до файлу формується як `sqlite:///data/app.db` у форматі SQLAlchemy connection string. Файл БД містить всі таблиці, індекси, обмеження та дані в одному файлі, що спрощує резервне копіювання (достатньо скопіювати один файл) та перенесення на інші машини.

**Структура таблиць** — структура таблиць визначається через SQLModel ORM-моделі у файлі `src/service/models.py`. Кожна модель наслідується від `SQLModel` з параметром `table=True`, що вказує SQLModel створити таблицю в БД. Поля визначаються через `Field()` з типами даних (int, str, datetime, bool, dict для JSON), обмеженнями (nullable, unique, index), foreign keys через `foreign_key="table.column"` та relationships через `Relationship()`. Структура створюється автоматично при першому запуску через `SQLModel.metadata.create_all(bind=engine)` у функції `init_db()`, яка викликається в `lifespan` контекстному менеджері FastAPI при startup.

**Індекси** — індекси створюються автоматично для полів з параметром `index=True` у `Field()` та для foreign keys. Основні індекси включають: первинні ключі (автоматично індексовані), `email` в таблиці `user` (унікальний індекс для швидкого пошуку користувача за email), `user_id` в таблицях `predictionhistory`, `assistantmessage`, `passwordresettoken`, `userblock` (індекси для швидкого пошуку записів користувача), `token` в таблиці `passwordresettoken` (унікальний індекс для швидкого пошуку токену), `uuid` в таблиці `chat` (унікальний індекс для швидкого пошуку чату за UUID), `chat_id` в таблиці `chatmessage` (індекс для швидкого пошуку повідомлень чату), `sender_id` в таблиці `chatmessage` (індекс для швидкого пошуку повідомлень відправника), `user1_id`, `user2_id` в таблиці `chat` (індекси для швидкого пошуку чатів користувача), унікальний складений індекс на `(user_id, blocked_user_id)` в таблиці `userblock` для запобігання дублюванню блокувань. Індекси забезпечують швидкий пошук записів за ключовими полями та покращують продуктивність запитів.

**Типи полів** — база даних використовує стандартні типи SQLite з відображенням через SQLModel: integer для числових полів (id, user_id, chat_id), varchar/text для рядкових полів (email, display_name, content), datetime для дат та часу (created_at, updated_at, expires_at), boolean для логічних полів (is_active, is_pinned, used), JSON (через SQLITE_JSON) для структурованих даних (inputs в таблиці predictionhistory, який містить вхідні параметри прогнозу, топ фактори, метадані). SQLModel автоматично конвертує Python-типи в SQLite-типи при створенні таблиць та конвертує SQLite-типи в Python-типи при читанні даних.

### 9.3. Основні таблиці

База даних містить сім основних таблиць, кожна з яких виконує конкретну роль у системі та має свої зв'язки з іншими таблицями.

**Таблиця user (користувачі)** — це центральна таблиця системи, яка зберігає профілі всіх користувачів. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `email` (унікальний, індексований, обов'язковий рядок для електронної пошти), `hashed_password` (обов'язковий рядок з bcrypt-хешем пароля), `display_name` (обов'язковий рядок для імені відображення), `first_name`, `last_name` (опційні рядки для імені та прізвища), `date_of_birth` (опційний datetime для дати народження), `gender` (опційний рядок: male/female/other), `avatar_url` (опційний рядок для URL завантаженого аватару), `avatar_type` (обов'язковий рядок: "generated" або "uploaded"), `avatar_color` (опційний рядок для кольору згенерованого аватару), `is_active` (boolean, за замовчуванням True для активності акаунта), `created_at`, `updated_at` (datetime для відстеження часу створення та оновлення). Таблиця використовується API для аутентифікації (пошук користувача за email, перевірка пароля), управління профілем (оновлення даних, зміна пароля, завантаження аватару), відображення інформації про користувача на фронтенді. Таблиця пов'язана з іншими таблицями через foreign keys: один користувач може мати багато записів в `predictionhistory` (зв'язок один-до-багатьох), багато повідомлень в `assistantmessage` (зв'язок один-до-багатьох), багато чатів через `user1_id` та `user2_id` в таблиці `chat` (зв'язок багато-до-багатьох), багато токенів для відновлення пароля (зв'язок один-до-багатьох), багато блокувань через `user_id` та `blocked_user_id` в таблиці `userblock` (зв'язок один-до-багатьох, двоспрямований).

**Таблиця predictionhistory (історія прогнозів)** — це таблиця для збереження всіх прогнозувань ризиків здоров'я, виконаних користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий), `target` (обов'язковий рядок: "diabetes_present" або "obesity_present" для цільової змінної прогнозування), `model_name` (опційний рядок для назви використаної ML-моделі), `probability` (обов'язковий float, 0-1 для ймовірності позитивного класу), `risk_bucket` (обов'язковий рядок: "low", "medium" або "high" для категорії ризику), `inputs` (обов'язковий JSON, який містить вхідні параметри прогнозу: вік, стать, ІМТ, артеріальний тиск, глюкоза, холестерин, топ фактори впливу, метадані моделі), `created_at` (datetime, автоматично встановлюється при створенні). Таблиця використовується API для збереження результатів прогнозування після успішного прогнозу через `add_prediction_history()` у `repositories.py`, отримання історії прогнозів користувача для відображення на фронтенді через `get_all_prediction_history()`, використання в AI-асистенті для контексту через зв'язок з `assistantmessage` через `prediction_id`, аналізу трендів ризиків у часі, статистики для діаграм та звітів. Таблиця пов'язана з таблицею `user` через foreign key `user_id` (зв'язок багато-до-одного), що дозволяє легко отримувати всі прогнози користувача та забезпечує автоматичне видалення записів при видаленні користувача (якщо налаштовано CASCADE). Таблиця також пов'язана з таблицею `assistantmessage` через опційний foreign key `prediction_id` (зв'язок один-до-багатьох), що дозволяє AI-асистенту використовувати контекст конкретного прогнозу для більш точних рекомендацій.

**Таблиця chat (чати)** — це таблиця для зберігання чатів між двома користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `uuid` (унікальний, індексований рядок, автоматично генерується через UUID для використання в URL), `user1_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID першого учасника), `user2_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID другого учасника), `created_at` (datetime, автоматично встановлюється при створенні), `updated_at` (datetime, автоматично оновлюється при додаванні повідомлень через `chat.touch()`), `is_pinned` (boolean, за замовчуванням False для закріплення важливих чатів), `order` (integer, за замовчуванням 0 для порядку відображення чатів для drag and drop). Таблиця використовується API для створення або отримання існуючого чату між двома користувачами через `get_or_create_chat()` у `repositories.py`, отримання списку чатів користувача для відображення на фронтенді, управління порядком відображення чатів, закріплення важливих чатів. Таблиця пов'язана з таблицею `user` через два foreign keys `user1_id` та `user2_id` (зв'язок багато-до-багатьох), що дозволяє кожному користувачу мати багато чатів з різними користувачами, а кожен чат унікальний для пари користувачів. Таблиця також пов'язана з таблицею `chatmessage` через foreign key `chat_id` (зв'язок один-до-багатьох), що дозволяє легко отримувати всі повідомлення чату.

**Таблиця chatmessage (повідомлення в чатах)** — це таблиця для зберігання повідомлень у чатах між користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `chat_id` (зовнішній ключ до таблиці `chat`, індексований, обов'язковий), `sender_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID відправника), `content` (обов'язковий Text для тексту повідомлення), `created_at` (datetime, автоматично встановлюється при створенні), `read_at` (опційний datetime, None означає непрочитане повідомлення). Таблиця використовується API для додавання повідомлень у чат через `add_chat_message()` у `repositories.py`, отримання історії повідомлень чату для відображення на фронтенді через `get_chat_messages()`, відстеження статусу прочитання для підрахунку непрочитаних повідомлень через `mark_messages_as_read()`, побудови історії діалогів, сортування повідомлень за часом для відображення на фронтенді. Таблиця пов'язана з таблицею `chat` через foreign key `chat_id` (зв'язок багато-до-одного), що дозволяє легко отримувати всі повідомлення чату та забезпечує автоматичне видалення повідомлень при видаленні чату (якщо налаштовано CASCADE). Таблиця також пов'язана з таблицею `user` через foreign key `sender_id` (зв'язок багато-до-одного), що дозволяє легко отримувати інформацію про відправника повідомлення.

**Таблиця assistantmessage (повідомлення AI-асистента)** — це таблиця для зберігання історії повідомлень з AI-асистентом для кожного користувача. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий), `role` (обов'язковий рядок: "user" для користувача або "assistant" для AI-асистента), `content` (обов'язковий Text для тексту повідомлення), `created_at` (datetime, автоматично встановлюється при створенні), `prediction_id` (опційний зовнішній ключ до таблиці `predictionhistory` — зв'язок з конкретним прогнозом для контексту). Таблиця використовується API для збереження повідомлень користувача та відповідей асистента через `add_message()` у `repositories.py`, отримання історії діалогів для відображення на фронтенді через `get_user_messages()`, відновлення контексту діалогу при наступних запитах для більш точних рекомендацій, побудови історії чату для відображення на фронтенді. Таблиця пов'язана з таблицею `user` через foreign key `user_id` (зв'язок багато-до-одного), що дозволяє зберігати окрему історію діалогу з асистентом для кожного користувача. Таблиця також пов'язана з таблицею `predictionhistory` через опційний foreign key `prediction_id` (зв'язок багато-до-одного), що дозволяє AI-асистенту використовувати контекст конкретного прогнозу для більш точних рекомендацій.

**Таблиця userblock (блокування користувачів)** — це таблиця для зберігання інформації про блокування між користувачами. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID користувача, який заблокував), `blocked_user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий — ID заблокованого користувача), `created_at` (datetime, автоматично встановлюється при створенні). Таблиця використовується API для додавання або видалення блокувань через `block_user()` та `unblock_user()` у `repositories.py`, перевірки наявності блокування між користувачами через `is_user_blocked()` та `get_blocked_user_ids()` для фільтрації при створенні чатів, відправці повідомлень, отриманні списку користувачів. Таблиця має унікальний складений індекс на парі `(user_id, blocked_user_id)` для запобігання дублюванню блокувань. Блокування одностороннє — якщо користувач A заблокував користувача B, це не означає, що B заблокував A. Таблиця пов'язана з таблицею `user` через два foreign keys `user_id` та `blocked_user_id` (зв'язок один-до-багатьох, двоспрямований), що дозволяє одному користувачу заблокувати багато інших користувачів, а один користувач може бути заблокований багатьма іншими.

**Таблиця passwordresettoken (токени для відновлення пароля)** — це таблиця для зберігання токенів для відновлення пароля, які генеруються при запиті "забув пароль" та відправляються на email користувача. Таблиця містить поля: `id` (первинний ключ, автоінкрементний integer), `user_id` (зовнішній ключ до таблиці `user`, індексований, обов'язковий), `token` (унікальний, індексований, обов'язковий рядок для унікального токену), `expires_at` (обов'язковий datetime для часу закінчення токену), `used` (boolean, за замовчуванням False для позначення використання токену), `created_at` (datetime, автоматично встановлюється при створенні). Таблиця використовується API для створення токенів при запиті відновлення пароля, перевірки валідності токену при встановленні нового пароля, запобігання повторному використанню токенів через поле `used`. Токени мають термін дії та можуть бути використані тільки один раз. Таблиця пов'язана з таблицею `user` через foreign key `user_id` (зв'язок багато-до-одного), що дозволяє одному користувачу мати багато токенів (наприклад, якщо запитує відновлення кілька разів).

### 9.4. Міграції (якщо логіка є)

Міграції бази даних реалізовані програмно через функцію `migrate_add_missing_columns()` у модулі `src/service/db.py`, яка додає відсутні колонки до існуючих таблиць при старті додатку.

**Створення нових таблиць** — нові таблиці створюються автоматично при першому запуску через `SQLModel.metadata.create_all(bind=engine)` у функції `init_db()`, яка викликається в `lifespan` контекстному менеджері FastAPI при startup. Функція перевіряє наявність таблиць через `inspector.get_table_names()` та створює їх, якщо вони не існують, на основі SQLModel-моделей, визначених у `src/service/models.py`. Після створення таблиць виконується міграція для додавання відсутніх колонок через `migrate_add_missing_columns()`. Це забезпечує, що структура БД завжди відповідає моделям, навіть якщо моделі були змінені після створення таблиць.

**Оновлення структури** — оновлення структури таблиць виконується через функцію `migrate_add_missing_columns()`, яка перевіряє наявність колонок у таблицях та додає відсутні через `ALTER TABLE`. Функція використовує SQLAlchemy inspector для отримання списку існуючих колонок через `inspector.get_columns(table_name)`, порівнює їх з очікуваними полями з моделей та додає відсутні колонки через SQL-запити `ALTER TABLE table_name ADD COLUMN column_name TYPE`. Міграції виконуються при кожному запуску додатку, що забезпечує актуальність схеми БД без необхідності ручного виконання міграцій. Наразі система міграцій проста та додає тільки нові колонки, не видаляючи старі та не змінюючи типи існуючих колонок.

**Додавання нових полів** — додавання нових полів до існуючих таблиць виконується через `migrate_add_missing_columns()`, яка перевіряє наявність полів та додає відсутні. Наприклад, для таблиці `user` функція перевіряє наявність полів `avatar_type`, `first_name`, `last_name`, `date_of_birth`, `gender` та додає їх, якщо вони відсутні. Для таблиці `chat` функція перевіряє наявність полів `is_pinned` та `order` та додає їх з значеннями за замовчуванням. Для таблиці `userblock` функція створює таблицю, якщо вона відсутня, разом з індексами. Це дозволяє додавати нові поля до існуючих таблиць без втрати даних та без необхідності ручного виконання SQL-скриптів. В майбутньому можна додати систему міграцій (наприклад, Alembic) для більш складних змін схеми, включаючи видалення колонок, зміну типів, перейменування полів.

### 9.5. Робота з БД у FastAPI

Робота з базою даних у FastAPI організована через SQLAlchemy engine, сесії та dependency injection для забезпечення ізоляції транзакцій та коректної обробки помилок.

**Пул з'єднань** — SQLAlchemy engine створюється один раз при імпорті модуля `db.py` через `create_engine()` та використовується для всіх підключень до БД. Engine налаштований з `echo=False` (без логування SQL-запитів) та `connect_args={"check_same_thread": False}` для підтримки багатопотоковості в ASGI. Engine автоматично керує пулом з'єднань, створюючи нові з'єднання при потребі та перевикористовуючи існуючі для оптимізації продуктивності. SQLite підтримує одночасні читання, але тільки один writer одночасно, що достатньо для середніх навантажень локальної системи.

**Асинхронність** — хоча FastAPI підтримує асинхронні операції через `async/await`, робота з SQLite через SQLAlchemy виконується синхронно, оскільки SQLite не підтримує нативну асинхронність. Для асинхронної роботи з БД потрібно використовувати асинхронні драйвери (наприклад, aiosqlite для SQLite або asyncpg для PostgreSQL) та асинхронні версії SQLAlchemy (SQLAlchemy 2.0 з async support). В поточній реалізації всі операції з БД виконуються синхронно, але FastAPI обробляє їх в thread pool для неблокуючої обробки запитів. Це забезпечує достатню продуктивність для локальної системи, але для продакшену з високим навантаженням варто розглянути перехід на асинхронну БД (PostgreSQL з asyncpg) або окремий сервіс для БД-операцій.

**Робота ORM чи raw SQL** — проєкт використовує ORM (SQLModel) як основний спосіб роботи з БД, що забезпечує типобезпеку, валідацію даних та спрощує роботу зі зв'язками між таблицями. SQLModel дозволяє визначати моделі, які використовуються і для валідації API (через Pydantic), і для роботи з БД (через SQLAlchemy), що забезпечує консистентність даних. Репозиторійний шар у `src/service/repositories.py` інкапсулює логіку роботи з БД через SQLModel-запити (наприклад, `select(User).where(User.email == email)`), що забезпечує читабельність коду та спрощує тестування. Raw SQL використовується тільки для міграцій через `text()` у функції `migrate_add_missing_columns()`, де потрібно виконувати `ALTER TABLE` запити, які не підтримуються SQLModel напряму. Це забезпечує баланс між зручністю ORM та гнучкістю raw SQL для спеціальних випадків.

## 10. Тестування (TESTING)

### 10.1. Загальний огляд

Система тестування проєкту HealthRisk.AI організована за принципом багаторівневої архітектури, що забезпечує перевірку коректності логіки, стабільності API, роботи ML моделей, UI та інтеграцій на різних рівнях абстракції.

**Що саме тестується в системі** — тести покривають всі ключові компоненти системи: функції бізнес-логіки (хешування паролів, JWT токени, обчислення ризиків, топ факторів), API ендпоінти (автентифікація, прогнозування, історія, чати, AI-асистент), ML моделі (завантаження, передбачення, діапазони ймовірностей, детермінізм), взаємодію між компонентами (API-БД, API-ML, повний цикл запиту прогнозу), обробку помилок (невалідні дані, неавтентифіковані запити, помилки БД, помилки ML), граничні випадки (екстремальні значення, пропущені дані, нереалістичні комбінації параметрів). Тести забезпечують, що система працює коректно при нормальному використанні, правильно обробляє помилки та граничні випадки, та залишається стабільною при змінах коду.

### 10.2. Типи тестів

Проєкт використовує декілька типів тестів для забезпечення якості коду та функціональності системи на різних рівнях абстракції.

**Юніт-тести** — це тести окремих функцій та утиліт ізольовано від інших компонентів системи. Юніт-тести покривають функції з бізнес-логіки (хешування паролів через `get_password_hash()`, перевірка паролів через `verify_password()`, генерація JWT токенів через `create_access_token()`, декодування токенів через `decode_token()`, обчислення ризиків через `get_risk_bucket()`, топ факторів через `calculate_top_factors_simple()`), утиліти (конвертери даних, форматування, обробка помилок, валідація), Pydantic схеми (валідація вхідних та вихідних даних API, перевірка типів, діапазонів, обов'язковості полів), невеликі сервісні класи (реєстр моделей, завантаження моделей, обробка даних). Юніт-тести розташовані у `tests/backend/unit/` для бекенду та `tests/ml/unit/` для ML, використовують моки для ізоляції компонентів та перевіряють коректність обробки валідних даних, граничних випадків та некоректних даних з очікуваними винятками.

**Інтеграційні тести** — це тести взаємодії між компонентами системи. Інтеграційні тести покривають взаємодію API і бази даних (тести перевіряють, що API коректно зберігає дані в БД, читає дані з БД, оновлює записи, видаляє записи, обробляє помилки БД, такі як дублювання email, неіснуючі записи), інтеграцію API з ML моделями (тести перевіряють, що API коректно завантажує моделі, виконує прогнозування, обробляє вхідні дані, повертає результати у правильному форматі, зберігає історію прогнозів), повний цикл запиту прогнозу (тести перевіряють весь процес від отримання вхідних даних через API до збереження результату в БД, включаючи валідацію, обробку, прогнозування, збереження). Інтеграційні тести розташовані у `tests/backend/integration/`, використовують тестову БД (тимчасову SQLite) для ізоляції та автоматичного очищення після завершення, використовують фікстури для підготовки даних (користувачі, токени, тестові дані) та перевіряють коректність роботи всіх компонентів разом.

**E2E-тести** — це тести повних сценаріїв користувача від початку до кінця. E2E-тести покривають повні сценарії користувача (реєстрація → логін → прогноз → історія → оновлення профілю), повний цикл роботи з системою (створення акаунту, виконання прогнозу, перегляд історії, генерація PDF-звіту, використання AI-асистента), навігацію між сторінками (перехід між секціями, збереження стану, відновлення після перезавантаження), автентифікацію (вхід, вихід, оновлення профілю, зміна пароля). E2E-тести розташовані у `tests/backend/e2e/`, використовують тестову БД та тестовий клієнт FastAPI для імітації повного циклу роботи користувача та перевіряють, що всі компоненти працюють разом коректно для реалістичних сценаріїв використання.

**Тести API** — це тести коректності роботи ендпоінтів, обробки запитів, валідації даних та обробки помилок. Тести API покривають ендпоінти логіну та реєстрації (тести перевіряють успішну реєстрацію, логін з правильними credentials, обробку дублювання email, невалідних email, порожніх паролів, неправильних credentials, неактивних акаунтів), прогноз ризику (тести перевіряють прогноз діабету, прогноз ожиріння, валідацію вхідних даних, обробку відсутніх обов'язкових полів, діапазони ймовірностей, категорії ризику, топ фактори, збереження в історії), історію (тести перевіряють отримання історії прогнозів, фільтрацію за користувачем, сортування за датою, обмеження кількості записів), чати (тести можуть перевіряти створення чатів, відправку повідомлень, отримання історії чатів), API-status (тести можуть перевіряти статус API, БД, Ollama). Тести API формують HTTP-запити через `TestClient` з FastAPI, перевіряють статус-коди відповідей (200 для успішних, 400 для помилок валідації, 401 для неавтентифікованих, 403 для відсутності прав, 404 для неіснуючих ресурсів, 422 для помилок валідації Pydantic), перевіряють структуру JSON-відповідей (наявність полів, значення, діапазони, допустимі значення) та перевіряють сценарії з помилками (401, 403, 422 з детальними повідомленнями).

**Тести ML-моделей** — це тести коректності завантаження моделей, стабільності передбачень, відповідності формату інпутів та аутпутів та якості метрик. Тести ML покривають завантаження моделей (тести перевіряють завантаження чемпіонських моделей для діабету та ожиріння, каліброваних моделей, конкретних моделей за ключем, обробку помилок при відсутності моделей), логіку прогнозування (тести перевіряють діапазони ймовірностей 0-1, детермінізм передбачень, реалістичні дані, суму ймовірностей = 1), екстремальні значення (тести перевіряють, що модель не падає на граничних значеннях параметрів, повертає валідні результати, обробляє нереалістичні комбінації параметрів), пропущені дані (тести перевіряють, що pipeline коректно обробляє None значення через імпутацію, що передбачення стабільні при пропущених опціональних полях), чутливість моделей (тести перевіряють, що збільшення факторів ризику збільшує ймовірність позитивного класу, що модель реагує на зміни параметрів логічно та передбачувано). Тести ML розташовані у `tests/ml/unit/` для unit тестів та `tests/ml/experimental/` для експериментальних тестів, використовують маркери `@pytest.mark.skipif` для пропуску тестів, якщо моделі не знайдено, та перевіряють, що моделі працюють коректно навіть при нестандартних вхідних даних.

**Експериментальні тести (нестандартні кейси)** — це тести нестандартних сценаріїв та граничних випадків для підтвердження надійності системи. Експериментальні тести покривають екстремальні значення параметрів (максимальний вік 120, максимальний ІМТ 60, максимальний тиск 250, максимальна глюкоза 400, мінімальні значення, нереалістичні комбінації), пропущені дані (один пропущений параметр, кілька пропущених параметрів, всі опціональні поля пропущені, обробка через імпутацію), чутливість моделей до змін факторів (чутливість до зміни ІМТ, глюкози, віку, перевірка що збільшення факторів ризику збільшує ймовірність). Експериментальні тести розташовані у `tests/ml/experimental/` та `tests/backend/experimental/`, допомагають виявити проблеми з обробкою граничних випадків, перевірити стабільність моделей на нестандартних даних, підтвердити що система не падає при неочікуваних вхідних даних, забезпечити що модель повертає валідні результати навіть при екстремальних значеннях, перевірити що обробка пропущених даних працює коректно.

### 10.3. Покриття

Покриття коду тестами відстежується через pytest-cov та аналіз структури тестів для виявлення непокритих частин коду та покращення якості тестів.

**Що має бути покрито** — покриття тестами має охоплювати всі критичні частини системи: функції аутентифікації (хешування паролів, JWT токени, перевірка паролів повинні бути покриті unit тестами для забезпечення безпеки), Pydantic схеми (валідація вхідних та вихідних даних повинна бути покрита unit тестами для забезпечення коректності даних), API ендпоінти (автентифікація та прогнозування повинні бути покриті інтеграційними тестами для забезпечення стабільності API), завантаження моделей (завантаження чемпіонських та конкретних моделей повинно бути покрито unit тестами для забезпечення коректності завантаження), логіка прогнозування (діапазони ймовірностей, детермінізм повинні бути покриті unit тестами для забезпечення коректності передбачень), обробка помилок (невалідні дані, неавтентифіковані запити, помилки БД повинні бути покриті тестами для забезпечення надійності системи), граничні випадки (екстремальні значення, пропущені дані повинні бути покриті експериментальними тестами для забезпечення стабільності).

**Чому це важливо** — покриття тестами важливе для забезпечення якості коду та надійності системи: виявлення помилок на ранніх етапах — тести допомагають виявити помилки до того, як вони потраплять у продакшен, що економить час та ресурси; запобігання регресіям — тести перевіряють, що зміни коду не зламали існуючий функціонал, що дозволяє безпечно рефакторити та додавати нові функції; документація поведінки — тести слугують документацією того, як повинна працювати система, що допомагає новим розробникам зрозуміти код; впевненість у змінах — високе покриття дає впевненість, що зміни не зламають систему, що дозволяє швидше розвивати проєкт; якість коду — покриття допомагає виявити непокритий код, що може містити помилки або невикористовуваний функціонал; інтеграція з CI/CD — покриття може бути інтегроване з CI/CD для автоматичної перевірки якості коду при кожному коміті.

### 10.4. Організація структури тестів

Структура тестів організована за принципом розділення за типами тестів та компонентами системи для зручності навігації та запуску окремих груп тестів.

**Де зберігаються** — всі тести розміщені у кореневій директорії `tests/` відносно кореня проєкту. Структура організована за типами тестів та компонентами системи: `tests/backend/unit/` для unit тестів бекенду, `tests/backend/integration/` для інтеграційних тестів бекенду, `tests/backend/e2e/` для e2e тестів бекенду, `tests/backend/experimental/` для експериментальних тестів бекенду, `tests/frontend/unit/` для unit тестів фронтенду, `tests/frontend/integration/` для інтеграційних тестів фронтенду, `tests/frontend/e2e/` для e2e тестів фронтенду, `tests/ml/unit/` для unit тестів ML, `tests/ml/experimental/` для експериментальних тестів ML, `tests/ml/metrics/` для тестів метрик моделей, `tests/utils/` для утиліт тестів (фікстури, генератори тестових даних), `tests/conftest.py` для загальних фікстур для всіх тестів.

**Логіка поділу** — тести розділені за типами та компонентами для зручності навігації та запуску: розділення за типами (unit, integration, e2e, experimental) дозволяє запускати тільки потрібний тип тестів для швидкої перевірки конкретної частини системи, розділення за компонентами (backend, frontend, ml) дозволяє запускати тести тільки для конкретного компонента, що економить час при розробці, окремі папки для утиліт та фікстур дозволяють повторно використовувати код між тестами, що спрощує підтримку. Це забезпечує чітку організацію тестів та дозволяє легко знаходити потрібні тести для конкретного компонента або типу.

**План для розширення** — структура тестів готова для майбутнього розширення: папки для фронтенду (`tests/frontend/unit/`, `tests/frontend/integration/`, `tests/frontend/e2e/`) створені та готові для додавання тестів, папка для експериментальних тестів бекенду (`tests/backend/experimental/`) готова для додавання нестандартних сценаріїв, папка для тестів метрик (`tests/ml/metrics/`) готова для додавання тестів якості моделей, утиліти для тестів (`tests/utils/`) готові для додавання нових генераторів тестових даних та фікстур. Це дозволяє легко додавати нові тести без зміни структури та забезпечує масштабованість системи тестування.

## 11. Архітектура системи (ARCHITECTURE OVERVIEW)

### 11.1. Загальна архітектура

Архітектура системи HealthRisk.AI організована за принципом багатошарової архітектури з чітким розділенням відповідальності між компонентами. Кожен шар виконує конкретні завдання та взаємодіє з іншими через чітко визначені інтерфейси.

**Компонентна схема** — система складається з кількох великих блоків: ETL & Data (фундаментальний шар для збору, обробки та підготовки даних), EDA (аналітичний шар для дослідження підготовленого датасету), ML-моделі (інтелектуальний шар для трансформації медичних параметрів в оцінки ризиків), Backend / API (центральний шар взаємодії, який об'єднує всі компоненти), Database (шар персистентності для збереження динамічних даних), Frontend (SPA) (інтерфейсний шар для взаємодії користувачів), AI (Ollama) (допоміжний інтелектуальний шар для AI-асистента), Reporting (шар генерації звітів), Testing (шар забезпечення якості). Кожен блок має свою відповідальність та інтегрується з іншими для створення єдиної системи.

**Основні блоки** — основні блоки системи включають: блок ETL & Data відповідає за збір, обробку та підготовку даних від сирих NHANES-таблиць до очищеного об'єднаного датасету `health_dataset.csv`, блок EDA відповідає за дослідження підготовленого датасету для розуміння розподілів, кореляцій та закономірностей, блок ML-моделі відповідає за навчання моделей машинного навчання та трансформацію медичних параметрів в оцінки ризиків, блок Backend / API відповідає за REST API для фронтенду, виконання ML inference, управління аутентифікацією, збереження та читання даних з БД, інтеграцію з Ollama, блок Database відповідає за збереження всіх динамічних даних системи, блок Frontend (SPA) відповідає за відображення інтерфейсу користувача, обробку взаємодії, комунікацію з API, генерацію звітів, блок AI (Ollama) відповідає за надання AI-асистента для пояснення результатів та надання рекомендацій, блок Reporting відповідає за генерацію PDF-звітів з результатами прогнозування, блок Testing відповідає за перевірку коректності роботи всіх компонентів системи.

**Як вони між собою взаємодіють** — взаємодія між блоками організована за принципом односпрямованого потоку даних: ETL → EDA → ML → API → Frontend. Дані проходять від сирих таблиць через обробку та аналіз до навчених моделей, які використовуються в API для обробки запитів користувачів. Фронтенд отримує дані через API та відображає їх користувачам. БД зберігає всі динамічні дані та використовується API для персистентності. AI-асистент та звіти працюють як допоміжні сервіси, які використовують дані з основних компонентів для надання додаткової функціональності. Тестування перевіряє коректність роботи всіх компонентів на різних рівнях абстракції.

### 11.2. Frontend

Фронтенд реалізований як Single Page Application (SPA) на чистому JavaScript без використання фреймворків, що забезпечує мінімалістичний, автономний та легкий клієнт з повною функціональністю системи.

**SPA + JS** — Single Page Application працює через один HTML-файл, який містить всі секції сторінок у прихованому стані. При завантаженні сторінки бекенд завжди повертає один і той самий HTML-файл незалежно від URL, а JavaScript визначає, яку секцію потрібно показати на основі поточного URL. Всі секції присутні в DOM з самого початку, але приховані через CSS-класи та атрибут `hidden`, що дозволяє швидко перемикатися між сторінками без додаткових HTTP-запитів. Перемикання секцій виконується через додавання класу `page--active` та видалення атрибута `hidden` для активної секції та приховування всіх інших. JavaScript виконує всю логіку SPA, включаючи маршрутизацію, управління станом, роботу з API, генерацію PDF, роботу з діаграмами, інтеграцію з AI-асистентом.

**Router** — маршрутизація реалізована через власну систему без використання зовнішніх бібліотек (Navigo використовується тільки як допоміжна утиліта). Система включає об'єкт `ROUTE_SECTIONS` для мапінгу URL на ID секцій, функцію `normalizePath()` для нормалізації шляхів (видалення подвійних слешів, обробка аліасів, конвертація в нижній регістр), функцію `getSectionByPath()` для визначення секції за URL, функцію `showSectionForPath()` для активації секції з перевіркою автентифікації, функцію `syncRouteFromLocation()` для синхронізації стану з URL, функцію `activateSection()` для активації конкретної секції з оновленням навігації та локалізації. Навігація між сторінками виконується без перезавантаження сторінки через History API браузера, що забезпечує плавну навігацію без затримок перезавантаження та зберігає історію перегляду для користувача.

**Умовно-компонентна логіка** — хоча фронтенд не використовує компонентну архітектуру фреймворків, логіка організована функціонально через функції у `app.js`, які відповідають за конкретні компоненти. Компоненти включають форми (форма прогнозування, форма входу, форма реєстрації, форма профілю), діаграми (Chart.js інстанси для різних типів графіків), модальні вікна (підтвердження дій, налаштування, інформація), нотифікації (toast-сповіщення для успіхів, помилок, інформації), sidebar (навігація, перемикання теми, статуси), чати (список чатів, детальний вигляд чату, повідомлення), AI-асистент (інтерфейс чату, історія повідомлень). Кожен компонент має свої функції для ініціалізації, оновлення та очищення, що забезпечує модульність та підтримуваність коду.

### 11.3. Backend

Бекенд реалізований на FastAPI з сервісно-орієнтованою архітектурою, де кожен компонент виконує конкретні завдання та інтегрується з іншими через чітко визначені інтерфейси.

**Шари: routing, services, ML, DB** — бекенд організований за принципом багатошарової архітектури: шар routing відповідає за обробку HTTP-запитів та маршрутизацію до відповідних обробників через FastAPI роутери (`src/service/api.py` для основних ендпоінтів, `src/service/routers/` для модульних роутерів, `src/service/routes_auth.py` для автентифікації), шар services відповідає за бізнес-логіку та інтеграцію з зовнішніми сервісами (`src/service/services/assistant_llm.py` для інтеграції з Ollama, `src/service/auth_utils.py` для аутентифікації, `src/service/avatar_utils.py` для управління аватарами), шар ML відповідає за завантаження та використання ML-моделей (`src/service/model_registry.py` для реєстру моделей, завантаження чемпіонських моделей, кешування), шар DB відповідає за роботу з базою даних (`src/service/db.py` для налаштування підключення, `src/service/models.py` для ORM-моделей, `src/service/repositories.py` для CRUD операцій). Кожен шар має свою відповідальність та взаємодіє з іншими через чітко визначені інтерфейси, що забезпечує модульність та підтримуваність коду.

**Схема request → process → response** — обробка запиту в бекенді організована як послідовний pipeline: request (HTTP-запит надходить до FastAPI через ASGI сервер Uvicorn, FastAPI визначає відповідний роутер на основі URL та методу HTTP, middleware обробляє запит для CORS, нормалізації шляхів, логування), process (роутер викликає відповідний обробник ендпоінта, dependency injection створює сесію БД через `Depends(get_session)`, перевіряє автентифікацію через `Depends(get_current_user)` для захищених ендпоінтів, валідує вхідні дані через Pydantic-схеми, виконує бізнес-логіку через сервіси та репозиторії, завантажує ML-моделі через реєстр моделей для прогнозування, зберігає дані в БД через репозиторії, формує відповідь), response (обробник повертає дані у форматі Pydantic-моделі, FastAPI серіалізує відповідь у JSON, middleware обробляє відповідь для додавання заголовків, логування, HTTP-відповідь повертається клієнту). Це забезпечує чітку структуру обробки запитів та дозволяє легко додавати нові ендпоінти або змінювати логіку обробки.

### 11.4. ML layer

ML-шар відповідає за завантаження навчених моделей, виконання інференсу та повернення результатів у форматі, зручному для API та фронтенду.

**Завантаження моделей** — моделі завантажуються в пам'ять при першому використанні через реєстр моделей у `src/service/model_registry.py`. Реєстр моделей завантажує champion-моделі (з пріоритетом каліброваних версій) для кожної цільової змінної (diabetes_present, obesity_present) з директорії `artifacts/models/{target}/`. Моделі зберігаються у форматі `.joblib` та завантажуються через `joblib.load()`. Реєстр кешує завантажені моделі в пам'яті для швидкого доступу при подальших запитах, що забезпечує швидкість інференсу без необхідності повторного завантаження з диску. Моделі також можуть бути завантажені за конкретним ключем (наприклад, "logreg", "random_forest") через функцію `load_model()`, якщо користувач вибрав конкретну модель замість автоматичного вибору champion.

**Інференс** — інференс виконується при запиті на прогноз через ендпоінт `/predict`. Процес включає кілька кроків: отримання вхідних параметрів користувача (вік, стать, ІМТ, тиск, глюкоза, холестерин) через Pydantic-схему `PredictRequest`, перетворення JSON-даних у pandas DataFrame, передачу через pipeline моделі (який виконує імпутацію пропущених значень через `SimpleImputer`, стандартизацію числових ознак через `StandardScaler`, one-hot encoding категоріальних ознак через `OneHotEncoder`), отримання ймовірності ризику через `pipeline.predict_proba()`, визначення категорії ризику (низький, середній, високий) на основі ймовірності через функцію `get_risk_bucket()`, обчислення топ-5 факторів впливу через функцію `calculate_top_factors_simple()`, формування JSON-відповіді з результатами. Інференс виконується синхронно, але FastAPI обробляє його в thread pool для неблокуючої обробки інших запитів.

**Повернення результатів** — результати інференсу повертаються у форматі JSON через Pydantic-схему `PredictResponse`, яка включає поля: `probability` (ймовірність ризику 0-1), `risk_bucket` (категорія ризику: "low", "medium" або "high"), `top_factors` (список факторів з їх впливом у відсотках), `model_name` (назва використаної моделі), `target` (цільова змінна). Відповідь також може включати метадані моделі (версія, дата навчання, метрики) для відображення на фронтенді. Результати зберігаються в БД через `add_prediction_history()` для історії прогнозів (якщо користувач автентифікований), що дозволяє користувачам переглядати свої попередні прогнози та аналізувати зміни ризиків у часі.

### 11.5. База даних

База даних виконує роль persistence layer, який зберігає всі динамічні дані та забезпечує персистентність між сесіями користувачів.

**Persistence layer** — база даних забезпечує персистентність даних через SQLite файл `data/app.db`, який зберігає всі дані в одному файлі на диску. Дані зберігаються структуровано через таблиці з визначеними полями, типами, обмеженнями та зв'язками між таблицями через foreign keys. SQLModel ORM забезпечує абстракцію над SQL, дозволяючи працювати з даними як з Python-об'єктами, що спрощує роботу з БД та забезпечує типобезпеку. Репозиторійний шар у `src/service/repositories.py` інкапсулює логіку роботи з БД, надаючи функції для CRUD операцій (створення, читання, оновлення, видалення) для всіх сутностей, що забезпечує консистентність та спрощує підтримку коду.

**Принцип збереження та читання** — збереження даних виконується через транзакції SQLite, які гарантують атомарність операцій (всі зміни виконуються разом або не виконуються взагалі). При створенні або оновленні запису сесія БД створюється через `get_session()`, дані додаються або оновлюються через SQLModel-моделі, транзакція комітиться через `session.commit()` при успішному завершенні або відкочується через `session.rollback()` при помилках. Читання даних виконується через SQL-запити через SQLModel (наприклад, `select(User).where(User.email == email)`), які автоматично конвертуються в SQL та виконуються через SQLAlchemy engine. Результати повертаються як Python-об'єкти, які можуть бути серіалізовані в JSON для API або використані безпосередньо в коді. Це забезпечує надійність збереження даних та швидкість читання через індекси на ключових полях.

### 11.6. AI-асистент

AI-асистент інтегрується з локальним Ollama сервером для надання персоналізованих рекомендацій щодо здоров'я на основі результатів прогнозування.

**Взаємодія з Ollama** — бекенд взаємодіє з Ollama через HTTP API через модуль `src/service/services/assistant_llm.py`. Модуль формує контекст про стан здоров'я користувача на основі останнього прогнозу через `build_health_context()`, який отримує дані з БД про останній прогноз користувача (цільова змінна, ймовірність, категорія ризику, ключові фактори) та форматує їх у текстовий контекст. Модуль конструює промпт для LLM з інструкціями та контекстом через `build_assistant_prompt()`, який включає системний промпт з інструкціями (асистент не ставить діагнозів, не призначає лікування), контекст користувача та запит користувача. Модуль викликає Ollama через HTTP POST-запит до `http://localhost:11434/api/generate` через `call_ollama()`, який відправляє промпт до Ollama та отримує відповідь від LLM. Відповідь обробляється та зберігається в БД через `add_message()` для історії діалогів.

**Обробка історії** — історія діалогів з AI-асистентом зберігається в таблиці `assistantmessage` для кожного користувача. Історія включає всі попередні повідомлення користувача та асистента, зберігає порядок хронологічно, включає timestamps для кожного повідомлення та може бути пов'язана з конкретним прогнозом через `prediction_id` для контексту. Історія завантажується при активації сторінки асистента через ендпоінт `/assistant/history`, який повертає всі повідомлення користувача, відсортовані за часом. Історія використовується для відображення діалогу на фронтенді та може бути використана для покращення контексту майбутніх відповідей (хоча наразі контекст формується тільки на основі останнього прогнозу).

**Алгоритм відповіді** — алгоритм формування відповіді AI-асистента включає кілька кроків: отримання повідомлення користувача через ендпоінт `/assistant/chat`, формування контексту про стан здоров'я користувача на основі останнього прогнозу (або конкретного прогнозу, якщо вказано `prediction_id`), конструювання промпту з інструкціями, контекстом та запитом користувача, виклик Ollama через HTTP API для генерації відповіді, обробка відповіді від Ollama (яка може бути у форматі NDJSON для streaming), збереження повідомлення користувача та відповіді асистента в БД, повернення відповіді фронтенду для відображення в чаті. Алгоритм забезпечує персоналізовані рекомендації на основі конкретних результатів прогнозування користувача та контексту його здоров'я.

**Кешування контексту** — контекст про стан здоров'я користувача формується на основі останнього прогнозу з БД через `get_latest_prediction()`, який отримує найновіший запис з таблиці `predictionhistory` для користувача. Контекст включає цільову змінну (діабет або ожиріння), ймовірність ризику, категорію ризику (низький, середній, високий), топ фактори впливу та вхідні параметри прогнозу. Контекст кешується в пам'яті на рівні запиту для уникнення повторних запитів до БД, але не зберігається між різними запитами для забезпечення актуальності даних. В майбутньому можна додати кешування контексту на рівні сесії користувача для покращення продуктивності при багаторазових запитах до асистента.

## 12. AI-МОДЕЛЬ OLLAMA

### 12.1. Що таке Ollama

Ollama — це локальний сервер для запуску великих мовних моделей (LLM) без необхідності підключення до хмарних сервісів, що забезпечує приватність, швидкість та незалежність від зовнішніх сервісів.

**Локальна LLM** — Ollama дозволяє запускати мовні моделі (наприклад, Llama3, Mistral, Phi) локально на комп'ютері користувача або сервері, без необхідності відправляти дані на зовнішні сервіси. Моделі завантажуються та запускаються через HTTP API, що дозволяє легко інтегрувати їх у додатки. Ollama автоматично керує завантаженням моделей, їх кешуванням у пам'яті та обробкою запитів, що спрощує роботу з LLM для розробників.

**Чому обрана** — Ollama обрана для проєкту HealthRisk.AI через кілька переваг: приватність — всі дані користувачів (результати прогнозів, запити до асистента) залишаються локально, не передаються на зовнішні сервіси, що критично важливо для медичних даних; швидкість — локальна обробка забезпечує низьку латентність без залежності від мережевих затримок; незалежність — система працює без необхідності інтернет-з'єднання для AI-асистента, що забезпечує стабільність роботи; безкоштовність — Ollama та багато моделей безкоштовні, не потрібні підписки на хмарні сервіси; гнучкість — можна використовувати різні моделі залежно від потреб, налаштовувати параметри генерації, додавати власні промпти; простота інтеграції — HTTP API дозволяє легко інтегрувати Ollama у будь-який додаток без складних налаштувань.

**Як працює інтеграція** — інтеграція з Ollama реалізована через модуль `src/service/services/assistant_llm.py`, який виконує HTTP-запити до локального Ollama сервера на адресі `http://localhost:11434/api/generate`. Модуль формує контекст про стан здоров'я користувача на основі останнього прогнозу, конструює промпт з інструкціями та контекстом, відправляє запит до Ollama через `requests.post()`, обробляє відповідь (яка може бути у форматі NDJSON для streaming або звичайного JSON), зберігає повідомлення в БД та повертає відповідь API. Інтеграція проста та не вимагає складних налаштувань, достатньо запустити Ollama сервер локально.

### 12.2. Архітектура інтеграції

Архітектура інтеграції з Ollama організована через модуль `assistant_llm.py`, який інкапсулює всю логіку взаємодії з LLM та забезпечує чистий інтерфейс для API.

**Виклики через API** — взаємодія з Ollama виконується через HTTP POST-запити до ендпоінту `/api/generate` на локальному сервері `http://localhost:11434`. Запит містить JSON з полями: `model` (назва моделі, наприклад "llama3"), `prompt` (текст промпту з інструкціями, контекстом та запитом користувача), `stream` (boolean, чи використовувати streaming відповідь), `options` (параметри генерації: температура, top_p, max_tokens). Відповідь від Ollama може бути у форматі звичайного JSON (якщо `stream=false`) або NDJSON (якщо `stream=true`), де кожен рядок містить частину відповіді. Модуль обробляє обидва формати та формує фінальну відповідь для API.

**Обробка відповідей** — обробка відповіді від Ollama включає кілька кроків: отримання HTTP-відповіді від Ollama через `requests.post()`, перевірка статус-коду (200 для успішних, інші для помилок), парсинг JSON або NDJSON відповіді, витягування тексту відповіді з поля `response`, обробка помилок (таймаути, помилки з'єднання, помилки Ollama), формування структурованої відповіді для API. Якщо відповідь у форматі NDJSON (streaming), модуль обробляє кожен рядок та збирає повну відповідь. Обробка включає обрізання зайвих пробілів, видалення спеціальних символів та форматування тексту для відображення на фронтенді.

**Токенізація** — Ollama автоматично виконує токенізацію вхідного тексту (промпту) та генерацію токенів для відповіді, тому модуль `assistant_llm.py` не виконує токенізацію безпосередньо. Модуль передає повний текст промпту до Ollama, який сам виконує токенізацію через свою модель. Параметри генерації (наприклад, `max_tokens`) контролюють максимальну кількість токенів у відповіді, що дозволяє обмежити довжину відповіді. Модуль не потребує знання про внутрішню структуру токенізації Ollama, що спрощує інтеграцію.

**Формування prompts** — формування промптів виконується через функцію `build_assistant_prompt()` у модулі `assistant_llm.py`. Промпт складається з кількох частин: системний промпт з інструкціями для асистента (асистент не ставить діагнозів, не призначає лікування, надає загальні рекомендації), контекст про стан здоров'я користувача (формується через `build_health_context()` на основі останнього прогнозу), запит користувача (текст повідомлення від користувача). Промпт формується як структурований текст з чіткими розділами, що забезпечує зрозумілість для LLM та коректність відповідей. Системний промпт включає обмеження та правила для забезпечення безпеки та відповідальності відповідей.

### 12.3. Використання у чаті

AI-асистент використовується у чаті для надання персоналізованих рекомендацій щодо здоров'я на основі результатів прогнозування користувача.

**Логіка підказок** — підказки для користувача формуються на основі контексту його останнього прогнозу через `build_health_context()`, який отримує дані з БД про останній прогноз (цільова змінна, ймовірність, категорія ризику, топ фактори). Контекст форматується як текстовий опис стану здоров'я користувача, який передається до LLM разом із запитом користувача. LLM використовує цей контекст для формування персоналізованих рекомендацій, які враховують конкретні результати прогнозування користувача. Підказки можуть включати рекомендації щодо зменшення ризиків, зміни способу життя, консультації з лікарем та інші корисні поради.

**Контекстні відповіді** — відповіді асистента формуються на основі контексту останнього прогнозу користувача, що забезпечує релевантність та персоналізацію. Контекст включає інформацію про цільову змінну (діабет або ожиріння), ймовірність ризику, категорію ризику (низький, середній, високий), топ фактори впливу (наприклад, високий ІМТ, підвищена глюкоза) та вхідні параметри прогнозу (вік, стать, артеріальний тиск). LLM використовує цей контекст для формування відповідей, які враховують конкретну ситуацію користувача та надають корисні рекомендації. Контекст оновлюється при кожному новому прогнозі, що забезпечує актуальність відповідей.

**Діалогова пам'ять** — історія діалогів з AI-асистентом зберігається в таблиці `assistantmessage` для кожного користувача, що дозволяє відстежувати попередні повідомлення та відповіді. Історія включає всі повідомлення користувача та асистента, зберігає порядок хронологічно, включає timestamps для кожного повідомлення та може бути пов'язана з конкретним прогнозом через `prediction_id` для контексту. Наразі контекст формується тільки на основі останнього прогнозу, але в майбутньому можна додати використання повної історії діалогів для покращення контексту та забезпечення послідовності розмови. Історія завантажується при активації сторінки асистента через ендпоінт `/assistant/history` та відображається на фронтенді для користувача.

### 12.4. Статуси та monitoring

Моніторинг стану Ollama виконується через ендпоінт `/assistant/health`, який перевіряє доступність сервера, вимірює латентність та повертає статус для відображення на фронтенді.

**Як перевіряється статус Ollama** — ендпоінт `/assistant/health` виконує HTTP-запит до локального Ollama сервера (`http://localhost:11434/api/generate`) з тестовим промптом ("ok"), вимірює латентність (час відповіді), перевіряє наявність поля `response` у відповіді. Запит виконується з таймаутом 10 секунд для запобігання довгим очікуванням. Результат повертається як JSON з полями: `status` ("online", "offline", "timeout", "error"), `is_available` (boolean), `latency_ms` (мілісекунди), `error` (текст помилки, якщо є), `timestamp`. Обробляються різні типи помилок: `Timeout` (таймаут 10 секунд), `ConnectionError` (Ollama не запущений), інші помилки (неочікувані помилки). Ендпоінт викликається періодично з фронтенду (кожні 10 секунд) для моніторингу стану Ollama.

**Чому інколи "лежить"** — Ollama може бути недоступна через кілька причин: сервер не запущений — якщо Ollama сервер не запущений локально, всі запити будуть повертати `ConnectionError`; таймаути — якщо Ollama завантажує велику модель або обробляє складний запит, він може не встигнути відповісти за 10 секунд, що призводить до таймауту; помилки моделі — якщо модель не завантажена або пошкоджена, Ollama може повертати помилки; нестача ресурсів — якщо на комп'ютері не вистачає пам'яті або CPU, Ollama може працювати повільно або не працювати взагалі; конфлікти портів — якщо порт 11434 зайнятий іншим процесом, Ollama не зможе запуститися. Для вирішення проблем потрібно перевірити, чи запущений Ollama сервер, чи завантажена модель, чи достатньо ресурсів системи.

**Як відображається статус на frontend** — статус Ollama відображається на сторінці `/api-status` через індикатори стану (зелений для онлайн, червоний для офлайн, жовтий для таймауту), графіки латентності (час відгуку в мілісекундах), детальну статистику (останній статус, середня латентність, кількість помилок), повідомлення про помилки (текст помилки, час останньої помилки). Фронтенд робить періодичні запити (кожні 10 секунд) до ендпоінту `/assistant/health`, зберігає історію статусів для побудови графіків та оновлює UI при зміні статусу. Індикатори стану відображаються у вкладці "Ollama" на сторінці `/api-status` разом з інформацією про API та БД.

## 13. Security (Безпека)

Система безпеки проєкту HealthRisk.AI організована через багатошаровий підхід, що забезпечує захист даних користувачів, API та ML-моделей від несанкціонованого доступу та зловмисних атак.

**JWT-токени** — система аутентифікації використовує JSON Web Tokens (JWT) для забезпечення безпечного доступу до захищених ендпоінтів. JWT токени генеруються при успішному логіні через функцію `create_access_token()` у модулі `auth_utils.py`, яка створює токен з полями: `sub` (email користувача), `exp` (час закінчення, за замовчуванням 60 хвилин), `iat` (час створення). Токен підписується через секретний ключ (SECRET_KEY з environment variables) за алгоритмом HS256, що забезпечує цілісність та автентичність токену. Токен передається клієнту у відповіді API та зберігається у `localStorage` на фронтенді для подальшого використання. При кожному захищеному запиті токен передається у заголовку `Authorization: Bearer <token>`, де він перевіряється через `get_current_user()` для отримання користувача з БД.

**Refresh/Access** — наразі система використовує тільки access токени без окремого refresh механізму. Access токени мають термін дії 60 хвилин, після чого користувач повинен увійти знову. В майбутньому можна додати refresh токени з довшим терміном дії (наприклад, 7 днів), які зберігаються у HTTP-only cookies для безпеки та використовуються для автоматичного оновлення access токенів без необхідності повторного логіну. Refresh токени повинні бути зберігані на сервері (у БД або Redis) для можливості відкликання при необхідності.

**CSRF — чому не потрібен у SPA** — Cross-Site Request Forgery (CSRF) захист не потрібен у Single Page Application (SPA), оскільки SPA використовує AJAX-запити через JavaScript, які автоматично включають cookies та заголовки з того ж домену. CSRF атаки працюють через міжсайтові запити з інших доменів, але SPA завжди робить запити з того ж домену, де розміщений фронтенд, тому CSRF токени не потрібні. Додатково, CORS налаштування на бекенді обмежують запити тільки з дозволених доменів, що забезпечує додатковий захист від міжсайтових атак. Для додаткової безпеки можна використовувати SameSite cookies та Content Security Policy (CSP) заголовки.

**Валідація даних** — валідація вхідних даних виконується на кількох рівнях: Pydantic схеми на рівні API для валідації структури, типів, діапазонів та обов'язковості полів у вхідних даних (наприклад, `PredictRequest`, `LoginRequest`, `RegisterRequest`), валідація на рівні бізнес-логіки для перевірки коректності значень (наприклад, перевірка email на унікальність, перевірка пароля на мінімальну довжину), валідація на рівні БД через обмеження (unique, not null, foreign keys) для забезпечення цілісності даних. Pydantic автоматично повертає детальні помилки валідації (HTTP 422) з описом проблем у кожному полі, що дозволяє фронтенду відображати зрозумілі повідомлення користувачам. Валідація забезпечує, що тільки коректні дані потрапляють у систему та обробляються ML-моделями.

**Валідація моделей** — ML-моделі валідуються на кількох етапах: валідація при завантаженні через перевірку наявності файлів моделей, коректності структури pipeline, наявності необхідних компонентів (imputer, scaler, encoder, classifier), валідація вхідних даних перед інференсом через перевірку наявності обов'язкових ознак, діапазонів значень, типів даних, валідація вихідних даних після інференсу через перевірку діапазонів ймовірностей (0-1), наявності всіх необхідних полів у відповіді, коректності категорій ризику. Валідація забезпечує, що моделі працюють коректно та повертають валідні результати навіть при нестандартних вхідних даних. Помилки валідації обробляються та повертаються як HTTP 500 з детальними повідомленнями для логування.

**Робота з паролями** — паролі користувачів ніколи не зберігаються у відкритому вигляді, а тільки як bcrypt-хеші через функцію `get_password_hash()` у модулі `auth_utils.py`. Bcrypt використовує salt (випадкову сіль для кожного пароля) та багато ітерацій хешування (за замовчуванням 12 раундів), що робить brute-force атаки практично неможливими. При логіні пароль перевіряється через `verify_password()`, яка порівнює хеш введеного пароля з хешем у БД без зберігання оригінального пароля. Паролі передаються через HTTPS (якщо налаштовано) для захисту від перехоплення під час передачі. Мінімальна довжина пароля та складність можуть бути додані через валідацію Pydantic для забезпечення безпеки.

**Захист API** — захист API організується через кілька механізмів: аутентифікація через JWT токени для захищених ендпоінтів (більшість ендпоінтів вимагають автентифікованого користувача через `Depends(get_current_user)`), CORS налаштування для обмеження запитів тільки з дозволених доменів, валідація вхідних даних через Pydantic для запобігання injection атакам, обробка помилок без розкриття внутрішніх деталей системи (повідомлення про помилки не містять стеку викликів або шляхів до файлів), rate limiting (може бути додано в майбутньому) для запобігання DDoS атакам. Публічні ендпоінти (наприклад, `/health`, `/api-status`) не вимагають аутентифікації, але не повертають чутливі дані. Захист забезпечує, що тільки авторизовані користувачі можуть отримувати доступ до захищених ресурсів та виконувати операції.

**Роль ізоляції ML-коду** — ML-код ізольований від основного API через модуль `model_registry.py`, який інкапсулює всю логіку завантаження та використання моделей. Ізоляція забезпечує: безпеку — моделі не можуть бути завантажені або модифіковані через API, вони доступні тільки через внутрішній код, захист від injection — вхідні дані валідуються перед передачею до моделей, моделі не виконують довільний код, тільки обробляють структуровані дані, контроль доступу — тільки авторизовані користувачі можуть виконувати прогнози через API, моделі не доступні напряму, тестованість — ML-код може бути протестований ізольовано від API, що спрощує тестування та налагодження. Ізоляція забезпечує, що ML-моделі використовуються тільки через безпечні інтерфейси та не можуть бути скомпрометовані через API.

**Чому PDF генерується локально** — PDF-звіти генеруються на фронтенді через jsPDF замість генерації на бекенді через кілька причин: безпека — дані користувачів не передаються на сервер для генерації PDF, всі дані залишаються локально у браузері, що зменшує ризик витоку даних, продуктивність — генерація PDF на клієнті не навантажує сервер, що дозволяє обробляти більше запитів одночасно, приватність — користувач має повний контроль над своїми даними, PDF генерується локально без передачі на сервер, швидкість — генерація PDF на клієнті швидша, оскільки не потрібні мережеві затримки для передачі даних на сервер та отримання готового PDF, масштабованість — генерація PDF на клієнті не вимагає додаткових ресурсів сервера, що дозволяє масштабувати систему без збільшення навантаження на сервер. Генерація PDF на фронтенді забезпечує безпеку, приватність та продуктивність системи.

## 14. DevOps / Deploy / Infrastructure

Інфраструктура проєкту HealthRisk.AI організована для локальної розробки та тестування з можливістю розгортання на продакшен сервери.

**Як запускати систему локально** — система запускається локально через кілька кроків: встановлення залежностей через `pip install -r requirements.txt` для Python залежностей, налаштування environment variables через копіювання `.env.example` у `.env` та заповнення необхідних значень (SECRET_KEY, DATABASE_URL), ініціалізація БД через автоматичне створення при першому запуску або через `make init-db` для ручної ініціалізації, запуск FastAPI сервера через `make run` або `uvicorn src.service.api:app --reload` для розробки з auto-reload, запуск Ollama сервера локально через `ollama serve` (якщо Ollama встановлена) для AI-асистента, відкриття браузера на `http://localhost:8000` для доступу до вебінтерфейсу. Система автоматично створює БД при першому запуску та налаштовує всі необхідні компоненти.

**Makefile** — Makefile містить команди для автоматизації розробки та розгортання: `make run` для запуску FastAPI сервера з auto-reload, `make test` для запуску всіх тестів, `make test-backend-unit` для запуску unit тестів бекенду, `make test-coverage` для запуску тестів з покриттям коду, `make init-db` для ініціалізації БД, `make clean` для очищення тимчасових файлів, `make lint` для перевірки коду через linter. Makefile спрощує роботу з проєктом та забезпечує консистентність команд між різними розробниками. Команди можуть бути розширені для додаткових завдань (наприклад, міграції БД, генерація документації, деплой).

**Навіщо Ollama у dev-середовищі** — Ollama потрібна у dev-середовищі для тестування та розробки AI-асистента, оскільки асистент вимагає локального LLM сервера для генерації відповідей. Без Ollama AI-асистент не працює, а ендпоінт `/assistant/chat` повертає помилки. Ollama дозволяє розробникам тестувати повний функціонал системи локально без необхідності підключення до хмарних сервісів. Для розробки можна використовувати легкі моделі (наприклад, Phi) для швидкої генерації відповідей, а для тестування — повні моделі (наприклад, Llama3) для реалістичних відповідей. Ollama може бути запущена у Docker контейнері для ізоляції або локально на комп'ютері розробника.

**Як працюють environment variables** — environment variables зберігаються у файлі `.env` у корені проєкту та завантажуються через `python-dotenv` при старті додатку. Основні змінні включають: `SECRET_KEY` (секретний ключ для JWT токенів, повинен бути унікальним та випадковим), `DATABASE_URL` (URL підключення до БД, за замовчуванням `sqlite:///data/app.db`), `OLLAMA_BASE_URL` (URL Ollama сервера, за замовчуванням `http://localhost:11434`), `DEBUG` (режим відлагодження, за замовчуванням `False`). Змінні завантажуються через `load_dotenv()` у модулі `db.py` та використовуються через `os.getenv()` у коді. Файл `.env` не комітиться у Git (доданий у `.gitignore`) для безпеки, а `.env.example` містить приклади значень для нових розробників.

**Які сервіси запускаються** — система вимагає запуску кількох сервісів: FastAPI сервер (основний бекенд, обробляє HTTP-запити, виконує ML inference, працює з БД), Ollama сервер (локальний LLM сервер для AI-асистента, опційний, якщо не потрібен асистент), веб-сервер (для розробки використовується Uvicorn, для продакшену можна використовувати Gunicorn з Uvicorn workers). FastAPI сервер є основним сервісом та повинен бути запущений завжди. Ollama сервер потрібен тільки для AI-асистента та може бути запущений окремо. Всі сервіси можуть бути запущені локально або в Docker контейнерах для ізоляції.

**Як розгортати систему** — розгортання системи на продакшен сервер включає кілька кроків: підготовка сервера (встановлення Python, залежностей, налаштування environment variables), копіювання файлів проєкту на сервер (через Git, FTP або інші методи), ініціалізація БД через `make init-db` або автоматично при першому запуску, запуск FastAPI сервера через systemd service або process manager (наприклад, PM2, Supervisor), налаштування reverse proxy (наприклад, Nginx) для обробки HTTP-запитів та SSL сертифікатів, запуск Ollama сервера (якщо потрібен AI-асистент), налаштування моніторингу та логування. Для продакшену рекомендується використовувати Gunicorn з Uvicorn workers для кращої продуктивності та стабільності. Система може бути розгорнута на хмарних платформах (наприклад, AWS, Google Cloud, Azure) або на власних серверах.

**Backup файлів** — резервне копіювання включає кілька компонентів: БД файл (`data/app.db`) — найважливіший файл, який містить всі дані користувачів, історію прогнозів, чати, повідомлення, повинен копіюватися регулярно (наприклад, щодня) через `cp data/app.db backups/app_$(date +%Y%m%d).db`, ML моделі (`artifacts/models/`) — навчені моделі, які важко відновити, повинні копіюватися при змінах, environment variables (`.env`) — чутливі дані, повинні зберігатися безпечно, конфігураційні файли (`configs/`) — налаштування проєкту, повинні копіюватися при змінах. Backup може виконуватися вручну або автоматично через cron jobs або скрипти. Backup файли повинні зберігатися на окремому сервері або у хмарному сховищі для захисту від втрати даних.

**Логи** — логування в системі виконується через стандартний Python logging модуль з різними рівнями (DEBUG, INFO, WARNING, ERROR, CRITICAL). Логи записуються у файли (наприклад, `logs/app.log`) або виводяться у консоль залежно від налаштувань. Логування включає: HTTP-запити (URL, метод, статус-код, час обробки), помилки (stack traces, деталі помилок, контекст), ML inference (час виконання, використані моделі, результати), БД операції (запити, помилки, транзакції), AI-асистент (запити до Ollama, відповіді, помилки). Логи можуть бути інтегровані з зовнішніми системами моніторингу (наприклад, ELK Stack, Sentry) для аналізу та алертів. Для продакшену рекомендується використовувати структуровані логи (JSON) для легшого парсингу та аналізу.

## 15. Інтернаціоналізація (i18n)

Система інтернаціоналізації проєкту HealthRisk.AI забезпечує підтримку кількох мов для вебінтерфейсу та дозволяє легко додавати нові мови.

**Чому вона потрібна** — інтернаціоналізація потрібна для забезпечення доступності системи для користувачів з різних країн та мов, що розширює аудиторію проєкту та покращує користувацький досвід. Для магістерського проєкту інтернаціоналізація демонструє професійний підхід до розробки та готовність системи до міжнародного використання. Підтримка української та англійської мов забезпечує доступність для українських користувачів та міжнародної аудиторії.

**Структура JSON-файлів** — переклади зберігаються у JSON-файлах у директорії `src/service/web/locales/` з назвами `uk.json` (українська) та `en.json` (англійська). Кожен файл містить структуровані ключі для всіх текстів у додатку, організовані за функціональними групами: `forms` (форми, поля вводу, кнопки), `history` (історія прогнозів, фільтри, сортування), `charts` (діаграми, легенди, підписи), `assistant` (AI-асистент, повідомлення, підказки), `errors` (повідомлення про помилки, валідація), `navigation` (меню, посилання, заголовки), `common` (загальні тексти, підтвердження, сповіщення). Структура ключів ієрархічна через вкладені об'єкти (наприклад, `forms.targets.diabetes_present`, `history.empty.title`), що дозволяє легко організувати та знаходити переклади. Кожен ключ містить текст перекладу для відповідної мови.

**Принцип завантаження мов** — мови завантажуються через модуль `i18n.js` на фронтенді, який визначає поточну мову користувача з `localStorage` (ключ `healthrisk_lang`) або з налаштувань браузера (через `navigator.language`). Модуль завантажує відповідний JSON-файл через `fetch()` та зберігає переклади у пам'яті для швидкого доступу. Якщо мова не підтримується, використовується українська як fallback. Завантаження виконується при ініціалізації сторінки та може бути повторено при зміні мови. Модуль надає функцію `i18n.t(key, vars)` для отримання перекладу за ключем з опційними змінними для інтерполяції (наприклад, `i18n.t('history.count', {count: 5})`).

**Як перемикається мова** — перемикання мови виконується через кнопку у sidebar або налаштуваннях, яка викликає функцію `setLanguage(lang)` у модулі `i18n.js`. Функція зберігає вибрану мову у `localStorage` (ключ `healthrisk_lang`), завантажує відповідний JSON-файл з перекладами, викликає `applyTranslations()` для оновлення всіх текстів на сторінці та оновлює атрибут `lang` на елементі `<html>` для правильного відображення тексту. Перемикання мови не вимагає перезавантаження сторінки, всі тексти оновлюються динамічно через JavaScript. Поточна мова зберігається між сесіями через `localStorage`, тому користувач не потребує повторного вибору мови при наступному відвідуванні.

**Локалізація атрибутів** — локалізація атрибутів HTML-елементів виконується через спеціальні атрибути з префіксом `data-i18n-`: `data-i18n-title` для атрибута `title`, `data-i18n-placeholder` для атрибута `placeholder`, `data-i18n-aria-label` для атрибута `aria-label`, `data-i18n-alt` для атрибута `alt` у зображень. Функція `applyTranslations()` обходить всі елементи з цими атрибутами, знаходить переклад через `i18n.t()` та встановлює його як значення відповідного атрибута. Це забезпечує локалізацію не тільки видимого тексту, але й допоміжних атрибутів для доступності та UX. Локалізація атрибутів виконується разом з локалізацією тексту при завантаженні сторінки та зміні мови.

**Локалізація UI компонентів** — UI компоненти локалізуються через атрибут `data-i18n` на HTML-елементах, який містить ключ перекладу. Функція `applyTranslations()` обходить всі елементи з цим атрибутом, знаходить переклад через `i18n.t()` та встановлює його як `textContent` елемента. Компоненти включають: форми (labels, placeholders, кнопки, повідомлення валідації), навігацію (меню, посилання, заголовки), нотифікації (toast-сповіщення для успіхів, помилок, інформації), модальні вікна (заголовки, тексти, кнопки підтвердження), діаграми (легенди, підписи осей, tooltips), AI-асистент (повідомлення, підказки, статуси). Локалізація виконується при ініціалізації компонентів та оновлюється при зміні мови.

**Підтримка динамічних текстів** — динамічні тексти (які містять змінні, наприклад, кількість записів, імена користувачів) локалізуються через функцію `i18n.t(key, vars)`, яка приймає ключ перекладу та об'єкт зі змінними для інтерполяції. Наприклад, `i18n.t('history.count', {count: 5})` замінює `{count}` у перекладі на значення `5`. Переклади можуть містити плейсхолдери у форматі `{variable_name}`, які замінюються значеннями з об'єкта `vars`. Це дозволяє створювати динамічні тексти з змінними без необхідності конкатенації рядків. Динамічні тексти використовуються для відображення кількості записів, імен користувачів, дат, часу та інших змінних значень.

**Масштабування під нові мови** — додавання нової мови вимагає кілька кроків: створення нового JSON-файлу у директорії `locales/` з тією ж структурою ключів, що й `uk.json` (наприклад, `de.json` для німецької), додавання коду мови до масиву `SUPPORTED_LANGUAGES` у `i18n.js` (наприклад, `['uk', 'en', 'de']`), додавання кнопки перемикання мови у UI (якщо потрібно), тестування перекладів для перевірки коректності та повноти. Модуль автоматично завантажує переклади для нової мови та використовує українську як fallback для відсутніх ключів. Структура ключів залишається незмінною, що забезпечує консистентність між мовами. Додавання нової мови не вимагає змін у коді, достатньо додати JSON-файл з перекладами.

## 16. Оптимізація продуктивності

Оптимізація продуктивності проєкту HealthRisk.AI організована на кількох рівнях для забезпечення швидкої роботи системи та комфортного користувацького досвіду.

**Чому SPA потребує оптимізації** — Single Page Application потребує оптимізації через кілька причин: великий розмір JavaScript файлу (`app.js` має близько 14667 рядків), що може сповільнити завантаження сторінки, велика кількість DOM-елементів (всі секції присутні в DOM з самого початку), що може сповільнити рендеринг, багаторазові API-запити для отримання даних, що може створювати затримки, складні операції (генерація PDF, рендеринг діаграм), які можуть блокувати UI, відсутність кешування даних між сесіями, що призводить до повторних запитів. Оптимізація забезпечує швидке завантаження сторінки, плавну навігацію, швидкі відповіді на дії користувача та ефективне використання ресурсів браузера.

**Оптимізація рендеру Canvas** — рендеринг Canvas для діаграм Chart.js оптимізується через кілька механізмів: використання `requestAnimationFrame` для плавної анімації та оновлення діаграм, обмеження частоти оновлень діаграм (наприклад, не більше 60 FPS), використання `will-change` CSS-властивості для оптимізації рендерингу, обмеження кількості одночасних діаграм на сторінці (показувати тільки видимі діаграми), використання `resizeObserver` для оптимізації зміни розміру діаграм, кешування даних діаграм для уникнення повторних обчислень, використання `debounce` для обмеження частоти оновлень при зміні фільтрів. Оптимізація забезпечує плавний рендеринг діаграм без лагів та блокування UI.

**Оптимізація PDF** — генерація PDF оптимізується через кілька підходів: асинхронне завантаження шрифтів (DejaVuSans) для уникнення блокування UI, використання `requestIdleCallback` для генерації PDF у вільний час браузера, обмеження розміру зображень діаграм (масштабування перед додаванням до PDF), використання `canvas.toDataURL()` з оптимальними параметрами якості для балансу між розміром та якістю, покрокова генерація PDF (генерація по одній сторінці за раз) для уникнення блокування UI, відображення прогресу генерації для інформування користувача. Оптимізація забезпечує швидку генерацію PDF без блокування UI та зберігає якість зображень.

**Мемоізація запитів** — мемоізація API-запитів реалізується через кешування відповідей у пам'яті на рівні запиту для уникнення повторних запитів з однаковими параметрами. Мемоізація включає: кешування результатів прогнозування для однакових вхідних параметрів (якщо користувач повторно запитує прогноз з тими ж даними), кешування історії прогнозів для уникнення повторних запитів до БД, кешування статусів API/БД/Ollama для обмеження частоти перевірок, кешування даних користувача (профіль, налаштування) для уникнення повторних запитів. Мемоізація забезпечує швидкість відповідей та зменшує навантаження на сервер. Кеш може бути очищений при зміні даних або при виході користувача.

**Кешування AI** — кешування відповідей AI-асистента реалізується через зберігання історії діалогів у БД та використання її для формування контексту без повторних запитів до Ollama для однакових питань. Кешування включає: зберігання повідомлень користувача та відповідей асистента у таблиці `assistantmessage` для подальшого використання, використання історії діалогів для покращення контексту майбутніх відповідей, кешування контексту про стан здоров'я користувача на рівні запиту для уникнення повторних запитів до БД. Кешування забезпечує швидкість відповідей та зменшує навантаження на Ollama. В майбутньому можна додати кешування відповідей для однакових питань для подальшого покращення продуктивності.

**Оптимізація JS** — оптимізація JavaScript коду включає кілька підходів: мінімізація коду через видалення коментарів, пробілів та невикористовуваного коду (через tools типу UglifyJS або Terser), розділення коду на модулі для lazy loading (завантаження тільки потрібних модулів), використання `async/defer` для скриптів, які не блокують рендеринг, обмеження глибини вкладеності функцій для покращення читабельності та продуктивності, використання `requestAnimationFrame` для анімацій та оновлень UI, оптимізація циклів та обробки масивів через ефективні алгоритми. Оптимізація забезпечує швидке виконання коду та зменшує час завантаження сторінки.

**Оптимізація завантаження сторінок** — оптимізація завантаження сторінок включає кілька механізмів: lazy loading секцій (завантаження тільки активної секції при першому відвідуванні), використання `IntersectionObserver` для lazy loading зображень та діаграм, кешування статичних ресурсів (CSS, JS, шрифти) через HTTP headers (Cache-Control), використання CDN для швидкого завантаження бібліотек (Chart.js, jsPDF, Lucide), мінімізація кількості HTTP-запитів через об'єднання файлів, використання `preload` для критичних ресурсів, оптимізація порядку завантаження скриптів (критичні скрипти спочатку). Оптимізація забезпечує швидке завантаження сторінки та покращує користувацький досвід. В майбутньому можна додати Service Workers для офлайн-роботи та кешування ресурсів. 